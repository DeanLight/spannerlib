{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your own optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Optimization Passes to the Pass Stack<a class=\"anchor\" id=\"optimization_passes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reading this section, we will briefly explain how passes work.\n",
    "There are five kinds of passes:\n",
    "1. **AST transformation passes** - These passes convert the input program into AST.\n",
    "2. **semantic checks passes** - These passes check the corectness of the program (i.e. one of the passes asserts that all the relations used in the program were registerred before).\n",
    "3. **AST execution passes** - These passes traverse the AST and covert it to a `parse graph`. In addition they register new relations and handle variables assingments.\n",
    "4. **term graph passes** - These passes adds rules into the `term graph`.\n",
    "5. **execution pass** - This pass traverses the `parse graph` and finds queries. Then it computes them using the `term graph`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two kinds of optimization passes:\n",
    "1. The first one, manipulates rules before they are added to the `term graph`.\n",
    "2. The second one, manipulates the structure of the `term graph`.\n",
    "\n",
    "note: It's also possible to optimize the execution function/pass (but we won't discuss it in this tutorial). \n",
    "    \n",
    "In this section, we will implement two simple optimization passes, one of each kind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Manipulation Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations of  this kind traverse the `parse_graph` and find rules that weren't added to the `term graph`.\n",
    "Then, they update each rule - by modifying its body relations list.\n",
    "\n",
    "Here are some examples of possible optimization passes of this kind:\n",
    "1. An optimization that removes duplicated relations from a rule.\n",
    "   i.e., the rule `A(X) <- B(X), C(X), B(X)` contains the relation `B(X)` twice.\n",
    "   The optimization will transform the rule into `A(X) <- B(X), C(X)`.\n",
    "   \n",
    "2. An optimization that removes useless relations from a rule.\n",
    "   i.e. the rule `A(X) <- B(X), C(Y)` contains the useless relation `C(Y)`.\n",
    "   The optimization will transform the rule into `A(X) <- B(X)`.\n",
    "   \n",
    "Below is an implementation of the latter example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Example: Remove Useless Relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the actual implementation, we will implement it in psuedo code:\n",
    "```\n",
    "1. a. Add the free variables inside the rule head into a relevant_free_variables set.\n",
    "   b. Mark all relations as useless, except those with no free variables (they are always relevant).\n",
    "   \n",
    "2. Find all relations which contain at least one free variable inside the relevant_free_variables set.\n",
    "\n",
    "3. Unmark these relations (since they are relevant).\n",
    "\n",
    "4. Add all free variables of the unmarked relations into the relevant_free_variables set.\n",
    "\n",
    "5. Repeat steps 2, 3 and 4 until the set of the marked relations converge.\n",
    "```\n",
    "note that this is a ```fixed_point``` algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installation NLP failed\n",
      "cargo or rustup are not installed in $PATH. please install rust: https://rustup.rs/\n"
     ]
    }
   ],
   "source": [
    "from spanner_workbench.general_utils import fixed_point\n",
    "from spanner_workbench.general_utils import get_output_free_var_names\n",
    "from spanner_workbench.general_utils import get_input_free_var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```get_output_free_var_names``` documentation\n",
    "```get_input_free_var_names``` documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, lets implement the logic that removes useless relations from a rule\n",
    "def remove_useless_relations(rule):\n",
    "        \"\"\"\n",
    "        Finds redundant relations and removes them from the rule.\n",
    "        \n",
    "        @param rule: a rule.\n",
    "        \"\"\"\n",
    "        # step 1.a. Add the free variables inside the rule head into a relevant_free_variables set.\n",
    "        relevant_free_vars = set(rule.head_relation.get_term_list())  \n",
    "\n",
    "        # step 1.b. Mark all relations as useless, except those with no free variables (they are always relevant).\n",
    "        initial_useless_relations_and_types = [(rel, rel_type) for rel, rel_type in zip(rule.body_relation_list, rule.body_relation_type_list)\n",
    "                                               if len(get_output_free_var_names(rel)) != 0]\n",
    "        # implement steps 2, 3 and 4\n",
    "        def step_function(current_useless_relations_and_types):\n",
    "            \"\"\"\n",
    "            Used by fixed pont algorithm.\n",
    "\n",
    "            @param current_useless_relations_and_types: current useless relations and their types\n",
    "            @return: useless relations after considering the new relevant free vars.\n",
    "            \"\"\"\n",
    "\n",
    "            next_useless_relations_and_types = []\n",
    "            \n",
    "            # step 2 - Find all relations that has at least on free variable inside the relevant_free_variables set.\n",
    "            for relation, rel_type in current_useless_relations_and_types:\n",
    "                term_list = get_output_free_var_names(relation)\n",
    "                if len(relevant_free_vars.intersection(term_list)) == 0:\n",
    "                    next_useless_relations_and_types.append((relation, rel_type))\n",
    "                else:\n",
    "                    # step 3 - Unmark relation. The relations isn't added to the useless list, and thus it's unmarked.\n",
    "                    # step 4 - Add all the free variables of the unmarked relation into the relevant_free_variables set.\n",
    "                    relevant_free_vars.update(term_list)\n",
    "                    relevant_free_vars.update(get_input_free_var_names(relation))\n",
    "\n",
    "            return next_useless_relations_and_types\n",
    "\n",
    "        # step 5 - fixed ponint. note that the distance function returns zero if and only if len(x) equals len(y).\n",
    "        useless_relations_and_types = fixed_point(start=initial_useless_relations_and_types, step=step_function, distance=lambda x, y: int(len(x) != len(y)))\n",
    "        \n",
    "        # this part filters the useless relation from the rule\n",
    "        relevant_relations_and_types = set(zip(rule.body_relation_list, rule.body_relation_type_list)).difference(useless_relations_and_types)\n",
    "        new_body_relation_list, new_body_relation_type_list = zip(*relevant_relations_and_types)\n",
    "        rule.body_relation_list = list(new_body_relation_list)\n",
    "        rule.body_relation_type_list = list(new_body_relation_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spanner_workbench.graphs import GraphBase, EvalState, STATE, TYPE, VALUE\n",
    "from spanner_workbench.passes_utils import ParseNodeType\n",
    "from spanner_workbench.lark_passes import GenericPass  # base class of all the passes\n",
    "    \n",
    "\n",
    "# finally, the implementation of the optimization pass\n",
    "class RemoveUselessRelationsFromRule(GenericPass):\n",
    "    \"\"\"\n",
    "    This pass removes duplicated relations from a rule.\n",
    "    For example, the rule A(X) <- B(X), C(Y) contains a redundant relation (C(Y)).\n",
    "    After this pass the rule will be A(X) <- B(X).\n",
    "\n",
    "    @note: in the rule A(X) <- B(X, Y), C(Y); C(Y) is not redundant!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, parse_graph: GraphBase, **kwargs):\n",
    "        self.parse_graph = parse_graph\n",
    "            \n",
    "    def run_pass(self, **kwargs):\n",
    "        # get the new rules in the parse graph\n",
    "        rules = self.parse_graph.get_all_nodes_with_attributes(type=ParseNodeType.RULE, state=EvalState.NOT_COMPUTED)\n",
    "        for rule_node_id in rules:\n",
    "            rule_node = self.parse_graph[rule_node_id]\n",
    "            rule = rule_node[VALUE]\n",
    "            remove_useless_relations(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the pass stack looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from spanner_workbench import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass stack before:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tAddRulesToTermGraph\n",
      "\n",
      "Pass stack after:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tRemoveUselessRelationsFromRule\n",
      "\tAddRulesToTermGraph\n"
     ]
    }
   ],
   "source": [
    "def print_pass_stack(pass_stack):\n",
    "    \"\"\"prints pass stack in a nice format\"\"\"\n",
    "    \n",
    "    for pass_ in pass_stack:\n",
    "        print(\"\\t\" + pass_.__name__)\n",
    "        \n",
    "magic_session = Session()  # reset the magic session\n",
    "\n",
    "original_pass_stack = magic_session.get_pass_stack()  # save the original pass stack\n",
    "\n",
    "new_pass_stack = original_pass_stack.copy()\n",
    "term_graph_pass = new_pass_stack.pop()  # remove last pass (this pass adds rules to term graph)\n",
    "new_pass_stack.extend([RemoveUselessRelationsFromRule, term_graph_pass])\n",
    "\n",
    "magic_session.set_pass_stack(new_pass_stack)\n",
    "\n",
    "print(f\"Pass stack before:\")\n",
    "print_pass_stack(original_pass_stack)\n",
    "\n",
    "print(\"\\nPass stack after:\")\n",
    "print_pass_stack(magic_session.get_pass_stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the effect of this pass on the parse graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse graph of unmodified pass stack:\n",
      "\n",
      "(__spanner_workbench_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Good(int)\n",
      "    (1) (computed) relation_declaration: Bad(int)\n",
      "    (2) (computed) rule: Example(X) <- Good(X), Bad(Y)\n",
      "\n",
      "\n",
      "Parse graph after adding optimization pass:\n",
      "\n",
      "(__spanner_workbench_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Good(int)\n",
      "    (1) (computed) relation_declaration: Bad(int)\n",
      "    (2) (computed) rule: Example(X) <- Good(X)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "new Good(int)\n",
    "new Bad(int)\n",
    "\n",
    "Example(X) <- Good(X), Bad(Y)\n",
    "\"\"\"\n",
    "\n",
    "def run_commands_and_print_parse_graph(session):\n",
    "    session.run_commands(commands)\n",
    "    print(session._parse_graph)\n",
    "    \n",
    "\n",
    "print(\"Parse graph of unmodified pass stack:\\n\")\n",
    "run_commands_and_print_parse_graph(Session()) \n",
    "\n",
    "print(\"\\nParse graph after adding optimization pass:\\n\")\n",
    "run_commands_and_print_parse_graph(magic_session) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference in the rule node!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Graph Structure Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations of this kind traverse the `term_graph` and modify its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Graph Structure\n",
    "Before reading on, it is important to understand how the ```TermGraph``` looks like in order to understand the terminology used - there is detailed documentation inside the class docstring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Optimization\n",
    "Here are some examples of possible optimization passes of this kind:\n",
    "1. An optimization that removes join nodes which have only one child relation.\n",
    "   Note: this optimization already exists so there is no need to implement it.\n",
    "   \n",
    "2. An optimization that removes project nodes whose input is a single-column relation.\n",
    "   \n",
    "Here's the implementation of the second example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Example: Remove Redundant Project Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following optimization will traverse the term graph and find all project nodes that has input relation with arity of one.<br>\n",
    "In this case, the project node is redundant and therefore, we remove it from the term graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before jumping into the actual implementation, we will implement it in a psuedo code:\n",
    "```\n",
    "1. Find all project nodes and their union nodes parents (inside the term graph).\n",
    "\n",
    "2. For each project node\n",
    "\n",
    "    2.1. Check if the arity of the project node's input relation is one, using the following steps:\n",
    "        a. get project's node child - we will denote it as child_node.\n",
    "        b. if type of child_node is GET_REL or RULE_REL or CALC node child, return true if arity of the relation stored in child_node is one.\n",
    "        c. if type of child_node is SELECT, return true if there is only one free variable in the relation stored in the child of the child_node. \n",
    "        d. if type of child_node is project:\n",
    "              (i). get input relaations from all of it's children nodes\n",
    "              (ii). return true if the arity of the join of all the input relations is one.\n",
    "              \n",
    "    2.2 if has arity of one, remove the node from the graph by connecting it's child to it's parent.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def is_relation_has_one_free_var(relation) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether relation is only one free variable.\n",
    "\n",
    "    @param relation_: a relation or an ie_relation.\n",
    "    \"\"\"\n",
    "\n",
    "    return len(relation.get_term_list()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spanner_workbench.graphs import *\n",
    "# this function implements step 2 in the pseudo code\n",
    "def is_input_relation_of_node_has_arity_of_one(term_graph: TermGraphBase, node_id) -> bool:\n",
    "    \"\"\"\n",
    "    @param node_id: id of the node.\n",
    "    @note: we expect id of project/join node.\n",
    "    @return: the arity of the relation that the node gets during the execution.\n",
    "    \"\"\"\n",
    "\n",
    "    # staep 2.1.a: note that this methods suppose to work for both project nodes and join nodes.\n",
    "    # project nodes always have one child while join nodes always have more than one child.\n",
    "    # for that reason, we traverse all the children of the node.\n",
    "    node_ids = term_graph.get_children(node_id)\n",
    "    \n",
    "    # used to compute arity of final relation\n",
    "    free_vars: Set[str] = set()\n",
    "\n",
    "    for node_id in node_ids:\n",
    "        node_attrs = term_graph[node_id]\n",
    "        node_type = node_attrs[TYPE]\n",
    "        \n",
    "        # step 2.1.b\n",
    "        if node_type in (TermNodeType.GET_REL, TermNodeType.RULE_REL, TermNodeType.CALC):\n",
    "            relation = node_attrs[VALUE]\n",
    "            # if relation has more than one free var we can't prune the project\n",
    "            if not is_relation_has_one_free_var(relation):\n",
    "                return False\n",
    "\n",
    "            free_vars |= set(relation.get_term_list())\n",
    "            \n",
    "        # step 2.1.c\n",
    "        elif node_type is TermNodeType.SELECT:\n",
    "            relation_child_id = next(iter(term_graph.get_children(node_id)))\n",
    "            relation = term_graph[relation_child_id][VALUE]\n",
    "            if not is_relation_has_one_free_var(relation):\n",
    "                return False\n",
    "\n",
    "            relation_free_vars = [var for var, var_type in zip(relation.get_term_list(), relation.get_type_list()) if var_type is DataTypes.free_var_name]\n",
    "            free_vars |= set(relation_free_vars)\n",
    "        \n",
    "        # step 2.1.d\n",
    "        elif node_type is TermNodeType.JOIN:\n",
    "            # the input of project node is the same as the input of the join node\n",
    "            return is_input_relation_of_node_has_arity_of_one(term_graph, node_id)\n",
    "\n",
    "    return len(free_vars) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, lets implement the optimization pass class\n",
    "class PruneUnnecessaryProjectNodes(GenericPass):\n",
    "    \"\"\"\n",
    "    This class prunes project nodes that gets a relation with one column (therefore, the project is redundant).\n",
    "\n",
    "    For example, the rule A(X) <- B(X) will yield the following term graph:\n",
    "\n",
    "        rule_rel node (of A)\n",
    "            union node\n",
    "                project node (on X)\n",
    "                   get_rel node (get B)\n",
    "\n",
    "        since we project a relation with one column, after this pass the term graph will be:\n",
    "\n",
    "        rule_rel node (of A)\n",
    "            union node\n",
    "                get_rel node (get B)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, term_graph: TermGraphBase, **kwargs):\n",
    "        self.term_graph = term_graph\n",
    "\n",
    "    def run_pass(self, **kwargs):\n",
    "        self.prune_project_nodes()\n",
    "        \n",
    "    def prune_project_nodes(self) -> None:\n",
    "        \"\"\"\n",
    "        Prunes the redundant project nodes.\n",
    "        \"\"\"\n",
    "\n",
    "        project_nodes = self.term_graph.get_all_nodes_with_attributes(type=TermNodeType.PROJECT)\n",
    "        for project_id in project_nodes:\n",
    "            if is_input_relation_of_node_has_arity_of_one(self.term_graph, project_id):\n",
    "                # step 2.2\n",
    "                self.term_graph.add_edge(self.term_graph.get_parent(project_id), self.term_graph.get_child(project_id))\n",
    "                self.term_graph.remove_node(project_id)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is adding this pass to the pass stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New pass stack:\n",
      "\tRemoveTokens\n",
      "\tFixStrings\n",
      "\tCheckReservedRelationNames\n",
      "\tConvertSpanNodesToSpanInstances\n",
      "\tConvertStatementsToStructuredNodes\n",
      "\tCheckDefinedReferencedVariables\n",
      "\tCheckReferencedRelationsExistenceAndArity\n",
      "\tCheckReferencedIERelationsExistenceAndArity\n",
      "\tCheckRuleSafety\n",
      "\tTypeCheckAssignments\n",
      "\tTypeCheckRelations\n",
      "\tSaveDeclaredRelationsSchemas\n",
      "\tResolveVariablesReferences\n",
      "\tExecuteAssignments\n",
      "\tAddStatementsToNetxParseGraph\n",
      "\tAddRulesToTermGraph\n",
      "\tPruneUnnecessaryProjectNodes\n"
     ]
    }
   ],
   "source": [
    "magic_session = Session()  # reset the magic_session\n",
    "\n",
    "new_pass_stack = magic_session.get_pass_stack()\n",
    "new_pass_stack.append(PruneUnnecessaryProjectNodes)\n",
    "magic_session.set_pass_stack(new_pass_stack)\n",
    "\n",
    "print(\"New pass stack:\")\n",
    "print_pass_stack(magic_session.get_pass_stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets see how this pass modifies the term graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term graph of unmodified pass stack:\n",
      "\n",
      "(__spanner_workbench_root) (not_computed) root\n",
      "    (A) (not_computed) rule_rel: A(X)\n",
      "        (0) (not_computed) union\n",
      "            (1) (not_computed) project: ['X']\n",
      "                (2) (not_computed) get_rel: B(X)\n",
      "\n",
      "DependencyGraph is:\n",
      "__spanner_workbench_root\n",
      "    A\n",
      "\n",
      "\n",
      "Term graph after adding optimization pass:\n",
      "\n",
      "(__spanner_workbench_root) (not_computed) root\n",
      "    (A) (not_computed) rule_rel: A(X)\n",
      "        (0) (not_computed) union\n",
      "            (2) (not_computed) get_rel: B(X)\n",
      "\n",
      "DependencyGraph is:\n",
      "__spanner_workbench_root\n",
      "    A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "new B(int)\n",
    "A(X) <- B(X)\n",
    "\"\"\"\n",
    "\n",
    "def run_commands_and_print_term_graph(session):\n",
    "    session.run_commands(commands)\n",
    "    print(session._term_graph)\n",
    "    \n",
    "\n",
    "print(\"Term graph of unmodified pass stack:\\n\")\n",
    "run_commands_and_print_term_graph(Session()) \n",
    "\n",
    "print(\"\\nTerm graph after adding optimization pass:\\n\")\n",
    "run_commands_and_print_term_graph(magic_session) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the changes in the term_graph's structure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Example: Overlapping Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another optimization example, this time without an implementation.\n",
    "It does the following:\n",
    "1. Finds overlapping structure of rules.\n",
    "2. Merges the overlapping structure and adds it to the term graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Example Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| output: false\n",
    "from IPython.display import SVG\n",
    "from spanner_workbench.utils import get_base_file_path\n",
    "from pathlib import Path\n",
    "def show_svg(svg_file):\n",
    "    return SVG(filename=f'{get_base_file_path()}/doc/{svg_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the following example:\n",
    "```\n",
    ">>> D(X,Y) <- A(X),B(Y),C(X,Y,Z)\n",
    ">>> E(X,Y) <- A(X),C(X,Y,Z), F(Z)\n",
    ">>> x(X,Y) <- E(X,Y)\n",
    ">>> x(X,Y) <- D(X,Y)\n",
    "```\n",
    "Without merging terms with overlapping structures,\n",
    "this would naively generate something that abstractly looks like this:\n",
    "<!--\n",
    " digraph G {\n",
    "   D_and [label=\"and\"]\n",
    "   E_and [label=\"and\"]\n",
    "   x->OR [style=dotted]\n",
    "   E->E_and [style=dotted]\n",
    "   D->D_and [style=dotted]\n",
    "   OR -> {D_and,E_and}\n",
    "   D_and ->{A,B,C}\n",
    "   E_and -> {A,C,F} \n",
    " }\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"278pt\" height=\"260pt\" viewBox=\"0.00 0.00 278.00 260.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 274,-256 274,4 -4,4\"/>\n",
       "<!-- D_and -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>D_and</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and</text>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">A</text>\n",
       "</g>\n",
       "<!-- D_and&#45;&gt;A -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>D_and-&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M99,-71.8314C99,-64.131 99,-54.9743 99,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.5001,-46.4132 99,-36.4133 95.5001,-46.4133 102.5001,-46.4132\"/>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n",
       "</g>\n",
       "<!-- D_and&#45;&gt;B -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>D_and-&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M83.7307,-74.7307C73.803,-64.803 60.6847,-51.6847 49.5637,-40.5637\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"51.7933,-37.8436 42.2473,-33.2473 46.8436,-42.7933 51.7933,-37.8436\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"171\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">C</text>\n",
       "</g>\n",
       "<!-- D_and&#45;&gt;C -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>D_and-&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M114.2693,-74.7307C124.197,-64.803 137.3153,-51.6847 148.4363,-40.5637\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"151.1564,-42.7933 155.7527,-33.2473 146.2067,-37.8436 151.1564,-42.7933\"/>\n",
       "</g>\n",
       "<!-- E_and -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>E_and</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and</text>\n",
       "</g>\n",
       "<!-- E_and&#45;&gt;A -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>E_and-&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M155.7307,-74.7307C145.803,-64.803 132.6847,-51.6847 121.5637,-40.5637\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"123.7933,-37.8436 114.2473,-33.2473 118.8436,-42.7933 123.7933,-37.8436\"/>\n",
       "</g>\n",
       "<!-- E_and&#45;&gt;C -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>E_and-&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M171,-71.8314C171,-64.131 171,-54.9743 171,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.5001,-46.4132 171,-36.4133 167.5001,-46.4133 174.5001,-46.4132\"/>\n",
       "</g>\n",
       "<!-- F -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>F</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"243\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n",
       "</g>\n",
       "<!-- E_and&#45;&gt;F -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>E_and-&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M186.2693,-74.7307C196.197,-64.803 209.3153,-51.6847 220.4363,-40.5637\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"223.1564,-42.7933 227.7527,-33.2473 218.2067,-37.8436 223.1564,-42.7933\"/>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"135\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x</text>\n",
       "</g>\n",
       "<!-- OR -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>OR</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"135\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">OR</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;OR -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x-&gt;OR</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M135,-215.8314C135,-208.131 135,-198.9743 135,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"138.5001,-190.4132 135,-180.4133 131.5001,-190.4133 138.5001,-190.4132\"/>\n",
       "</g>\n",
       "<!-- OR&#45;&gt;D_and -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>OR-&gt;D_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.2854,-144.5708C122.0403,-136.0807 116.8464,-125.6929 112.1337,-116.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"115.237,-114.6477 107.6343,-107.2687 108.976,-117.7782 115.237,-114.6477\"/>\n",
       "</g>\n",
       "<!-- OR&#45;&gt;E_and -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>OR-&gt;E_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.7146,-144.5708C147.9597,-136.0807 153.1536,-125.6929 157.8663,-116.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.024,-117.7782 162.3657,-107.2687 154.763,-114.6477 161.024,-117.7782\"/>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"207\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">E</text>\n",
       "</g>\n",
       "<!-- E&#45;&gt;E_and -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>E-&gt;E_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M198.2854,-144.5708C194.0403,-136.0807 188.8464,-125.6929 184.1337,-116.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.237,-114.6477 179.6343,-107.2687 180.976,-117.7782 187.237,-114.6477\"/>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"63\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">D</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;D_and -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>D-&gt;D_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M71.7146,-144.5708C75.9597,-136.0807 81.1536,-125.6929 85.8663,-116.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.024,-117.7782 90.3657,-107.2687 82.763,-114.6477 89.024,-117.7782\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_svg('naive_term_graph.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weakness with this approach is that `A AND C` is computed twice.\n",
    "\n",
    "A version of the term graph that takes care to merge terms with overlapping structures would look more like this:\n",
    "<!--\n",
    " digraph G {\n",
    "   D_and [label=\"and\"]\n",
    "   E_and [label=\"and\"]\n",
    "   x->OR [style=dotted]\n",
    "   E->E_and [style=dotted]\n",
    "   D->D_and [style=dotted]\n",
    "   OR -> {D_and,E_and}\n",
    "   D_and ->{and,B}\n",
    "   E_and -> {and,F} \n",
    "   and -> {A,C}\n",
    " }\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"215pt\" height=\"332pt\" viewBox=\"0.00 0.00 215.00 332.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-328 211,-328 211,4 -4,4\"/>\n",
       "<!-- D_and -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>D_and</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and</text>\n",
       "</g>\n",
       "<!-- and -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>and</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and</text>\n",
       "</g>\n",
       "<!-- D_and&#45;&gt;and -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>D_and-&gt;and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M64.437,-145.3008C69.9235,-136.5224 76.7686,-125.5703 82.9163,-115.7339\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.9751,-117.4436 88.3071,-107.1086 80.0391,-113.7336 85.9751,-117.4436\"/>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n",
       "</g>\n",
       "<!-- D_and&#45;&gt;B -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>D_and-&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3258,-144.2022C44.2524,-136.0064 40.5384,-126.1024 37.1305,-117.0145\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"40.3858,-115.7274 33.5974,-107.593 33.8315,-118.1853 40.3858,-115.7274\"/>\n",
       "</g>\n",
       "<!-- E_and -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>E_and</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"144\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"144\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">and</text>\n",
       "</g>\n",
       "<!-- E_and&#45;&gt;and -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>E_and-&gt;and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M133.563,-145.3008C128.0765,-136.5224 121.2314,-125.5703 115.0837,-115.7339\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"117.9609,-113.7336 109.6929,-107.1086 112.0249,-117.4436 117.9609,-113.7336\"/>\n",
       "</g>\n",
       "<!-- F -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>F</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n",
       "</g>\n",
       "<!-- E_and&#45;&gt;F -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>E_and-&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M150.6742,-144.2022C153.7476,-136.0064 157.4616,-126.1024 160.8695,-117.0145\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.1685,-118.1853 164.4026,-107.593 157.6142,-115.7274 164.1685,-118.1853\"/>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"108\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"108\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x</text>\n",
       "</g>\n",
       "<!-- OR -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>OR</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"108\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"108\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">OR</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;OR -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x-&gt;OR</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M108,-287.8314C108,-280.131 108,-270.9743 108,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"111.5001,-262.4132 108,-252.4133 104.5001,-262.4133 111.5001,-262.4132\"/>\n",
       "</g>\n",
       "<!-- OR&#45;&gt;D_and -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>OR-&gt;D_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95.7466,-217.6621C88.8423,-208.4564 80.0823,-196.7764 72.3715,-186.4953\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.005,-184.1733 66.2049,-178.2733 69.405,-188.3733 75.005,-184.1733\"/>\n",
       "</g>\n",
       "<!-- OR&#45;&gt;E_and -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>OR-&gt;E_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M116.7146,-216.5708C120.9597,-208.0807 126.1536,-197.6929 130.8663,-188.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"134.024,-189.7782 135.3657,-179.2687 127.763,-186.6477 134.024,-189.7782\"/>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"180\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"180\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">E</text>\n",
       "</g>\n",
       "<!-- E&#45;&gt;E_and -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>E-&gt;E_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M171.2854,-216.5708C167.0403,-208.0807 161.8464,-197.6929 157.1337,-188.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"160.237,-186.6477 152.6343,-179.2687 153.976,-189.7782 160.237,-186.6477\"/>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"36\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"36\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">D</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;D_and -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>D-&gt;D_and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" stroke-dasharray=\"1,5\" d=\"M40.4494,-216.2022C42.4398,-208.2406 44.8332,-198.6671 47.0511,-189.7957\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"50.5094,-190.3929 49.5394,-179.8425 43.7184,-188.6951 50.5094,-190.3929\"/>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">A</text>\n",
       "</g>\n",
       "<!-- and&#45;&gt;A -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>and-&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.2854,-72.5708C86.0403,-64.0807 80.8464,-53.6929 76.1337,-44.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.237,-42.6477 71.6343,-35.2687 72.976,-45.7782 79.237,-42.6477\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"135\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">C</text>\n",
       "</g>\n",
       "<!-- and&#45;&gt;C -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>and-&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M107.7146,-72.5708C111.9597,-64.0807 117.1536,-53.6929 121.8663,-44.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"125.024,-45.7782 126.3657,-35.2687 118.763,-42.6477 125.024,-45.7782\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "show_svg('shared_term_graph.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we realized that A,C is a joint component and that we need only compute it once.\n",
    "This would be the automatic equivalent of a smart programmer, refactoring the query above to look like\n",
    "\n",
    "```\n",
    ">>> TEMP(X,Y,Z) <- A(X), C(X,Y,Z)\n",
    ">>> D(X,Y) <- B(Y),TEMP(X,Y,Z)\n",
    ">>> E(X,Y) <- TEMP(X,Y,Z), F(Z)\n",
    ">>> x(X,Y) <- E(X,Y)\n",
    ">>> x(X,Y) <- D(X,Y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a pseudo implementation of this pass: \n",
    "```\n",
    "1. get all the registered rules by using term_graph.get_all_rules).\n",
    "\n",
    "2. find overlapping structure between rules (this step can be implemented in many different ways).\n",
    "\n",
    "3. create new rule that consists of the overlapping structure.\n",
    "\n",
    "4. add this new rule to the term graph by using term_graph.add_rule_to_term_graph.\n",
    "\n",
    "5. updated the previous rule to use the newly created rule.\n",
    "\n",
    "6. added the rules to the term graph.\n",
    "\n",
    "7. delete the previous versions of the rule from the term graph by using term_graph.remove_rule.\n",
    "```\n",
    "\n",
    "For example, \n",
    "if the following rules were registered:\n",
    "1. ```D(X,Y) <- A(X),B(Y),C(X,Y,Z)```\n",
    "2. ```E(X,Y) <- A(X),C(X,Y,Z), F(Z)```\n",
    "\n",
    "In the second step of the algorithm, we will find that both rules share the structure ```A(X),C(X,Y,Z)```.<br>\n",
    "In the third step we will create a new relation ```TEMP(X,Y,Z) <- A(X), C(X,Y,Z)```, and add it to the term graph.<br>\n",
    "In the fifth step we will modify to original rules in the following way:\n",
    "1. ```D(X,Y) <- B(Y),TEMP(X,Y,Z)```\n",
    "2. ```E(X,Y) <- TEMP(X,Y,Z), F(Z)```\n",
    "\n",
    "And then we will add them to the term graph.<br>\n",
    "The last step will delete the old rules from the term graph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
