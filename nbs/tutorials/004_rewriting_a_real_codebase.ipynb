{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewriting a real code base\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tutorials.covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from IPython.display import display, HTML\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Introduction:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial, we will guide you through the process of refactoring an existing data pipeline into the spannerlib framework, showing the utility of this approach from a software engineering perspective. \n",
    "We will: \n",
    "* Give an overview of the original implementation\n",
    "* Discuss the use case we chose this use case\n",
    "* Show how to analyze which parts of a python codebase should turn into one of the following modalities:\n",
    "  * Relational Data\n",
    "  * Declarative Code\n",
    "  * IE functions (and Aggregation functions)\n",
    "  * Regular python code along side spannerlib\n",
    "* Demonstrate a rewriting of the use-case into spannerlib\n",
    "* Compare between the original and the spannerlib implementations along the following metrics\n",
    "  * lines of code per modality\n",
    "  * Decomposition\n",
    "  * Separation of concerns\n",
    "  * Bug surface area\n",
    "  * Readability\n",
    "  * and Debug-ability\n",
    "  * barriers of entry\n",
    "\n",
    "\n",
    "We've chosen to adapt a medical text classification NLP pipeline, specifically dealing with classifying COVID-19 status from medical transcripts,from the paper [\"A Natural Language Processing System for National\n",
    "COVID-19 Surveillance in the US Department of Veterans Affairs\"](https://aclanthology.org/2020.nlpcovid19-acl.10.pdf) which was published in the [Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020](https://aclanthology.org/volumes/2020.nlpcovid19-acl/). Code for the original implementation is available [here](https://github.com/abchapman93/VA_COVID-19_NLP_BSV/tree/master).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the original implemenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline was implemented using the [spacy] and [medspacy] frameworks, which are libraries build for rule base NLP pipelines.\n",
    "The original pipeline is split into 6 main componenets:\n",
    "\n",
    "- concept tagger: \n",
    "  - Assigns a semantic tags to each Token based on textual patterns that involve regex like patterns, over regular text, POS tags and lemmas.\n",
    "- target matcher:\n",
    "  - Assigns higher level tags to entities and covid 19 mentions based on patterns over the semantic tags from the previous versions\n",
    "- sectionizer:\n",
    "  - Segments the text into different sections found commonly in medical report, and differentiate between relevant and non relevant sections\n",
    "- context:\n",
    "  - modifies semantic attributes of entities and covid 19 such as positive status, negation, reference to entities which are not the patient etc\n",
    "  - these modification depends on \n",
    "    - patterns over text and semantic tags found in the same sentence as the entitiy\n",
    "    - the sections that the entity is in\n",
    "- postprocessor: \n",
    "  - Another phase of entity tag modification which was added later on\n",
    "  - Modifications depend on either\n",
    "    - patterns found in the next sentence after the entity\n",
    "    - patterns found on entities which already have specific tags\n",
    "- document classifier: \n",
    "  - assigning each covid mention a classification based on it's associated tags\n",
    "  - assigning each document a label of \"POS\", \"UNK\", or \"NEG\" based on the tags of the covid-19 mentions within it.\n",
    "\n",
    "We will explain about each stage in more details, including code snippets later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we chose this use-case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in giving a fair comparison between a real world NLP pipeline and our approach.\n",
    "This paper represents a real world NLP usecase in the pre-LLM era, which demonstrates how to combine NLP models and business logic via rules.\n",
    "The Code is ~4000 lines of code which is big enough to not be considered a toy example, but is small enough to allow us to present it's decomposition in a timely fashion. \n",
    "\n",
    "Moreover, most of the orchestration logic in this pipeline is done using spacy's compositional SDK. This means that we do not compare ourselves to control flow written in vanilla python, which might be an easy goal to beat, but rather a compositional SDK that is well tuned to this task, making our proof of burden harder. While the usage of a compositional SDK, as opposed to vanilla python in the original implementation, makes the original implementation shorter than it would otherwise have been, most pipeline libraries have a relatively high barrier of entry, and require the user to learn multiple interfaces and classes that are unique to that library. \n",
    "\n",
    "This tradeoff elucidates the power and elegance of spannerlib's use of the relational model explicitly for data modelling. If indeed our implementation will be shorter and simpler, while avoiding the need to learn abstractions found in current compositional libraries, this will mean that our approach sits closer to the pareto frontier on the tradeoff between conciseness and entry barriers.\n",
    "\n",
    "Finally, not all operations in this pipeline can be modelled as IE function and declarative code. Rather than choosing an example that neatly fits our paradigm, we showcase how regular python code can interplay with spannerlib code when only part of a codebase is suitable to refactoring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepdive on the original implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept tagger module defines a collection of rules that can be used to tag certain tokens in the text.\n",
    "A basic rule looks like\n",
    "```python\n",
    "# a basic pattern rule\n",
    "TargetRule( literal=\"coronavirus\", category=\"COVID-19\", pattern=[{\"LOWER\": {\"REGEX\": \"coronavirus|hcov|ncov$\"}}], )\n",
    "```\n",
    "Where `TargetRule` is a medspacy class which maps a given pattern to a tag (ie `COVID-19`)\n",
    "\n",
    "The Target pattern belongs to a spacy specific pattern language, which may include lemma tags, POS tags, group membership and more, and has a non neglible learning cost.\n",
    "\n",
    "Here are some examples of rules that use Lemmas and POS in them:\n",
    "```python\n",
    "# using lemma and group membership\n",
    "TargetRule(\n",
    "        \"results positive\",\n",
    "        \"positive\",\n",
    "        pattern=[\n",
    "            {\"LOWER\": \"results\"},\n",
    "            {\"LEMMA\": \"be\", \"OP\": \"?\"},\n",
    "            {\"LOWER\": {\"IN\": [\"pos\", \"positive\"]}},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# using POS and group membership\n",
    "TargetRule(\n",
    "        \"other experiencer\",\n",
    "        category=\"other_experiencer\",\n",
    "        pattern=[\n",
    "            {\n",
    "                \"POS\": {\"IN\": [\"NOUN\", \"PROPN\", \"PRON\", \"ADJ\"]},\n",
    "                \"LOWER\": {\n",
    "                    \"IN\": [\n",
    "                        \"someone\",\n",
    "                        \"somebody\",\n",
    "                        \"person\",\n",
    "                        \"anyone\",\n",
    "                        \"anybody\",\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "```\n",
    "\n",
    "Thi module contains ~327 lines of code which comprise of only dict of the form  `{tag:[TargetRule]}`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Targer Matcher module defines a collection of target rules that also use the tags defined in the previous module.\n",
    "These 2 modules are seperated since they must run sequentially, unlike rules in each module, which can run in parallel.\n",
    "They use the same `TargetRule`. For example:\n",
    "```python\n",
    "# uses the concept tags 'positive' and 'COVID-19' from the concept tagger\n",
    "TargetRule(\n",
    "            \"<POSITIVE> <COVID-19> unit\",\n",
    "            \"COVID-19\",\n",
    "            pattern=[\n",
    "                {\"_\": {\"concept_tag\": \"positive\"}, \"OP\": \"+\"},\n",
    "                {\"_\": {\"concept_tag\": \"COVID-19\"}, \"OP\": \"+\"},\n",
    "                {\"LOWER\": {\"IN\": [\"unit\", \"floor\"]}},\n",
    "            ],\n",
    "        )\n",
    "```\n",
    "\n",
    "This module contains ~726 lines of code with the same form as the concept matcher `{tag:[TargetRule]}`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectionizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sectionizer module contains a list of `SectionRule` classes which outline which text literals should be taken as starting tokens for a new section.\n",
    "They are used by spacy's pipeline SDK to seperate the documents into different sections and subsequently work on the sections separately.\n",
    "For example:\n",
    "```python\n",
    "# section rules that describe possible starting tokens for the imaging sections\n",
    "    SectionRule(category=\"imaging\", literal=\"IMAGING:\"),\n",
    "    SectionRule(category=\"imaging\", literal=\"INTERPRETATION:\"),\n",
    "    SectionRule(category=\"imaging\", literal=\"Imaging:\"),\n",
    "    SectionRule(category=\"imaging\", literal=\"MRI:\"),\n",
    "    SectionRule(category=\"imaging\", literal=\"Radiology:\"),\n",
    "```\n",
    "\n",
    "This module contains ~116 lines of code which are just a list of `SectionRule`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context module is in charge of adding tags to entities, depending on what other patterns are found in the same sentence as the covid match.\n",
    "This id done by defining a list of `ConTextRule` classes which outline which pattern to look for, around which existing tags.\n",
    "For example, bellow is a rule that looks for covid mentions that are preceded in the same sentence by \"not detected\". And in such cases adds the tag `NEGATED_EXISTENCE` to the mention.\n",
    "```python\n",
    "ConTextRule(\n",
    "    literal=\"Not Detected\",\n",
    "    category=\"NEGATED_EXISTENCE\",\n",
    "    # direction defines whether to try to match the pattern before or after the entity in question\n",
    "    direction=\"BACKWARD\",\n",
    "    pattern=[\n",
    "        {\"LOWER\": {\"IN\": [\"not\", \"non\"]}},\n",
    "        {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "        {\"TEXT\": \"-\", \"OP\": \"?\"},\n",
    "        {\"LOWER\": {\"REGEX\": \"detecte?d\"}},\n",
    "    ],\n",
    "    # allowed types defines which entities to apply the context search for, based on which tags they have.\n",
    "    # in this case we only try to match these patterns around COVID-19 mentions.\n",
    "    allowed_types={\"COVID-19\"},\n",
    "),\n",
    "```\n",
    "`ConTextRules` also allow to define callbacks that will run on matches to further filter them, in cases where the pattern logic is not sufficient.\n",
    "In this example, a callback function defined by the authors of the code is run on the matches, and removes them if they dont fit more nuanced criteria.\n",
    "```python\n",
    "ConTextRule(\n",
    "    \"active for\",\n",
    "    \"DEFINITE_POSITIVE_EXISTENCE\",\n",
    "    direction=\"FORWARD\",\n",
    "    pattern=[{\"LOWER\": \"active\"}, {\"LOWER\": \"for\", \"OP\": \"?\"}],\n",
    "    allowed_types={\"COVID-19\"},\n",
    "    max_scope=2,\n",
    "    on_match=callbacks.disambiguate_active,\n",
    ")\n",
    "```\n",
    "\n",
    "This module contains ~2370 lines of code comprise of a list of `ConTextRules` and ~208 lines of callback functions that are used in some of the rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PostProccessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module does changes the tags of some entities depending on custom logic, that cannot be addressed by the spacy ecosystem.\n",
    "spacy does allow to add this custom logic using a nested strucutre of `PostprocessingRule` and `Postprocessing` pattern.\n",
    "For example, the following remove a coronavirus entity if 'denies' and 'contact' are in the same sentence as the entity.\n",
    "```python\n",
    "PostprocessingRule(\n",
    "        patterns=[\n",
    "            PostprocessingPattern(lambda ent: ent.label_ == \"COVID-19\"),\n",
    "            PostprocessingPattern(\n",
    "                postprocessing_functions.sentence_contains,\n",
    "                condition_args=({\"deny\", \"denies\", \"denied\"},),\n",
    "            ),\n",
    "            PostprocessingPattern(\n",
    "                postprocessing_functions.sentence_contains,\n",
    "                condition_args=({\"contact\", \"contacts\", \"confirmed\"},),\n",
    "            ),\n",
    "        \\],\n",
    "        action=postprocessing_functions.remove_ent,\n",
    "    )\n",
    "```\n",
    "Based on our analysis of the code, the postprocessing rules, together with their custom logic, come in 3 flavors:\n",
    "* rules that are based on sentence context alone\n",
    "  * these are similar to the context rules, like the example shown above.\n",
    "* rules based on the context of the sentence after the entity\n",
    "* rules based on the context of the sentece and of other tags given to the entity in previous matches.\n",
    "\n",
    "Here are examples of the latter two flavors:\n",
    "\n",
    "```python\n",
    "# if the covid mention was previously tagged with DEFINITE_POSITIVE_EXISTENCE but the sentence contains words like \"should\"\n",
    "# then we tag the mention as uncertain.\n",
    "PostprocessingRule(\n",
    "    patterns=[\n",
    "        PostprocessingPattern(lambda ent: ent.label_ == \"COVID-19\"),\n",
    "        PostprocessingPattern(\n",
    "            postprocessing_functions.is_modified_by_category,\n",
    "            condition_args=(\"DEFINITE_POSITIVE_EXISTENCE\",),\n",
    "        ),\n",
    "        PostprocessingPattern(\n",
    "            postprocessing_functions.sentence_contains,\n",
    "            condition_args=(\n",
    "                {\n",
    "                    \"should\",\n",
    "                    \"unless\",\n",
    "                    \"either\",\n",
    "                    \"if comes back\",\n",
    "                    \"if returns\",\n",
    "                    \"if s?he tests positive\",\n",
    "                },\n",
    "                True,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    action=set_is_uncertain,\n",
    "    action_args=(True,),\n",
    ")\n",
    "# If a test does not have any results within the same sentence, check the next sentence.\n",
    "PostprocessingRule(\n",
    "    patterns=[\n",
    "        PostprocessingPattern(lambda ent: ent.label_ == \"COVID-19\"),\n",
    "        PostprocessingPattern(\n",
    "            postprocessing_functions.is_modified_by_category,\n",
    "            condition_args=(\"test\",),\n",
    "        ),\n",
    "        PostprocessingPattern(has_positive, success_value=False),\n",
    "        (\n",
    "            PostprocessingPattern(\n",
    "                next_sentence_contains,\n",
    "                condition_args=(\"results? (are|is) positive\",),\n",
    "            ),\n",
    "            PostprocessingPattern(\n",
    "                next_sentence_contains, condition_args=(\"results pos[^s]\",)\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    action=set_is_positive,\n",
    "    action_args=(True,),\n",
    ")\n",
    "```\n",
    "\n",
    "This module has ~364 lines of `PostProcessingRule` definitions and ~84 lines of custom logic python functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document classifier\n",
    "This module classifies the document based on the tags given to covid mentions.\n",
    "It is comprised out of ~77 lines of vanilla python code.\n",
    "\n",
    "### Additional code\n",
    "\n",
    "There are ~270 more lines of code that are comprised of the main pipline logic, which loads all the modules and run the pipeline, and some utility functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines of Code overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We purposefully vanilla python code from the different `Rule` classes which act as \"Data as Code\".\n",
    "We will come back to this point in the analysis bellow.\n",
    "\n",
    "| Section             | CodeType             | ~#lines of code |\n",
    "|---------------------|----------------------|-----------------|\n",
    "| Concept Tagger      | `TargetRule`         | 327             |\n",
    "| Target Matcher      | `TargetRule`         | 726             |\n",
    "| Sectionizer         | `SectionRule`        | 116             |\n",
    "| Context             | `ConTextRule`        | 2370            |\n",
    "|                     | Vanilla Python       | 208             |\n",
    "| Post Processing     | `PostProcessingRule` | 364             |\n",
    "|                     | Vanilla Python       | 84              |\n",
    "| Document Classifier | Vanilla Python       | 77              |\n",
    "| Other               | Vanilla Python       | 270             |\n",
    "| **Total**           |                      | 4542            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules for our implemenation and notes on line of code comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our comparison fair, we have some key guidelines for our implementations, and a note on the line of code measures.\n",
    "First, we must note that the lines of code measured above include whitespace or lines with parenthesis that is used to make the code more readable.\n",
    "* We do not format the original code using formatting tools that try to squeeze more logic into more lines since that hurt readability and essentially `hacks` the measure of lines of code.\n",
    "* In our implementation we do not skim on whitespace or comments when it helps readability and count our lines of code including it as well.\n",
    "\n",
    "Some additional guidelines:\n",
    "* We do not use any other libraries other than the libraries used by the original project (such as spacy) and python standard libraries.\n",
    "  * This is done to ensure that we do not \"beat\" the original implementation due to more sophisticated tool use, beyond the spannerlib framework of course.\n",
    "\n",
    "Please also note that while the line of code comparison is the best quantitative analysis we could perform, the true strength of the spannerlib approach doesn't come simply from line of code reduction, but from other software engineering concerns which we will go into bellow.\n",
    "\n",
    "In the step by step implementation, we include some debugging statements and tests to help explain the code.\n",
    "However most of that is not part of the pipeline, in the end to end implementation section we will leave only the actual implementation of the pipeline.\n",
    "To help the reader differentiate, we mark python cells that have code that will carry on to the e2e implementation with the `#| export` tag and spannerlog cells are marked with `{slog_file}` which redirects spannerlog code to a given file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our implementation, step by step implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# importing dependencies\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "from spannerlib import get_magic_session,Session,Span\n",
    "sess = get_magic_session()\n",
    "\n",
    "# ! pip install spacy\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# configurations\n",
    "slog_file = 'covid_logic.pl'\n",
    "input_dir = Path('sample_inputs')\n",
    "data_dir = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding Scope of spannerlib code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to design a conceptual pipeline, or refactor an existing codebase using spannerlib, best practices dictate that we should first start off with several questions to help us understand what parts of our code should turn into spannerlib code:\n",
    "1. What basic computational building blocks do we need?\n",
    "  * This does not include things like:\n",
    "    * compositional control flow\n",
    "    * dataclasses and other OOP hierarchies that are used for data modelling\n",
    "    * Constructs that help manage and inspect program state\n",
    "    * etc ...\n",
    "  * This does include\n",
    "    * low level numerical/textual analysis\n",
    "    * data ingestion from external sources\n",
    "2. What in our code is not strictly data processing? for example:\n",
    "  * statistics and visualizations\n",
    "  * logging or publishing of results\n",
    "  * Getting user input in an interactive system.\n",
    "3. What data processing pipeline cannot, or is not easy to express via our declerative language?\n",
    "  * such as operations that need to extract entire relations at once from other relations, without being able to be mapped to tuple level extractions.\n",
    "  * Or operations that do not fit set semantics and require ordering.\n",
    "  * Operations that do not fit the relational paradigm well, for example graph analytics.\n",
    "    * Note that these points are not a limitation of the spannerlib paradigm but of the very limited declarative language we chose to extend (Datalog).\n",
    "    * The spannerlib approach can be extended to any declarative language, including non relational ones.\n",
    "\n",
    "Like any programming process, you might not get the final answer on the first attempt but these questions help narrow down the design space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the basic computational building blocks are:\n",
    "1. basic textual analysis tools like pattern matching and splitting of text\n",
    "  * Available through the spannerlib's std library\n",
    "  * Some primitive NLP tasks such as:\n",
    "    * sentence boundary detection\n",
    "    * POS tagging\n",
    "    * Lemmatization\n",
    "2. This is strictly a text processing pipeline, so there are no statistics etc involved\n",
    "3. There is no obvious operation that do not fit, but as we will see once we do our data modelling, there are operations that do not fit Spannerlog.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our ie functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this analysis, we can already start building our IE functions. \n",
    "* We will use regex based ie functions form the standard library\n",
    "  * `rgx` for pattern matching\n",
    "  * `rgx_split` for splitting text based on delimeter patterns\n",
    "* We will implement using spacy\n",
    "  * POS extraction\n",
    "  * LEMMA extraction\n",
    "  * Sentence boundary detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def split_sentence(text):\n",
    "    \"\"\"\n",
    "    Splits a text into individual sentences. using spacy's sentence detection.\n",
    "    \n",
    "    Returns:\n",
    "        str: Individual sentences extracted from the input text.\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(str(text))\n",
    "    start = 0\n",
    "    for sentence in doc.sents:\n",
    "        end = start+len(sentence.text)\n",
    "        # note that we yield a Span object, so we can keep track of the locations of the sentences\n",
    "        yield Span(text,start,end)\n",
    "        start = end + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (input_dir/'sample1.txt').read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[@a6c01c,0,43) \"Patient pr...\",\n",
       " [@a6c01c,44,100) \"His wife r...\",\n",
       " [@a6c01c,101,139) \"SARS-COV-2...\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert list(split_sentence(text)) == ['Patient presents to be tested for COVID-19.',\n",
    " 'His wife recently tested positive for novel coronavirus.',\n",
    " 'SARS-COV-2 results came back positive.']\n",
    "list(split_sentence(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for both Lemmas and POS, the original pipeline is only interested in a very small subsets of lemmas and POS.\n",
    "We could take two approaches here:\n",
    "1. Generate all POS and Lemmas and filter them declaratively\n",
    "2. Configure our extractors to only extract the information we know we may want.\n",
    "\n",
    "Since our `rgx` functions output all relevant matches as Spans, we will demonstrate the second approach here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LemmaFromList():\n",
    "    def __init__(self,lemma_list):\n",
    "        self.lemma_list = lemma_list\n",
    "\n",
    "    def __call__(self,text):\n",
    "        doc = nlp(str(text))\n",
    "        for word in doc:\n",
    "            start = word.idx\n",
    "            end = start + len(word.text)\n",
    "            if word.lemma_ in self.lemma_list:\n",
    "                yield (Span(text,start,end),word.lemma_)\n",
    "            elif word.like_num:\n",
    "                yield (Span(text,start,end),'like_num')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "lemma_list = (data_dir/'lemma_words.txt').read_text().split()\n",
    "lemmatizer = LemmaFromList(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(lemmatizer('the boy was sick')) == [(\"was\",\"be\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PosFromList():\n",
    "    def __init__(self,pos_list):\n",
    "        self.pos_list = pos_list\n",
    "    def __call__(self,text):\n",
    "        doc = nlp(str(text))\n",
    "        for word in doc:\n",
    "            start = word.idx\n",
    "            end = start + len(word.text)\n",
    "            if word.pos_ in self.pos_list:\n",
    "                yield (Span(text,start,end),word.pos_)\n",
    "\n",
    "pos_annotator = PosFromList([\"NOUN\", \"PROPN\", \"PRON\", \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([@01e12d,0,4) \"sick\", 'ADJ'), ([@01e12d,5,8) \"boy\", 'NOUN')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert list(pos_annotator('sick boy')) == [('sick','ADJ'),('boy','NOUN')]\n",
    "list(pos_annotator('sick boy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "sess.register('split_sentence',split_sentence,[(str,Span)],[Span])\n",
    "sess.register('pos',pos_annotator,[(Span,str)],[Span,str])\n",
    "sess.register('lemma',lemmatizer,[(Span,str)],[Span,str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an idea of the building blocks we would have at our disposal. Once we have that, the next thing we need to think about it how we will model our data.\n",
    "Specifically, we can ask four guiding questions:\n",
    "1. How do we get our input data, is it relational or close to it?\n",
    "2. What does our output data look like, is it relational or close to it?\n",
    "3. What parts of our code can be turned into data?\n",
    "4. Are there any computations that require, or are currently based on data models that are not relational?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the answer to the first 3 question are pretty simple:\n",
    "1. We get a directory of text files, we can model that as a (path,text) relation.\n",
    "2. We want a classification of files, we can model that as a (path,label) relation.\n",
    "3. All the different `Rule` Data Classes stand a good chance of being convertible to relational data.\n",
    "   * ie `SectionRule`s are labelled text delimeters\n",
    "   * `ContextRule`s seem like they can be turned into regexes or at most serialized and stored as data.\n",
    "\n",
    "However, question number 4 is more tricky.\n",
    "To understand why, please note that while the `pattern` attributes of rules look very similar to regular expressions which work on a character level, spacy's data model works on Word level, and the patterns look not only at the raw text but at token tags, either Lemma, POS or tags defined by the user.\n",
    "\n",
    "This poses a little bit of a challenge, and likely stems from the fact that this solution was built using spacy in an ad-hoc manner.\n",
    "Spannerlib, can work on relations over all pythonic types (though relational modelling using primitives and Spans is recommended). This means that we have 2 approaches we can choose to take:\n",
    "1. We can build based on spacy, a word level, tag aware regex pattern matcher\n",
    "   * this could be cool but would basically be rebuilding parts of spacy, which would overfit to the current implementatio and is a classical example of the [XY fallacy](https://en.wikipedia.org/wiki/XY_problem) in code redesign.\n",
    "2. See if we can remodel this problem using classical textual information extraction ideas.\n",
    "\n",
    "Unsurprisingly, we will choose the second approach, even though it will cause us to have some computations that are not supported by Spannerlog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A detour into text rewrtting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand our approach, we must first note that the sequential nature of this pipeline, like many other NLP pipelines, means that we extract tags of entities using patterns, and then reduce our natural language problem to a problem over the tags and not the original text. For example, after normalizing `sars COV 2` and `novel corona virus` to `COVID-19`, we do not care what the original form of the tag was, we can simply continue analyzing the text as if `COVID-19` was there all along.\n",
    "\n",
    "This aspect of our pipeline leads us to a well known pattern of \"text rewriting\". In this pattern, we have several phases of span/tag extractions, which are then used to rewrite the original text to a simplified form, followed by possible other rewriting iterations, before the final text form in generated for mining.\n",
    "\n",
    "However, we must note that text rewriting does not fit the limitation of Spannerlog for several reasons:\n",
    "* text rewriting at its most basic takes an original text, and a table of `(from,to)` pairs and generating a new text.\n",
    "  * This means that rewriting requires the context of an entire table to perform, which does not fit the `tuple->relation` paradigm of datalog\n",
    "* rewriting the text as a string requires sorting of the `from` spans\n",
    "\n",
    "Does this, mean that our attempted refactoring a failure?\n",
    "Of course not :)\n",
    "\n",
    "As per the spannerlib framework, the bi directional interaction between Spannerlog and regular python code does not need to be done in a single iteration.\n",
    "What we need is to simply stratify our pipeline and our documents into different versions, and interleave rewritting of new versions with information extraction of tags from the previous version. To do this we need to implement some rewriting logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rewrite(text,span_label_pairs):\n",
    "    \"\"\"rewrites a string given a dataframe with spans and the string to rewrite them to\n",
    "    assumes that the spans belong to the text\n",
    "\n",
    "    Args:\n",
    "        text (str like): string to rewrite\n",
    "        span_label_pairs (pd.Dataframe) dataframe with two columns, first is spans in the doc to rewrite\n",
    "            second is what to rewrite to\n",
    "    Returns:\n",
    "        The rewritten string\n",
    "    \"\"\"    \n",
    "    if isinstance(text,Span):\n",
    "        text = text.as_str()\n",
    "    span_label_pairs = sorted(list(span_label_pairs.itertuples(index=False,name=None)), key=lambda x: x[0].start)\n",
    "\n",
    "    rewritten_text = ''\n",
    "    current_pos = 0\n",
    "    for span,label in span_label_pairs:\n",
    "        rewritten_text += text[current_pos:span.start] + label \n",
    "        current_pos = span.end\n",
    "\n",
    "    rewritten_text += text[current_pos:]\n",
    "\n",
    "    return rewritten_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[@6a488f,8,11) \"was\"</td>\n",
       "      <td>'be'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0     1\n",
       "0  [@6a488f,8,11) \"was\"  'be'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = 'the boy was sick'\n",
    "replace_span_with = pd.DataFrame(lemmatizer(text))\n",
    "display(replace_span_with.map(repr))\n",
    "res = rewrite(text,replace_span_with) \n",
    "assert res == 'the boy be sick' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[@doc,18,21) \"old\"</td>\n",
       "      <td>'young'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@doc,22,28) \"friend\"</td>\n",
       "      <td>'nemesis'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0          1\n",
       "0     [@doc,18,21) \"old\"    'young'\n",
       "1  [@doc,22,28) \"friend\"  'nemesis'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Span('hello darkness my old friend, I come ...',name='doc')\n",
    "spans_to_replace = pd.DataFrame([\n",
    "    [doc.slice(18,21),'young'],\n",
    "    [doc.slice(22,28),'nemesis'],\n",
    "])\n",
    "spans_to_replace.map(repr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello darkness my young nemesis, I come ...'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewritten_doc=rewrite(doc,spans_to_replace)\n",
    "assert rewritten_doc == 'hello darkness my young nemesis, I come ...'\n",
    "rewritten_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rewrite_docs(docs,span_label,new_version):\n",
    "    \"\"\"Given a dataframe of documents of the form (path,doc,version) and a dataframe of spans to rewrite\n",
    "    of the form (path,word,from_span,to_tag), rewrites the documents and returns a new dataframe of the form\n",
    "    (path,doc,new_version)\n",
    "\n",
    "    \"\"\"\n",
    "    new_tuples =[]\n",
    "    span_label.columns = ['P','D','W','L']\n",
    "    for path,doc,_ in docs.itertuples(index=False,name=None):\n",
    "        span_label_per_doc = span_label[span_label['P'] == path][['W','L']]\n",
    "        new_text = rewrite(doc,span_label_per_doc)\n",
    "        new_tuples.append((path,new_text,new_version))\n",
    "    return pd.DataFrame(new_tuples,columns=['P','D','V'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming data modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after resolving the matter of patten matching on tags, we can model our documents and rules as follows:\n",
    "* Documents will be modelled by  `Docs(Path,Text,Version)`\n",
    "* Concept Tagger Rules will be modelled by `ConceptTagRules(pattern,tag,textVersion)`\n",
    "  * where the version is either `lemma` or `POS` for lemma and pos based pattern respectively (there are no patterns that require both)\n",
    "* Target Matcher Rules will be modelled by `TargetTagRules(pattern,tag)`\n",
    "* Section delimiters and section relevancy will be modelled by `SectionTags(Pattern,Tag)` and `PositiveSectionTags(Tag)`.\n",
    "* Context Rules will be modelled by `SentenceContextRules(pattern,tag)`\n",
    "\n",
    "As for PostprocessRules, the 3 different flavors can be modelled differently\n",
    "* rules based on sentence context alone are modelled by `PostprocessPatternRules(pattern,tag)`\n",
    "* rules based on sentence context and existing tags are modelled by `PostprocessRulesWithAttributes(pattern,old_tag,new_tag)`\n",
    "  * where instead of removing a mention or deleting a tag, which is not something you can or want to do declaratively, we will simply add a new tag whose semantic is to disregard the mention or the old tag.\n",
    "* rules based on the next sentence are modelled by `NextSentencePostprocessPatternRules(pattern,tag)`\n",
    "\n",
    "All patterns mentioned above are regex patterns using python's regex flavour.\n",
    "\n",
    "#### A note on data modelling and schema design\n",
    "The same operations we know and love from relational schema design, such as schema normalization and schema merging etc can be applied to data modelling in the spannerlib framework.\n",
    "For example, we could have, to limit the number of Postprocessing Rule relations, merged their schema by adding an `ANY` tag that matches any pattern and changing building a single relation of the form `ProsProcessRule(pattern,old_tag,new_tag,is_next_sentence)`. This would have lead to less relations and less Spannerlog rules, but the remaining rules would have been slightly more complex. Such tradeoffs are analogous to tradeoffs, in regular code design, between amount, length and complexity of functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "sess.import_rel(\"ConceptTagRules\",data_dir/\"concept_tags_rules.csv\" , delim=\",\")\n",
    "sess.import_rel(\"TargetTagRules\",data_dir/\"target_rules.csv\",delim=\",\")\n",
    "sess.import_rel(\"SectionTags\",data_dir/\"section_tags.csv\",delim=\",\")\n",
    "sess.import_rel(\"PositiveSectionTags\",data_dir/\"positive_section_tags.csv\",delim=\",\")\n",
    "sess.import_rel(\"SentenceContextRules\",data_dir/'sentence_context_rules.csv',delim=\"#\")\n",
    "sess.import_rel(\"PostprocessPatternRules\",data_dir/'postprocess_pattern_rules.csv',delim=\"#\")\n",
    "sess.import_rel(\"PostprocessRulesWithAttributes\",data_dir/'postprocess_attributes_rules.csv',delim=\"#\")\n",
    "sess.import_rel(\"NextSentencePostprocessPatternRules\",data_dir/'postprocess_pattern_next_sentence_rules.csv',delim=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the rule files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?ConceptTagRules(Pattern,Tag,TextType)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "      <th>TextType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'(?i)(?:(?:229(?:e)?|oc(?:-)?(?:43)?|o43|0c43|...</td>\n",
       "      <td>'OTHER_CORONAVIRUS'</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'(?i)(?:(?:antibody|antibodies|ab) test)'</td>\n",
       "      <td>'antibody test'</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'(?i)(?:(?:coronavirus|hcovs?|ncovs?|covs?)(?:...</td>\n",
       "      <td>'OTHER_CORONAVIRUS'</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'(?i)(?:(?:diagnos(?:is|ed)|dx(?:\\\\.)?)(?:of|w...</td>\n",
       "      <td>'diagnosis'</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'(?i)(?:\\\\+(?: ve)?|\\\\(\\\\+\\\\)|positive|\\\\bpos\\...</td>\n",
       "      <td>'positive'</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'(?i)(?:patient|pt(?:\\\\.)?|vt|veteran)'</td>\n",
       "      <td>'patient'</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'(?i)(?:pneum(?:onia)?|pna|hypoxia|septic shoc...</td>\n",
       "      <td>'associated_diagnosis'</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'(?i)(?:resident|pts|patients|coworker|coworke...</td>\n",
       "      <td>'other_experiencer'</td>\n",
       "      <td>'pos'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'(?i)(?:someone|somebody|person|anyone|anybody...</td>\n",
       "      <td>'other_experiencer'</td>\n",
       "      <td>'pos'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'(?i)(?:wife|husband|spouse|family|member|girl...</td>\n",
       "      <td>'family'</td>\n",
       "      <td>'pos'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Pattern                     Tag  \\\n",
       "0   '(?i)(?:(?:229(?:e)?|oc(?:-)?(?:43)?|o43|0c43|...     'OTHER_CORONAVIRUS'   \n",
       "1           '(?i)(?:(?:antibody|antibodies|ab) test)'         'antibody test'   \n",
       "2   '(?i)(?:(?:coronavirus|hcovs?|ncovs?|covs?)(?:...     'OTHER_CORONAVIRUS'   \n",
       "3   '(?i)(?:(?:diagnos(?:is|ed)|dx(?:\\\\.)?)(?:of|w...             'diagnosis'   \n",
       "4   '(?i)(?:\\\\+(?: ve)?|\\\\(\\\\+\\\\)|positive|\\\\bpos\\...              'positive'   \n",
       "..                                                ...                     ...   \n",
       "14            '(?i)(?:patient|pt(?:\\\\.)?|vt|veteran)'               'patient'   \n",
       "15  '(?i)(?:pneum(?:onia)?|pna|hypoxia|septic shoc...  'associated_diagnosis'   \n",
       "16  '(?i)(?:resident|pts|patients|coworker|coworke...     'other_experiencer'   \n",
       "17  '(?i)(?:someone|somebody|person|anyone|anybody...     'other_experiencer'   \n",
       "18  '(?i)(?:wife|husband|spouse|family|member|girl...                'family'   \n",
       "\n",
       "   TextType  \n",
       "0   'lemma'  \n",
       "1   'lemma'  \n",
       "2   'lemma'  \n",
       "3   'lemma'  \n",
       "4   'lemma'  \n",
       "..      ...  \n",
       "14  'lemma'  \n",
       "15  'lemma'  \n",
       "16    'pos'  \n",
       "17    'pos'  \n",
       "18    'pos'  \n",
       "\n",
       "[19 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?TargetTagRules(Pattern,Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'(?i)((?:person|patient) with confirm COVID-19)'</td>\n",
       "      <td>'1 2 3 4'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'(?i)(?:(?:(?:contact|exposure) (?:with|to)? )...</td>\n",
       "      <td>'OTHER_PERSON'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'(?i)(?:(?:patient|person) (?:who|that) test (...</td>\n",
       "      <td>'OTHER_PERSON'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'(?i)(?:COVID-19 (?:restriction|emergency|epid...</td>\n",
       "      <td>'1 2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'(?i)(?:COVID-19 positive (?:patient|person|pe...</td>\n",
       "      <td>'OTHER_PERSON'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'(?i)(?:in order to decrease the spread of the...</td>\n",
       "      <td>'1 2 3 4 5 6 7 8 9 10'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'(?i)(?:known(?: positive)? COVID-19(?: positi...</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'(?i)(?:positive COVID-19 (?:tested )?other_ex...</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'(?i)(?:results confirm|(?:neg|pos)\\\\S+ pressu...</td>\n",
       "      <td>'1 2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'(?i)(ref : not detected|history of present il...</td>\n",
       "      <td>'&lt;IGNORE&gt;'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Pattern                     Tag\n",
       "0    '(?i)((?:person|patient) with confirm COVID-19)'               '1 2 3 4'\n",
       "1   '(?i)(?:(?:(?:contact|exposure) (?:with|to)? )...          'OTHER_PERSON'\n",
       "2   '(?i)(?:(?:patient|person) (?:who|that) test (...          'OTHER_PERSON'\n",
       "3   '(?i)(?:COVID-19 (?:restriction|emergency|epid...                   '1 2'\n",
       "4   '(?i)(?:COVID-19 positive (?:patient|person|pe...          'OTHER_PERSON'\n",
       "..                                                ...                     ...\n",
       "15  '(?i)(?:in order to decrease the spread of the...  '1 2 3 4 5 6 7 8 9 10'\n",
       "16  '(?i)(?:known(?: positive)? COVID-19(?: positi...              'COVID-19'\n",
       "17  '(?i)(?:positive COVID-19 (?:tested )?other_ex...              'COVID-19'\n",
       "18  '(?i)(?:results confirm|(?:neg|pos)\\\\S+ pressu...                   '1 2'\n",
       "19  '(?i)(ref : not detected|history of present il...              '<IGNORE>'\n",
       "\n",
       "[20 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?SectionTags(Pattern,Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'A/P:'</td>\n",
       "      <td>'observation_and_plan'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'ACTIVE MEDICATIONS LIST:'</td>\n",
       "      <td>'medications'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'ACTIVE MEDICATIONS:'</td>\n",
       "      <td>'medications'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'ADDENDUM:'</td>\n",
       "      <td>'addendum'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'ADMISSION DIAGNOSES:'</td>\n",
       "      <td>'diagnoses'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>'Sexual History:'</td>\n",
       "      <td>'social_history'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>'Signed electronically by:'</td>\n",
       "      <td>'signature'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>'Social History:'</td>\n",
       "      <td>'social_history'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>'Studies:'</td>\n",
       "      <td>'labs_and_studies'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>'UNDERLYING MEDICAL CONDITION:'</td>\n",
       "      <td>'past_medical_history'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Pattern                     Tag\n",
       "0                             'A/P:'  'observation_and_plan'\n",
       "1         'ACTIVE MEDICATIONS LIST:'           'medications'\n",
       "2              'ACTIVE MEDICATIONS:'           'medications'\n",
       "3                        'ADDENDUM:'              'addendum'\n",
       "4             'ADMISSION DIAGNOSES:'             'diagnoses'\n",
       "..                               ...                     ...\n",
       "105                'Sexual History:'        'social_history'\n",
       "106      'Signed electronically by:'             'signature'\n",
       "107                'Social History:'        'social_history'\n",
       "108                       'Studies:'      'labs_and_studies'\n",
       "109  'UNDERLYING MEDICAL CONDITION:'  'past_medical_history'\n",
       "\n",
       "[110 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?PositiveSectionTags(Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'diagnoses'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'observation_and_plan'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'past_medical_history'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'problem_list'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Tag\n",
       "0             'diagnoses'\n",
       "1  'observation_and_plan'\n",
       "2  'past_medical_history'\n",
       "3          'problem_list'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?SentenceContextRules(Pattern,Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'(?i)(?:(?:(?:(?:-)?hx|history|) of)(?: (?!&lt;IG...</td>\n",
       "      <td>'negated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'(?i)(?:(?:(?:area|county|community|city) (?:w...</td>\n",
       "      <td>'negated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'(?i)(?:(?:(?:he|she) thinks (?:he|she) (?:hav...</td>\n",
       "      <td>'negated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'(?i)(?:(?:(?:in|to) (?:the )(?:hospital|icu|m...</td>\n",
       "      <td>'admission'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'(?i)(?:(?:(?:limit|reduce|lower|minimize)(?: ...</td>\n",
       "      <td>'future'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>'(?i)(?:resp(?:iratory) failure(?:(?: (?:with|...</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>'(?i)(?:results positive(?: (?!&lt;IGNORE&gt;)\\\\S+){...</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>'(?i)(?:screen\\\\S*(?: (?!&lt;IGNORE&gt;)\\\\S+){0,9} C...</td>\n",
       "      <td>'screening'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>'(?i)(?:the (?:veteran|vet|patient) have(?: (?...</td>\n",
       "      <td>'patient_experiencer'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>'(?i)(?:without any(?: (?!&lt;IGNORE&gt;)\\\\S+){0,1} ...</td>\n",
       "      <td>'negated'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Pattern                    Tag\n",
       "0    '(?i)(?:(?:(?:(?:-)?hx|history|) of)(?: (?!<IG...              'negated'\n",
       "1    '(?i)(?:(?:(?:area|county|community|city) (?:w...              'negated'\n",
       "2    '(?i)(?:(?:(?:he|she) thinks (?:he|she) (?:hav...              'negated'\n",
       "3    '(?i)(?:(?:(?:in|to) (?:the )(?:hospital|icu|m...            'admission'\n",
       "4    '(?i)(?:(?:(?:limit|reduce|lower|minimize)(?: ...               'future'\n",
       "..                                                 ...                    ...\n",
       "166  '(?i)(?:resp(?:iratory) failure(?:(?: (?:with|...             'positive'\n",
       "167  '(?i)(?:results positive(?: (?!<IGNORE>)\\\\S+){...             'positive'\n",
       "168  '(?i)(?:screen\\\\S*(?: (?!<IGNORE>)\\\\S+){0,9} C...            'screening'\n",
       "169  '(?i)(?:the (?:veteran|vet|patient) have(?: (?...  'patient_experiencer'\n",
       "170  '(?i)(?:without any(?: (?!<IGNORE>)\\\\S+){0,1} ...              'negated'\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?PostprocessPatternRules(Pattern,Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'(?=.*\\\\b(?:deny|denies|denied)\\\\b)(?=.*\\\\b(?:...</td>\n",
       "      <td>'IGNORE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'(?=.*\\\\b(?:setting of|s/o)\\\\b)(?!.*\\\\b(?:COVI...</td>\n",
       "      <td>'no_positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'(?i)(.*benign.*)'</td>\n",
       "      <td>'uncertain'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'.* \\\\?'</td>\n",
       "      <td>'IGNORE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'.*education.*'</td>\n",
       "      <td>'IGNORE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'admitted to COVID-19 unit'</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pattern            Tag\n",
       "0  '(?=.*\\\\b(?:deny|denies|denied)\\\\b)(?=.*\\\\b(?:...       'IGNORE'\n",
       "1  '(?=.*\\\\b(?:setting of|s/o)\\\\b)(?!.*\\\\b(?:COVI...  'no_positive'\n",
       "2                                 '(?i)(.*benign.*)'    'uncertain'\n",
       "3                                           '.* \\\\?'       'IGNORE'\n",
       "4                                    '.*education.*'       'IGNORE'\n",
       "5                        'admitted to COVID-19 unit'     'positive'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?PostprocessRulesWithAttributes(Pattern,Old_Tag,New_Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Old_Tag</th>\n",
       "      <th>New_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'.*(?:re[ -]?test|second test|repeat).*'</td>\n",
       "      <td>'negated'</td>\n",
       "      <td>'no_negated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'.*(?:should|unless|either|if comes back|if re...</td>\n",
       "      <td>'positive'</td>\n",
       "      <td>'uncertain'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'.*(?:sign|symptom|s/s).*'</td>\n",
       "      <td>'positive'</td>\n",
       "      <td>'uncertain'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'.*pending.*'</td>\n",
       "      <td>'negated'</td>\n",
       "      <td>'no_negated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'.*precaution.*'</td>\n",
       "      <td>'positive'</td>\n",
       "      <td>'no_future'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pattern     Old_Tag       New_Tag\n",
       "0           '.*(?:re[ -]?test|second test|repeat).*'   'negated'  'no_negated'\n",
       "1  '.*(?:should|unless|either|if comes back|if re...  'positive'   'uncertain'\n",
       "2                         '.*(?:sign|symptom|s/s).*'  'positive'   'uncertain'\n",
       "3                                      '.*pending.*'   'negated'  'no_negated'\n",
       "4                                   '.*precaution.*'  'positive'   'no_future'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?NextSentencePostprocessPatternRules(Pattern,Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'(?i)(?:^(?:positive|detected)|results?(?: be)...</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pattern         Tag\n",
       "0  '(?i)(?:^(?:positive|detected)|results?(?: be)...  'positive'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog\n",
    "?ConceptTagRules(Pattern,Tag,TextType)\n",
    "?TargetTagRules(Pattern,Tag)\n",
    "?SectionTags(Pattern,Tag)\n",
    "?PositiveSectionTags(Tag)\n",
    "?SentenceContextRules(Pattern,Tag)\n",
    "?PostprocessPatternRules(Pattern,Tag)\n",
    "?PostprocessRulesWithAttributes(Pattern,Old_Tag,New_Tag)\n",
    "?NextSentencePostprocessPatternRules(Pattern,Tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample10.txt</td>\n",
       "      <td>patient was screened for cov-19. results came ...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample8.txt</td>\n",
       "      <td>Patient was sent for a covid test. Someone was...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample9.txt</td>\n",
       "      <td>Patient had contact patient with coronavirus. ...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample7.txt</td>\n",
       "      <td>Elevated cholesterol levels require further as...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample6.txt</td>\n",
       "      <td>The patient have reported novel coronavirus.</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample4.txt</td>\n",
       "      <td>neg covid education.</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample5.txt</td>\n",
       "      <td>positive covid precaution.</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample1.txt</td>\n",
       "      <td>Patient presents to be tested for COVID-19. Hi...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample2.txt</td>\n",
       "      <td>The patient was tested for Coronavirus 2019. R...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample3.txt</td>\n",
       "      <td>Problem List: 1. Pneumonia 2. Novel Coronaviru...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Path                                                Doc   Version\n",
       "0  sample10.txt  patient was screened for cov-19. results came ...  raw_text\n",
       "1   sample8.txt  Patient was sent for a covid test. Someone was...  raw_text\n",
       "2   sample9.txt  Patient had contact patient with coronavirus. ...  raw_text\n",
       "3   sample7.txt  Elevated cholesterol levels require further as...  raw_text\n",
       "4   sample6.txt      The patient have reported novel coronavirus.   raw_text\n",
       "5   sample4.txt                              neg covid education.   raw_text\n",
       "6   sample5.txt                         positive covid precaution.  raw_text\n",
       "7   sample1.txt  Patient presents to be tested for COVID-19. Hi...  raw_text\n",
       "8   sample2.txt  The patient was tested for Coronavirus 2019. R...  raw_text\n",
       "9   sample3.txt  Problem List: 1. Pneumonia 2. Novel Coronaviru...  raw_text"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "from glob import glob\n",
    "file_paths = [Path(p) for p in glob(str(input_dir/'*.txt'))]\n",
    "raw_docs = pd.DataFrame([\n",
    "    [p.name,p.read_text(),'raw_text'] for p in file_paths\n",
    "],columns=['Path','Doc','Version']\n",
    ")\n",
    "sess.import_rel('Docs',raw_docs)\n",
    "raw_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewriting texts based on tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we need to rewrite our texts multiple times base on:\n",
    "* Lemmas\n",
    "* Lemma concept matches\n",
    "* POS tags \n",
    "* and target matcher tags\n",
    "\n",
    "This section replaces the Concept Matcher and Target Tagger modules in the original implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?Lemmas(P,D,Word,Lem)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'Patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@a6c01c,0,7) \"Patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'Patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@a6c01c,20,22) \"be\"</td>\n",
       "      <td>'be'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>'patient was screened for cov-19. results came...</td>\n",
       "      <td>[@9f417c,0,7) \"patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>'patient was screened for cov-19. results came...</td>\n",
       "      <td>[@9f417c,8,11) \"was\"</td>\n",
       "      <td>'be'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>'The patient was tested for Coronavirus 2019. ...</td>\n",
       "      <td>[@591f89,4,11) \"patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>'Patient was sent for a covid test. Someone wa...</td>\n",
       "      <td>[@aad8ff,8,11) \"was\"</td>\n",
       "      <td>'be'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>'Patient was sent for a covid test. Someone wa...</td>\n",
       "      <td>[@aad8ff,43,46) \"was\"</td>\n",
       "      <td>'be'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient had contact patient with coronavirus....</td>\n",
       "      <td>[@0e1178,8,11) \"had\"</td>\n",
       "      <td>'have'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient had contact patient with coronavirus....</td>\n",
       "      <td>[@0e1178,12,19) \"contact\"</td>\n",
       "      <td>'contact'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient had contact patient with coronavirus....</td>\n",
       "      <td>[@0e1178,20,27) \"patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 P                                                  D  \\\n",
       "0    'sample1.txt'  'Patient presents to be tested for COVID-19. H...   \n",
       "1    'sample1.txt'  'Patient presents to be tested for COVID-19. H...   \n",
       "2   'sample10.txt'  'patient was screened for cov-19. results came...   \n",
       "3   'sample10.txt'  'patient was screened for cov-19. results came...   \n",
       "4    'sample2.txt'  'The patient was tested for Coronavirus 2019. ...   \n",
       "..             ...                                                ...   \n",
       "15   'sample8.txt'  'Patient was sent for a covid test. Someone wa...   \n",
       "16   'sample8.txt'  'Patient was sent for a covid test. Someone wa...   \n",
       "17   'sample9.txt'  'Patient had contact patient with coronavirus....   \n",
       "18   'sample9.txt'  'Patient had contact patient with coronavirus....   \n",
       "19   'sample9.txt'  'Patient had contact patient with coronavirus....   \n",
       "\n",
       "                         Word        Lem  \n",
       "0     [@a6c01c,0,7) \"Patient\"  'patient'  \n",
       "1        [@a6c01c,20,22) \"be\"       'be'  \n",
       "2     [@9f417c,0,7) \"patient\"  'patient'  \n",
       "3        [@9f417c,8,11) \"was\"       'be'  \n",
       "4    [@591f89,4,11) \"patient\"  'patient'  \n",
       "..                        ...        ...  \n",
       "15       [@aad8ff,8,11) \"was\"       'be'  \n",
       "16      [@aad8ff,43,46) \"was\"       'be'  \n",
       "17       [@0e1178,8,11) \"had\"     'have'  \n",
       "18  [@0e1178,12,19) \"contact\"  'contact'  \n",
       "19  [@0e1178,20,27) \"patient\"  'patient'  \n",
       "\n",
       "[20 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -o {slog_file}\n",
    "Lemmas(P,D,Word,Lem)<-Docs(P,D,\"raw_text\"),lemma(D)->(Word,Lem)\n",
    "?Lemmas(P,D,Word,Lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "lemma_tags = sess.export('?Lemmas(P,D,W,L)')\n",
    "lemma_docs = rewrite_docs(raw_docs,lemma_tags,'lemma')\n",
    "sess.import_rel('Docs',lemma_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?Docs(P,D,V)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'Patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>'raw_text'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>'patient be screened for cov-19. results came ...</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>'patient was screened for cov-19. results came...</td>\n",
       "      <td>'raw_text'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>'The patient be tested for Coronavirus like_nu...</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'sample7.txt'</td>\n",
       "      <td>'Elevated cholesterol levels require further a...</td>\n",
       "      <td>'raw_text'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>'Patient be sent for a covid test. Someone be ...</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>'Patient was sent for a covid test. Someone wa...</td>\n",
       "      <td>'raw_text'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient had contact patient with coronavirus....</td>\n",
       "      <td>'raw_text'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient have contact patient with coronavirus...</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 P                                                  D  \\\n",
       "0    'sample1.txt'  'Patient presents to be tested for COVID-19. H...   \n",
       "1    'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "2   'sample10.txt'  'patient be screened for cov-19. results came ...   \n",
       "3   'sample10.txt'  'patient was screened for cov-19. results came...   \n",
       "4    'sample2.txt'  'The patient be tested for Coronavirus like_nu...   \n",
       "..             ...                                                ...   \n",
       "15   'sample7.txt'  'Elevated cholesterol levels require further a...   \n",
       "16   'sample8.txt'  'Patient be sent for a covid test. Someone be ...   \n",
       "17   'sample8.txt'  'Patient was sent for a covid test. Someone wa...   \n",
       "18   'sample9.txt'  'Patient had contact patient with coronavirus....   \n",
       "19   'sample9.txt'  'Patient have contact patient with coronavirus...   \n",
       "\n",
       "             V  \n",
       "0   'raw_text'  \n",
       "1      'lemma'  \n",
       "2      'lemma'  \n",
       "3   'raw_text'  \n",
       "4      'lemma'  \n",
       "..         ...  \n",
       "15  'raw_text'  \n",
       "16     'lemma'  \n",
       "17  'raw_text'  \n",
       "18  'raw_text'  \n",
       "19     'lemma'  \n",
       "\n",
       "[20 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog\n",
    "?Docs(P,D,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?LemmaConceptMatches(Path,Doc,Span,Label)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Span</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,0,7) \"patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,34,42) \"COVID-19\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,69,77) \"positive\"</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,82,99) \"novel coro...\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,101,111) \"SARS-COV-2\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient have contact patient with coronavirus...</td>\n",
       "      <td>[@539a7c,0,7) \"Patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient have contact patient with coronavirus...</td>\n",
       "      <td>[@539a7c,21,28) \"patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient have contact patient with coronavirus...</td>\n",
       "      <td>[@539a7c,34,45) \"coronaviru...\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient have contact patient with coronavirus...</td>\n",
       "      <td>[@539a7c,57,65) \"positive\"</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'Patient have contact patient with coronavirus...</td>\n",
       "      <td>[@539a7c,66,77) \"coronaviru...\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Path                                                Doc  \\\n",
       "0   'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "1   'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "2   'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "3   'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "4   'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "..            ...                                                ...   \n",
       "22  'sample9.txt'  'Patient have contact patient with coronavirus...   \n",
       "23  'sample9.txt'  'Patient have contact patient with coronavirus...   \n",
       "24  'sample9.txt'  'Patient have contact patient with coronavirus...   \n",
       "25  'sample9.txt'  'Patient have contact patient with coronavirus...   \n",
       "26  'sample9.txt'  'Patient have contact patient with coronavirus...   \n",
       "\n",
       "                               Span       Label  \n",
       "0           [@4d073b,0,7) \"patient\"   'patient'  \n",
       "1        [@4d073b,34,42) \"COVID-19\"  'COVID-19'  \n",
       "2        [@4d073b,69,77) \"positive\"  'positive'  \n",
       "3   [@4d073b,82,99) \"novel coro...\"  'COVID-19'  \n",
       "4    [@4d073b,101,111) \"SARS-COV-2\"  'COVID-19'  \n",
       "..                              ...         ...  \n",
       "22          [@539a7c,0,7) \"Patient\"   'patient'  \n",
       "23        [@539a7c,21,28) \"patient\"   'patient'  \n",
       "24  [@539a7c,34,45) \"coronaviru...\"  'COVID-19'  \n",
       "25       [@539a7c,57,65) \"positive\"  'positive'  \n",
       "26  [@539a7c,66,77) \"coronaviru...\"  'COVID-19'  \n",
       "\n",
       "[27 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "LemmaConceptMatches(Path,Doc,Span,Label) <- \\\n",
    "    Docs(Path,Doc,\"lemma\"),\\\n",
    "    ConceptTagRules(Pattern, Label, \"lemma\"),\\\n",
    "    rgx(Pattern,Doc) -> (Span)\n",
    "?LemmaConceptMatches(Path,Doc,Span,Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Span</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,0,7) \"patient\"</td>\n",
       "      <td>'patient'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,34,42) \"COVID-19\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,69,77) \"positive\"</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,82,99) \"novel coro...\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@4d073b,101,111) \"SARS-COV-2\"</td>\n",
       "      <td>'COVID-19'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Path                                                Doc  \\\n",
       "0  'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "1  'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "2  'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "3  'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "4  'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "\n",
       "                              Span       Label  \n",
       "0          [@4d073b,0,7) \"patient\"   'patient'  \n",
       "1       [@4d073b,34,42) \"COVID-19\"  'COVID-19'  \n",
       "2       [@4d073b,69,77) \"positive\"  'positive'  \n",
       "3  [@4d073b,82,99) \"novel coro...\"  'COVID-19'  \n",
       "4   [@4d073b,101,111) \"SARS-COV-2\"  'COVID-19'  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample10.txt</td>\n",
       "      <td>patient be screened for cov-19. results came b...</td>\n",
       "      <td>lemma_concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample8.txt</td>\n",
       "      <td>patient be sent for a COVID-19 test. Someone b...</td>\n",
       "      <td>lemma_concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample9.txt</td>\n",
       "      <td>patient have contact patient with COVID-19. sc...</td>\n",
       "      <td>lemma_concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample7.txt</td>\n",
       "      <td>Elevated cholesterol levels require further as...</td>\n",
       "      <td>lemma_concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample6.txt</td>\n",
       "      <td>The patient have reported COVID-19.</td>\n",
       "      <td>lemma_concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              P                                                  D  \\\n",
       "0  sample10.txt  patient be screened for cov-19. results came b...   \n",
       "1   sample8.txt  patient be sent for a COVID-19 test. Someone b...   \n",
       "2   sample9.txt  patient have contact patient with COVID-19. sc...   \n",
       "3   sample7.txt  Elevated cholesterol levels require further as...   \n",
       "4   sample6.txt               The patient have reported COVID-19.    \n",
       "\n",
       "               V  \n",
       "0  lemma_concept  \n",
       "1  lemma_concept  \n",
       "2  lemma_concept  \n",
       "3  lemma_concept  \n",
       "4  lemma_concept  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "lemma_concept_matches = sess.export('?LemmaConceptMatches(Path,Doc,Span,Label)')\n",
    "display(lemma_concept_matches.map(repr).head())\n",
    "lemma_concepts = rewrite_docs(lemma_docs,lemma_concept_matches,'lemma_concept')\n",
    "sess.import_rel('Docs',lemma_concepts)\n",
    "lemma_concepts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?Docs(\"sample2.txt\",D,V)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'The patient be tested for COVID-19 like_num. ...</td>\n",
       "      <td>'lemma_concept'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'The patient be tested for Coronavirus like_nu...</td>\n",
       "      <td>'lemma'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'The patient was tested for Coronavirus 2019. ...</td>\n",
       "      <td>'raw_text'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   D                V\n",
       "0  'The patient be tested for COVID-19 like_num. ...  'lemma_concept'\n",
       "1  'The patient be tested for Coronavirus like_nu...          'lemma'\n",
       "2  'The patient was tested for Coronavirus 2019. ...       'raw_text'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog\n",
    "?Docs(\"sample2.txt\",D,V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?Pos(\"sample8.txt\",D,Word,Lem)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'patient be sent for a COVID-19 test. Someone ...</td>\n",
       "      <td>[@1edc3c,0,7) \"patient\"</td>\n",
       "      <td>'NOUN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'patient be sent for a COVID-19 test. Someone ...</td>\n",
       "      <td>[@1edc3c,22,30) \"COVID-19\"</td>\n",
       "      <td>'NOUN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'patient be sent for a COVID-19 test. Someone ...</td>\n",
       "      <td>[@1edc3c,31,35) \"test\"</td>\n",
       "      <td>'NOUN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'patient be sent for a COVID-19 test. Someone ...</td>\n",
       "      <td>[@1edc3c,37,44) \"Someone\"</td>\n",
       "      <td>'PRON'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'patient be sent for a COVID-19 test. Someone ...</td>\n",
       "      <td>[@1edc3c,55,63) \"positive\"</td>\n",
       "      <td>'ADJ'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   D  \\\n",
       "0  'patient be sent for a COVID-19 test. Someone ...   \n",
       "1  'patient be sent for a COVID-19 test. Someone ...   \n",
       "2  'patient be sent for a COVID-19 test. Someone ...   \n",
       "3  'patient be sent for a COVID-19 test. Someone ...   \n",
       "4  'patient be sent for a COVID-19 test. Someone ...   \n",
       "\n",
       "                         Word     Lem  \n",
       "0     [@1edc3c,0,7) \"patient\"  'NOUN'  \n",
       "1  [@1edc3c,22,30) \"COVID-19\"  'NOUN'  \n",
       "2      [@1edc3c,31,35) \"test\"  'NOUN'  \n",
       "3   [@1edc3c,37,44) \"Someone\"  'PRON'  \n",
       "4  [@1edc3c,55,63) \"positive\"   'ADJ'  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "# here we get the spans of all POS\n",
    "Pos(P,D,Word,Lem)<-Docs(P,D,\"lemma_concept\"),pos(D)->(Word,Lem)\n",
    "?Pos(\"sample8.txt\",D,Word,Lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "# here we look for concept rule matches where the matched word is also tagged via POS\n",
    "PosConceptMatches(Path,Doc,Span,Label) <- \\\n",
    "    Docs(Path,Doc,\"lemma_concept\"),\\\n",
    "    ConceptTagRules(Pattern, Label, \"pos\"),\\\n",
    "    rgx(Pattern,Doc) -> (Span),\\\n",
    "    Pos(Path,Doc,Span,POSLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'patient presents to be tested for COVID-19. H...</td>\n",
       "      <td>[@668ee5,48,52) \"wife\"</td>\n",
       "      <td>'family'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>'patient be sent for a COVID-19 test. Someone ...</td>\n",
       "      <td>[@1edc3c,37,44) \"Someone\"</td>\n",
       "      <td>'other_experiencer'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P                                                  D  \\\n",
       "0  'sample1.txt'  'patient presents to be tested for COVID-19. H...   \n",
       "1  'sample8.txt'  'patient be sent for a COVID-19 test. Someone ...   \n",
       "\n",
       "                           W                    L  \n",
       "0     [@668ee5,48,52) \"wife\"             'family'  \n",
       "1  [@1edc3c,37,44) \"Someone\"  'other_experiencer'  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient be sent for a covid test. Someone be t...</td>\n",
       "      <td>lemma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient was sent for a covid test. Someone was...</td>\n",
       "      <td>raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient be sent for a COVID-19 test. Someone b...</td>\n",
       "      <td>lemma_concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient be sent for a COVID-19 test. other_exp...</td>\n",
       "      <td>pos_concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   D              V\n",
       "0  Patient be sent for a covid test. Someone be t...          lemma\n",
       "1  Patient was sent for a covid test. Someone was...       raw_text\n",
       "2  patient be sent for a COVID-19 test. Someone b...  lemma_concept\n",
       "3  patient be sent for a COVID-19 test. other_exp...    pos_concept"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "pos_concept_matches = sess.export('?PosConceptMatches(P,D,W,L)')\n",
    "display(pos_concept_matches.map(repr).head())\n",
    "\n",
    "pos_concept_docs = rewrite_docs(lemma_concepts,pos_concept_matches,'pos_concept')\n",
    "sess.import_rel('Docs',pos_concept_docs)\n",
    "sess.export('?Docs(\"sample8.txt\",D,V)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see for example in sample8.txt, Someone changed to other_experiencer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "TargetMatches(Path,Doc, Span, Label) <- \\\n",
    "    Docs(Path,Doc,\"pos_concept\"),\\\n",
    "    TargetTagRules(Pattern, Label), rgx(Pattern,Doc) -> (Span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>'patient have contact patient with COVID-19. s...</td>\n",
       "      <td>[@e00245,44,71) \"screening ...\"</td>\n",
       "      <td>'positive coronavirus screening'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P                                                  D  \\\n",
       "0  'sample9.txt'  'patient have contact patient with COVID-19. s...   \n",
       "\n",
       "                                 W                                 L  \n",
       "0  [@e00245,44,71) \"screening ...\"  'positive coronavirus screening'  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "target_matches = sess.export('?TargetMatches(P,D,W,L)')\n",
    "display(target_matches.map(repr))\n",
    "target_rule_docs = rewrite_docs(pos_concept_docs,target_matches,'target_concept')\n",
    "sess.import_rel('Docs',target_rule_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished rewriting our documents, lets look at the rewritting of the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_text\n",
      "Patient had contact patient with coronavirus. screening positive coronavirus.\n",
      "================================================================================\n",
      "lemma\n",
      "Patient have contact patient with coronavirus. screening positive coronavirus.\n",
      "================================================================================\n",
      "target_concept\n",
      "patient have contact patient with COVID-19. positive coronavirus screening.\n",
      "================================================================================\n",
      "lemma_concept\n",
      "patient have contact patient with COVID-19. screening positive COVID-19.\n",
      "================================================================================\n",
      "pos_concept\n",
      "patient have contact patient with COVID-19. screening positive COVID-19.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for doc,doc_type in sess.export('?Docs(\"sample9.txt\",D,V)').itertuples(index=False,name=None):\n",
    "    print(doc_type)\n",
    "    print(doc)\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting text by sentence and section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now finished our rewriting, \n",
    "This section replaces the sectionizer, and the parts of the context and postprocessing sections that deal with sentence splitting logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking text into sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>literal</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lab results:</td>\n",
       "      <td>labs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADDENDUM:</td>\n",
       "      <td>addendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addendum:</td>\n",
       "      <td>addendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALLERGIC REACTIONS:</td>\n",
       "      <td>allergies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALLERGIES:</td>\n",
       "      <td>allergies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               literal        tag\n",
       "0         Lab results:       labs\n",
       "1            ADDENDUM:   addendum\n",
       "2            Addendum:   addendum\n",
       "3  ALLERGIC REACTIONS:  allergies\n",
       "4           ALLERGIES:  allergies"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "section_tags = pd.read_csv(data_dir/'section_tags.csv',names=['literal','tag'])\n",
    "section_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lab results:|ADDENDUM:|Addendum:|ALLERGIC REACTIONS:|ALLERGIES:|CC:|CHIEF COMPLAINT:|Chief Complaint:|COMMENTS:|ADMISSION DIAGNOSES:|DIAGNOSES:|Diagnosis:|Primary Diagnosis:|Primary:|SECONDARY DIAGNOSES:|Secondary Diagnoses:|Secondary Diagnosis:|Secondary:|Family History:|Brief Hospital Course:|CONCISE SUMMARY OF HOSPITAL COURSE BY ISSUE/SYSTEM:|HOSPITAL COURSE:|SUMMARY OF HOSPITAL COURSE:|IMAGING:|INTERPRETATION:|Imaging:|MRI:|Radiology:|ADMISSION LABS:|Admission Labs:|Discharge Labs:|ECHO:|FINDINGS:|Findings:|INDICATION:|LABS:|Labs:|MICRO:|Micro:|Microbiology:|Pertinent Results:|STUDIES:|Studies:|ACTIVE MEDICATIONS LIST:|ACTIVE MEDICATIONS:|ADMISSION MEDICATIONS:|CURRENT MEDICATIONS:|DISCHARGE MEDICATIONS:|Discharge Medications:|HOME MEDICATIONS:|MEDICATIONS AT HOME:|MEDICATIONS LIST:|MEDICATIONS ON ADMISSION:|MEDICATIONS ON DISCHARGE:|MEDICATIONS ON TRANSFER:|MEDICATIONS PRIOR TO ADMISSION:|MEDICATIONS:|MEDICATIONS:|Neuro:|A/P:|ASSESSMENT/PLAN:|ASSESSMENT:|Assessment/Plan:|Clinical Impression:|DISCHARGE DIAGNOSES:|DISCHARGE DIAGNOSIS:|Discharge Condition:|Discharge Diagnoses:|Discharge Diagnosis:|Discharge Disposition:|FINAL DIAGNOSES:|FINAL DIAGNOSIS:|IMPRESSION:|Impression and Plan:|Impression and Recommendation:|Facility:|Service:|Current Medical Problems:|History of Chronic Illness:|MHx:|PAST HISTORY:|PAST MEDICAL HISTORY:|PAST MEDICAL Hx:|PAST SURGICAL HISTORY:|PMH:|PMHx:|Past Medical History:|UNDERLYING MEDICAL CONDITION:|Education:|Patient Education:|DISCHARGE INSTRUCTIONS/FOLLOWUP:|DISCHARGE INSTRUCTIONS:|Discharge Instructions:|Followup Instructions:|PE:|PHYSICAL EXAM:|PHYSICAL EXAMINATION:|Physical Exam:|Active Problem List:|Current Problems:|Medical Problems:|PROBLEM LIST:|Problem List:|REASON FOR THIS EXAMINATION:|Electronic Signature:|Signed electronically by:|PMHSx:|PSH:|SH:|Sexual History:|Social History:'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "# we will programatically build a regex that matches all the section patterns\n",
    "section_delimeter_pattern = section_tags['literal'].str.cat(sep='|')\n",
    "sess.import_var('section_delimeter_pattern',section_delimeter_pattern)\n",
    "section_delimeter_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?Sections(P,D,Sec,Content)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>Sec</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>'Problem List: like_num. Pneumonia like_num. C...</td>\n",
       "      <td>'Problem List:'</td>\n",
       "      <td>[@882253,13,62) \" like_num....\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P                                                  D  \\\n",
       "0  'sample3.txt'  'Problem List: like_num. Pneumonia like_num. C...   \n",
       "\n",
       "               Sec                          Content  \n",
       "0  'Problem List:'  [@882253,13,62) \" like_num....\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?PositiveSections(P,D,Sec,Content)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>D</th>\n",
       "      <th>Sec</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>'Problem List: like_num. Pneumonia like_num. C...</td>\n",
       "      <td>'Problem List:'</td>\n",
       "      <td>[@882253,13,62) \" like_num....\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P                                                  D  \\\n",
       "0  'sample3.txt'  'Problem List: like_num. Pneumonia like_num. C...   \n",
       "\n",
       "               Sec                          Content  \n",
       "0  'Problem List:'  [@882253,13,62) \" like_num....\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "# we get section spans and their content using our regex pattern and the rgx_split ie function\n",
    "Sections(P,D,Sec,Content)<-Docs(P,D,\"target_concept\"),\\\n",
    "    rgx_split($section_delimeter_pattern,D)->(SecSpan,Content),\\\n",
    "    as_str(SecSpan)->(Sec)\n",
    "?Sections(P,D,Sec,Content)\n",
    "\n",
    "PositiveSections(P,D,Sec,Content)<-Sections(P,D,Sec,Content),SectionTags(Sec,Tag),PositiveSectionTags(Tag)\n",
    "?PositiveSections(P,D,Sec,Content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breaking texts into sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?Sents(P,S)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,0,43) \"patient pr...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,94,130) \"COVID-19 r...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>[@f3a9fd,0,31) \"patient be...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>[@f3a9fd,32,59) \"results ca...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'sample7.txt'</td>\n",
       "      <td>[@a2c41c,0,82) \"Elevated c...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>[@3db2e4,0,36) \"patient be...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>[@3db2e4,37,74) \"other_expe...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>[@6d2862,0,43) \"patient ha...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>[@6d2862,44,75) \"positive c...\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 P                                 S\n",
       "0    'sample1.txt'    [@931cb5,0,43) \"patient pr...\"\n",
       "1    'sample1.txt'   [@931cb5,44,93) \"His family...\"\n",
       "2    'sample1.txt'  [@931cb5,94,130) \"COVID-19 r...\"\n",
       "3   'sample10.txt'    [@f3a9fd,0,31) \"patient be...\"\n",
       "4   'sample10.txt'   [@f3a9fd,32,59) \"results ca...\"\n",
       "..             ...                               ...\n",
       "14   'sample7.txt'    [@a2c41c,0,82) \"Elevated c...\"\n",
       "15   'sample8.txt'    [@3db2e4,0,36) \"patient be...\"\n",
       "16   'sample8.txt'   [@3db2e4,37,74) \"other_expe...\"\n",
       "17   'sample9.txt'    [@6d2862,0,43) \"patient ha...\"\n",
       "18   'sample9.txt'   [@6d2862,44,75) \"positive c...\"\n",
       "\n",
       "[19 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "Sents(P,S)<-Docs(P,D,\"target_concept\"),split_sentence(D)->(S)\n",
    "?Sents(P,S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will show 3 ways of getting pairs of adjacent sentences,\n",
    "The first is simply to make an ie function out of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternative 1, build a dedicated ie function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "def sentence_pairs(text):\n",
    "    yield from pairwise(split_sentence(text))\n",
    "\n",
    "sess.register('sentence_pairs',sentence_pairs,[(str,Span)],[Span,Span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?SentPairs_ver1(P,S1,S2)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,0,43) \"patient pr...\"</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "      <td>[@931cb5,94,130) \"COVID-19 r...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>[@f3a9fd,0,31) \"patient be...\"</td>\n",
       "      <td>[@f3a9fd,32,59) \"results ca...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,0,44) \"The patien...\"</td>\n",
       "      <td>[@e4b074,45,65) \"Results be...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,45,65) \"Results be...\"</td>\n",
       "      <td>[@e4b074,66,115) \"patient un...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>[@882253,0,23) \"Problem Li...\"</td>\n",
       "      <td>[@882253,24,43) \"Pneumonia ...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>[@882253,24,43) \"Pneumonia ...\"</td>\n",
       "      <td>[@882253,44,61) \"COVID-19 l...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>[@3db2e4,0,36) \"patient be...\"</td>\n",
       "      <td>[@3db2e4,37,74) \"other_expe...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>[@6d2862,0,43) \"patient ha...\"</td>\n",
       "      <td>[@6d2862,44,75) \"positive c...\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                P                               S1  \\\n",
       "0   'sample1.txt'   [@931cb5,0,43) \"patient pr...\"   \n",
       "1   'sample1.txt'  [@931cb5,44,93) \"His family...\"   \n",
       "2  'sample10.txt'   [@f3a9fd,0,31) \"patient be...\"   \n",
       "3   'sample2.txt'   [@e4b074,0,44) \"The patien...\"   \n",
       "4   'sample2.txt'  [@e4b074,45,65) \"Results be...\"   \n",
       "5   'sample3.txt'   [@882253,0,23) \"Problem Li...\"   \n",
       "6   'sample3.txt'  [@882253,24,43) \"Pneumonia ...\"   \n",
       "7   'sample8.txt'   [@3db2e4,0,36) \"patient be...\"   \n",
       "8   'sample9.txt'   [@6d2862,0,43) \"patient ha...\"   \n",
       "\n",
       "                                 S2  \n",
       "0   [@931cb5,44,93) \"His family...\"  \n",
       "1  [@931cb5,94,130) \"COVID-19 r...\"  \n",
       "2   [@f3a9fd,32,59) \"results ca...\"  \n",
       "3   [@e4b074,45,65) \"Results be...\"  \n",
       "4  [@e4b074,66,115) \"patient un...\"  \n",
       "5   [@882253,24,43) \"Pneumonia ...\"  \n",
       "6   [@882253,44,61) \"COVID-19 l...\"  \n",
       "7   [@3db2e4,37,74) \"other_expe...\"  \n",
       "8   [@6d2862,44,75) \"positive c...\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog\n",
    "SentPairs_ver1(P,S1,S2)<-Docs(P,D,\"target_concept\"),sentence_pairs(D)->(S1,S2)\n",
    "?SentPairs_ver1(P,S1,S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weakness in this approach is that we had build an IE function to do the extraction from scratch, obfuscating the fact that it and the split_sentence ie function share some logic. In our case since generating adjacent pairs is simple using itertools, this wasn't so bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate pairs declaratively, and build a filter ie function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_adjacent(span1,span2):\n",
    "    yield span1.doc==span2.doc and span1.end +1 == span2.start\n",
    "\n",
    "sess.register('is_adjacent',is_adjacent,[Span,Span],[bool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?SentPairs_ver2(P,S1,S2)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,0,43) \"patient pr...\"</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "      <td>[@931cb5,94,130) \"COVID-19 r...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>[@f3a9fd,0,31) \"patient be...\"</td>\n",
       "      <td>[@f3a9fd,32,59) \"results ca...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,0,44) \"The patien...\"</td>\n",
       "      <td>[@e4b074,45,65) \"Results be...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,45,65) \"Results be...\"</td>\n",
       "      <td>[@e4b074,66,115) \"patient un...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>[@882253,0,23) \"Problem Li...\"</td>\n",
       "      <td>[@882253,24,43) \"Pneumonia ...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>[@882253,24,43) \"Pneumonia ...\"</td>\n",
       "      <td>[@882253,44,61) \"COVID-19 l...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>[@3db2e4,0,36) \"patient be...\"</td>\n",
       "      <td>[@3db2e4,37,74) \"other_expe...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>[@6d2862,0,43) \"patient ha...\"</td>\n",
       "      <td>[@6d2862,44,75) \"positive c...\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                P                               S1  \\\n",
       "0   'sample1.txt'   [@931cb5,0,43) \"patient pr...\"   \n",
       "1   'sample1.txt'  [@931cb5,44,93) \"His family...\"   \n",
       "2  'sample10.txt'   [@f3a9fd,0,31) \"patient be...\"   \n",
       "3   'sample2.txt'   [@e4b074,0,44) \"The patien...\"   \n",
       "4   'sample2.txt'  [@e4b074,45,65) \"Results be...\"   \n",
       "5   'sample3.txt'   [@882253,0,23) \"Problem Li...\"   \n",
       "6   'sample3.txt'  [@882253,24,43) \"Pneumonia ...\"   \n",
       "7   'sample8.txt'   [@3db2e4,0,36) \"patient be...\"   \n",
       "8   'sample9.txt'   [@6d2862,0,43) \"patient ha...\"   \n",
       "\n",
       "                                 S2  \n",
       "0   [@931cb5,44,93) \"His family...\"  \n",
       "1  [@931cb5,94,130) \"COVID-19 r...\"  \n",
       "2   [@f3a9fd,32,59) \"results ca...\"  \n",
       "3   [@e4b074,45,65) \"Results be...\"  \n",
       "4  [@e4b074,66,115) \"patient un...\"  \n",
       "5   [@882253,24,43) \"Pneumonia ...\"  \n",
       "6   [@882253,44,61) \"COVID-19 l...\"  \n",
       "7   [@3db2e4,37,74) \"other_expe...\"  \n",
       "8   [@6d2862,44,75) \"positive c...\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog\n",
    "SentPairs_ver2(P,S1,S2)<-Sents(P,S1),Sents(P,S2),is_adjacent(S1,S2)->(True)\n",
    "?SentPairs_ver2(P,S1,S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simpler than the first alternative, and we get to reuse the Sent rules, however it might seem a little bother some to implement and register an ie function for every so called \"WHERE\" clause we would like to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third alternative, a generic boolean expression evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?SentPairs(P,S1,S2)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,0,43) \"patient pr...\"</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "      <td>[@931cb5,94,130) \"COVID-19 r...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample10.txt'</td>\n",
       "      <td>[@f3a9fd,0,31) \"patient be...\"</td>\n",
       "      <td>[@f3a9fd,32,59) \"results ca...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,0,44) \"The patien...\"</td>\n",
       "      <td>[@e4b074,45,65) \"Results be...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,45,65) \"Results be...\"</td>\n",
       "      <td>[@e4b074,66,115) \"patient un...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>[@882253,0,23) \"Problem Li...\"</td>\n",
       "      <td>[@882253,24,43) \"Pneumonia ...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>[@882253,24,43) \"Pneumonia ...\"</td>\n",
       "      <td>[@882253,44,61) \"COVID-19 l...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>[@3db2e4,0,36) \"patient be...\"</td>\n",
       "      <td>[@3db2e4,37,74) \"other_expe...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>[@6d2862,0,43) \"patient ha...\"</td>\n",
       "      <td>[@6d2862,44,75) \"positive c...\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                P                               S1  \\\n",
       "0   'sample1.txt'   [@931cb5,0,43) \"patient pr...\"   \n",
       "1   'sample1.txt'  [@931cb5,44,93) \"His family...\"   \n",
       "2  'sample10.txt'   [@f3a9fd,0,31) \"patient be...\"   \n",
       "3   'sample2.txt'   [@e4b074,0,44) \"The patien...\"   \n",
       "4   'sample2.txt'  [@e4b074,45,65) \"Results be...\"   \n",
       "5   'sample3.txt'   [@882253,0,23) \"Problem Li...\"   \n",
       "6   'sample3.txt'  [@882253,24,43) \"Pneumonia ...\"   \n",
       "7   'sample8.txt'   [@3db2e4,0,36) \"patient be...\"   \n",
       "8   'sample9.txt'   [@6d2862,0,43) \"patient ha...\"   \n",
       "\n",
       "                                 S2  \n",
       "0   [@931cb5,44,93) \"His family...\"  \n",
       "1  [@931cb5,94,130) \"COVID-19 r...\"  \n",
       "2   [@f3a9fd,32,59) \"results ca...\"  \n",
       "3   [@e4b074,45,65) \"Results be...\"  \n",
       "4  [@e4b074,66,115) \"patient un...\"  \n",
       "5   [@882253,24,43) \"Pneumonia ...\"  \n",
       "6   [@882253,44,61) \"COVID-19 l...\"  \n",
       "7   [@3db2e4,37,74) \"other_expe...\"  \n",
       "8   [@6d2862,44,75) \"positive c...\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "SentPairs(P,S1,S2)<-Sents(P,S1),Sents(P,S2),expr_eval(\"{0}.end +1 == {1}.start\",S1,S2)->(True)\n",
    "?SentPairs(P,S1,S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This alternative used a cheeky ie function from the standard library called `expr_eval` that lets as evaluate simple pythonic expression by writing them in a format similar to python's format strings. This ie function is quite useful for replacing simple filters but becomes error prone for large complex expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging Covid Mentions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will tag covid mentions based on their context. This section replaces the rest of the Context and postprocessing rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?CovidMentions(Path,Span)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,34,42) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,84,92) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,94,102) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,26,34) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,87,95) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sample4.txt'</td>\n",
       "      <td>[@77c574,4,12) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'sample5.txt'</td>\n",
       "      <td>[@ffb7c7,9,17) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'sample6.txt'</td>\n",
       "      <td>[@b2612f,26,34) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>[@3db2e4,22,30) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>[@6d2862,34,42) \"COVID-19\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Path                         Span\n",
       "0   'sample1.txt'   [@931cb5,34,42) \"COVID-19\"\n",
       "1   'sample1.txt'   [@931cb5,84,92) \"COVID-19\"\n",
       "2   'sample1.txt'  [@931cb5,94,102) \"COVID-19\"\n",
       "3   'sample2.txt'   [@e4b074,26,34) \"COVID-19\"\n",
       "4   'sample2.txt'   [@e4b074,87,95) \"COVID-19\"\n",
       "..            ...                          ...\n",
       "6   'sample4.txt'    [@77c574,4,12) \"COVID-19\"\n",
       "7   'sample5.txt'    [@ffb7c7,9,17) \"COVID-19\"\n",
       "8   'sample6.txt'   [@b2612f,26,34) \"COVID-19\"\n",
       "9   'sample8.txt'   [@3db2e4,22,30) \"COVID-19\"\n",
       "10  'sample9.txt'   [@6d2862,34,42) \"COVID-19\"\n",
       "\n",
       "[11 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?CovidMentionSents(P,Mention,Sent)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>Mention</th>\n",
       "      <th>Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,34,42) \"COVID-19\"</td>\n",
       "      <td>[@931cb5,0,43) \"patient pr...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,84,92) \"COVID-19\"</td>\n",
       "      <td>[@931cb5,44,93) \"His family...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,94,102) \"COVID-19\"</td>\n",
       "      <td>[@931cb5,94,130) \"COVID-19 r...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,26,34) \"COVID-19\"</td>\n",
       "      <td>[@e4b074,0,44) \"The patien...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,87,95) \"COVID-19\"</td>\n",
       "      <td>[@e4b074,66,115) \"patient un...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sample4.txt'</td>\n",
       "      <td>[@77c574,4,12) \"COVID-19\"</td>\n",
       "      <td>[@77c574,0,23) \"neg COVID-...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'sample5.txt'</td>\n",
       "      <td>[@ffb7c7,9,17) \"COVID-19\"</td>\n",
       "      <td>[@ffb7c7,0,29) \"positive C...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'sample6.txt'</td>\n",
       "      <td>[@b2612f,26,34) \"COVID-19\"</td>\n",
       "      <td>[@b2612f,0,35) \"The patien...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'sample8.txt'</td>\n",
       "      <td>[@3db2e4,22,30) \"COVID-19\"</td>\n",
       "      <td>[@3db2e4,0,36) \"patient be...\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'sample9.txt'</td>\n",
       "      <td>[@6d2862,34,42) \"COVID-19\"</td>\n",
       "      <td>[@6d2862,0,43) \"patient ha...\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                P                      Mention  \\\n",
       "0   'sample1.txt'   [@931cb5,34,42) \"COVID-19\"   \n",
       "1   'sample1.txt'   [@931cb5,84,92) \"COVID-19\"   \n",
       "2   'sample1.txt'  [@931cb5,94,102) \"COVID-19\"   \n",
       "3   'sample2.txt'   [@e4b074,26,34) \"COVID-19\"   \n",
       "4   'sample2.txt'   [@e4b074,87,95) \"COVID-19\"   \n",
       "..            ...                          ...   \n",
       "6   'sample4.txt'    [@77c574,4,12) \"COVID-19\"   \n",
       "7   'sample5.txt'    [@ffb7c7,9,17) \"COVID-19\"   \n",
       "8   'sample6.txt'   [@b2612f,26,34) \"COVID-19\"   \n",
       "9   'sample8.txt'   [@3db2e4,22,30) \"COVID-19\"   \n",
       "10  'sample9.txt'   [@6d2862,34,42) \"COVID-19\"   \n",
       "\n",
       "                                Sent  \n",
       "0     [@931cb5,0,43) \"patient pr...\"  \n",
       "1    [@931cb5,44,93) \"His family...\"  \n",
       "2   [@931cb5,94,130) \"COVID-19 r...\"  \n",
       "3     [@e4b074,0,44) \"The patien...\"  \n",
       "4   [@e4b074,66,115) \"patient un...\"  \n",
       "..                               ...  \n",
       "6     [@77c574,0,23) \"neg COVID-...\"  \n",
       "7     [@ffb7c7,0,29) \"positive C...\"  \n",
       "8     [@b2612f,0,35) \"The patien...\"  \n",
       "9     [@3db2e4,0,36) \"patient be...\"  \n",
       "10    [@6d2862,0,43) \"patient ha...\"  \n",
       "\n",
       "[11 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "# first we get the covid mentions and their surrounding sentences, using the span_contained ie function\n",
    "CovidMentions(Path, Span) <- Docs(Path,D,\"target_concept\"), rgx(\"COVID-19\",D) -> (Span)\n",
    "CovidMentionSents(P,Mention,Sent)<-CovidMentions(P,Mention),Sents(P,Sent),span_contained(Mention,Sent)->(True)\n",
    "\n",
    "?CovidMentions(Path, Span)\n",
    "?CovidMentionSents(P,Mention,Sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define how to derive covid tags using sections, context and the different postprocessing rule types. Notice how easy it is to convey complex control flow that combines multiple data sources elegantly using Spannerlog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?CovidTags(Path,Mention,Tag,Derivation)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Mention</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Derivation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,84,92) \"COVID-19\"</td>\n",
       "      <td>'negated'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,84,92) \"COVID-19\"</td>\n",
       "      <td>'positive'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,94,102) \"COVID-19\"</td>\n",
       "      <td>'positive'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,87,95) \"COVID-19\"</td>\n",
       "      <td>'IGNORE'</td>\n",
       "      <td>'post pattern'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,87,95) \"COVID-19\"</td>\n",
       "      <td>'future'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'sample4.txt'</td>\n",
       "      <td>[@77c574,4,12) \"COVID-19\"</td>\n",
       "      <td>'negated'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'sample5.txt'</td>\n",
       "      <td>[@ffb7c7,9,17) \"COVID-19\"</td>\n",
       "      <td>'future'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'sample5.txt'</td>\n",
       "      <td>[@ffb7c7,9,17) \"COVID-19\"</td>\n",
       "      <td>'no_future'</td>\n",
       "      <td>'post attribute change'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'sample5.txt'</td>\n",
       "      <td>[@ffb7c7,9,17) \"COVID-19\"</td>\n",
       "      <td>'positive'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'sample6.txt'</td>\n",
       "      <td>[@b2612f,26,34) \"COVID-19\"</td>\n",
       "      <td>'patient_experiencer'</td>\n",
       "      <td>'sentence context'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Path                      Mention                    Tag  \\\n",
       "0   'sample1.txt'   [@931cb5,84,92) \"COVID-19\"              'negated'   \n",
       "1   'sample1.txt'   [@931cb5,84,92) \"COVID-19\"             'positive'   \n",
       "2   'sample1.txt'  [@931cb5,94,102) \"COVID-19\"             'positive'   \n",
       "3   'sample2.txt'   [@e4b074,87,95) \"COVID-19\"               'IGNORE'   \n",
       "4   'sample2.txt'   [@e4b074,87,95) \"COVID-19\"               'future'   \n",
       "..            ...                          ...                    ...   \n",
       "9   'sample4.txt'    [@77c574,4,12) \"COVID-19\"              'negated'   \n",
       "10  'sample5.txt'    [@ffb7c7,9,17) \"COVID-19\"               'future'   \n",
       "11  'sample5.txt'    [@ffb7c7,9,17) \"COVID-19\"            'no_future'   \n",
       "12  'sample5.txt'    [@ffb7c7,9,17) \"COVID-19\"             'positive'   \n",
       "13  'sample6.txt'   [@b2612f,26,34) \"COVID-19\"  'patient_experiencer'   \n",
       "\n",
       "                 Derivation  \n",
       "0        'sentence context'  \n",
       "1        'sentence context'  \n",
       "2        'sentence context'  \n",
       "3            'post pattern'  \n",
       "4        'sentence context'  \n",
       "..                      ...  \n",
       "9        'sentence context'  \n",
       "10       'sentence context'  \n",
       "11  'post attribute change'  \n",
       "12       'sentence context'  \n",
       "13       'sentence context'  \n",
       "\n",
       "[14 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "\n",
    "# note that for ease of debugging, we extended our head to track which rule a fact was derived from\n",
    "\n",
    "# a tag is positive if it is contained in a positive section\n",
    "CovidTags(Path,Mention,'positive','section')<-\\\n",
    "    PositiveSections(Path,D,Title,Section),\\\n",
    "    CovidMentions(Path,Mention),\\\n",
    "    span_contained(Mention,Section)->(True)\n",
    "\n",
    "# Context rules tags\n",
    "CovidTags(Path,Mention,Tag,'sentence context')<-\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    SentenceContextRules(Pattern,Tag),\\\n",
    "    rgx(Pattern,Sent)->(ContextSpan),\\\n",
    "    span_contained(Mention,ContextSpan)->(True)\n",
    "\n",
    "# post processing based on pattern\n",
    "CovidTags(Path,Mention,Tag,'post pattern')<-\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    PostprocessPatternRules(Pattern,Tag),\\\n",
    "    rgx(Pattern,Sent)->(ContextSpan),\\\n",
    "    span_contained(Mention,ContextSpan)->(True)\n",
    "\n",
    "# post processing based on pattern and existing attributes\n",
    "# notice the recursive call to CovidTags\n",
    "CovidTags(Path,Mention,Tag,\"post attribute change\")<-\\\n",
    "    CovidTags(Path,Mention,OldTag,Derivation),\\\n",
    "    PostprocessRulesWithAttributes(Pattern,OldTag,Tag),\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    rgx(Pattern,Sent)->(ContextSpan),\\\n",
    "    span_contained(Mention,ContextSpan)->(True)\n",
    "\n",
    "# post processing based on pattern in the next sentence\n",
    "CovidTags(Path,Mention,Tag,\"next sentence\")<-\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    SentPairs(Path,Sent,NextSent),\\\n",
    "    PostprocessPatternRules(Pattern,Tag),\\\n",
    "    rgx(Pattern,NextSent)->(ContextSpan)\n",
    "\n",
    "?CovidTags(Path,Mention,Tag,Derivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Classificaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section we will aggregate tags on mentions into document classification in two stages,\n",
    "aggregation of tags per mention and aggregation of mentions per document. This section replaces the document classification state in the original pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def agg_mention(group):\n",
    "    \"\"\"\n",
    "    aggregates attribute groups of covid spans\n",
    "    \"\"\"\n",
    "    if 'IGNORE' in group.values:\n",
    "        return 'IGNORE'\n",
    "    elif 'negated' in group.values and not 'no_negated' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'future' in group.values and not 'no_future' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'other experiencer' in group.values or 'not relevant' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'positive' in group.values and not 'uncertain' in group.values and not 'no_positive' in group.values:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "#| export\n",
    "def AggDocumentTags(group):\n",
    "    \"\"\"\n",
    "    Classifies a document as 'POS', 'UNK', or 'NEG' based on COVID-19 attributes.\n",
    "    \"\"\"\n",
    "    if 'positive' in group.values:\n",
    "        return 'POS'\n",
    "    elif 'uncertain' in group.values:\n",
    "        return 'UNK'\n",
    "    elif 'negated' in group.values:\n",
    "        return 'NEG'\n",
    "    else:\n",
    "        return 'UNK'\n",
    "\n",
    "\n",
    "sess.register_agg('agg_mention',agg_mention,[str],[str])\n",
    "sess.register_agg('agg_doc_tags',AggDocumentTags,[str],[str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?AggregatedCovidTags(Path,Mention,Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Mention</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,84,92) \"COVID-19\"</td>\n",
       "      <td>'negated'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>[@931cb5,94,102) \"COVID-19\"</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>[@e4b074,87,95) \"COVID-19\"</td>\n",
       "      <td>'IGNORE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>[@882253,44,52) \"COVID-19\"</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample4.txt'</td>\n",
       "      <td>[@77c574,4,12) \"COVID-19\"</td>\n",
       "      <td>'IGNORE'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'sample5.txt'</td>\n",
       "      <td>[@ffb7c7,9,17) \"COVID-19\"</td>\n",
       "      <td>'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'sample6.txt'</td>\n",
       "      <td>[@b2612f,26,34) \"COVID-19\"</td>\n",
       "      <td>'uncertain'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Path                      Mention          Tag\n",
       "0  'sample1.txt'   [@931cb5,84,92) \"COVID-19\"    'negated'\n",
       "1  'sample1.txt'  [@931cb5,94,102) \"COVID-19\"   'positive'\n",
       "2  'sample2.txt'   [@e4b074,87,95) \"COVID-19\"     'IGNORE'\n",
       "3  'sample3.txt'   [@882253,44,52) \"COVID-19\"   'positive'\n",
       "4  'sample4.txt'    [@77c574,4,12) \"COVID-19\"     'IGNORE'\n",
       "5  'sample5.txt'    [@ffb7c7,9,17) \"COVID-19\"   'positive'\n",
       "6  'sample6.txt'   [@b2612f,26,34) \"COVID-19\"  'uncertain'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'?DocumentTags(Path,Tag)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'sample1.txt'</td>\n",
       "      <td>'POS'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'sample2.txt'</td>\n",
       "      <td>'UNK'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'sample3.txt'</td>\n",
       "      <td>'POS'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'sample4.txt'</td>\n",
       "      <td>'UNK'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sample5.txt'</td>\n",
       "      <td>'POS'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'sample6.txt'</td>\n",
       "      <td>'UNK'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Path    Tag\n",
       "0  'sample1.txt'  'POS'\n",
       "1  'sample2.txt'  'UNK'\n",
       "2  'sample3.txt'  'POS'\n",
       "3  'sample4.txt'  'UNK'\n",
       "4  'sample5.txt'  'POS'\n",
       "5  'sample6.txt'  'UNK'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spannerlog -a {slog_file}\n",
    "AggregatedCovidTags(Path,Mention,agg_mention(Tag))<-\\\n",
    "    CovidTags(Path,Mention,Tag,Derivation)\n",
    "\n",
    "?AggregatedCovidTags(Path,Mention,Tag)\n",
    "\n",
    "DocumentTags(Path,agg_doc_tags(Tag))<-\\\n",
    "    AggregatedCovidTags(Path,Mention,Tag)\n",
    "\n",
    "?DocumentTags(Path,Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample1.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample2.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample3.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample4.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample5.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample6.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P    T\n",
       "0  sample1.txt  POS\n",
       "1  sample2.txt  UNK\n",
       "2  sample3.txt  POS\n",
       "3  sample4.txt  UNK\n",
       "4  sample5.txt  POS\n",
       "5  sample6.txt  UNK"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "doc_tags = sess.export('?DocumentTags(P,T)')\n",
    "doc_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling unmentioned paths:\n",
    "At this step, we assign a classification result 'UNK' to paths not identified in the previous DataFrame result. This occurs when our pipeline doesn't detect any mention of COVID-19 or its synonyms in the text of those paths. As a result, these paths are excluded from all types of relations, consistent with our primary focus on COVID-19 entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_inputs/sample1.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_inputs/sample10.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_inputs/sample2.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_inputs/sample3.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_inputs/sample4.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_inputs/sample5.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_inputs/sample6.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_inputs/sample7.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_inputs/sample8.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_inputs/sample9.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample1.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample2.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample3.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample4.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample5.txt</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample6.txt</td>\n",
       "      <td>UNK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             P    T\n",
       "0    sample_inputs/sample1.txt  UNK\n",
       "1   sample_inputs/sample10.txt  UNK\n",
       "2    sample_inputs/sample2.txt  UNK\n",
       "3    sample_inputs/sample3.txt  UNK\n",
       "4    sample_inputs/sample4.txt  UNK\n",
       "5    sample_inputs/sample5.txt  UNK\n",
       "6    sample_inputs/sample6.txt  UNK\n",
       "7    sample_inputs/sample7.txt  UNK\n",
       "8    sample_inputs/sample8.txt  UNK\n",
       "9    sample_inputs/sample9.txt  UNK\n",
       "10                 sample1.txt  POS\n",
       "11                 sample2.txt  UNK\n",
       "12                 sample3.txt  POS\n",
       "13                 sample4.txt  UNK\n",
       "14                 sample5.txt  POS\n",
       "15                 sample6.txt  UNK"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "paths = pd.DataFrame(file_paths,columns=['P'])\n",
    "classification = paths.merge(doc_tags,on='P',how='outer')\n",
    "classification['T']=classification['T'].fillna('UNK')\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this we have completed the pipeline.\n",
    "In the next section we will look at the entire code base, compare lines of code and analyze the advantages of the spannerlib implementation form a software engineering perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to End implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "from spannerlib import get_magic_session,Session,Span\n",
    "sess = get_magic_session()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# configurations\n",
    "logic_file = Path('covid_logic.pl')\n",
    "input_dir = Path('sample_inputs')\n",
    "data_dir = Path('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spannerlog Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% spannerlog\n",
    "Lemmas(P,D,Word,Lem)<-Docs(P,D,\"raw_text\"),lemma(D)->(Word,Lem)\n",
    "\n",
    "LemmaConceptMatches(Path,Doc,Span,Label) <- \\\n",
    "    Docs(Path,Doc,\"lemma\"),\\\n",
    "    ConceptTagRules(Pattern, Label, \"lemma\"),\\\n",
    "    rgx(Pattern,Doc) -> (Span)\n",
    "\n",
    "# here we get the spans of all POS\n",
    "Pos(P,D,Word,Lem)<-Docs(P,D,\"lemma_concept\"),pos(D)->(Word,Lem)\n",
    "\n",
    "# here we look for concept rule matches where the matched word is also tagged via POS\n",
    "PosConceptMatches(Path,Doc,Span,Label) <- \\\n",
    "    Docs(Path,Doc,\"lemma_concept\"),\\\n",
    "    ConceptTagRules(Pattern, Label, \"pos\"),\\\n",
    "    rgx(Pattern,Doc) -> (Span),\\\n",
    "    Pos(Path,Doc,Span,POSLabel)\n",
    "\n",
    "TargetMatches(Path,Doc, Span, Label) <- \\\n",
    "    Docs(Path,Doc,\"pos_concept\"),\\\n",
    "    TargetTagRules(Pattern, Label), rgx(Pattern,Doc) -> (Span)\n",
    "\n",
    "# we get section spans and their content using our regex pattern and the rgx_split ie function\n",
    "Sections(P,D,Sec,Content)<-Docs(P,D,\"target_concept\"),\\\n",
    "    rgx_split($section_delimeter_pattern,D)->(SecSpan,Content),\\\n",
    "    as_str(SecSpan)->(Sec)\n",
    "\n",
    "PositiveSections(P,D,Sec,Content)<-Sections(P,D,Sec,Content),SectionTags(Sec,Tag),PositiveSectionTags(Tag)\n",
    "\n",
    "Sents(P,S)<-Docs(P,D,\"target_concept\"),split_sentence(D)->(S)\n",
    "\n",
    "SentPairs(P,S1,S2)<-Sents(P,S1),Sents(P,S2),expr_eval(\"{0}.end +1 == {1}.start\",S1,S2)->(True)\n",
    "\n",
    "# first we get the covid mentions and their surrounding sentences, using the span_contained ie function\n",
    "CovidMentions(Path, Span) <- Docs(Path,D,\"target_concept\"), rgx(\"COVID-19\",D) -> (Span)\n",
    "CovidMentionSents(P,Mention,Sent)<-CovidMentions(P,Mention),Sents(P,Sent),span_contained(Mention,Sent)->(True)\n",
    "\n",
    "# note that for ease of debugging, we extended our head to track which rule a fact was derived from\n",
    "# a tag is positive if it is contained in a positive section\n",
    "CovidTags(Path,Mention,'positive','section')<-\\\n",
    "    PositiveSections(Path,D,Title,Section),\\\n",
    "    CovidMentions(Path,Mention),\\\n",
    "    span_contained(Mention,Section)->(True)\n",
    "\n",
    "# Context rules tags\n",
    "CovidTags(Path,Mention,Tag,'sentence context')<-\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    SentenceContextRules(Pattern,Tag),\\\n",
    "    rgx(Pattern,Sent)->(ContextSpan),\\\n",
    "    span_contained(Mention,ContextSpan)->(True)\n",
    "\n",
    "# post processing based on pattern\n",
    "CovidTags(Path,Mention,Tag,'post pattern')<-\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    PostprocessPatternRules(Pattern,Tag),\\\n",
    "    rgx(Pattern,Sent)->(ContextSpan),\\\n",
    "    span_contained(Mention,ContextSpan)->(True)\n",
    "\n",
    "# post processing based on pattern and existing attributes\n",
    "# notice the recursive call to CovidTags\n",
    "CovidTags(Path,Mention,Tag,\"post attribute change\")<-\\\n",
    "    CovidTags(Path,Mention,OldTag,Derivation),\\\n",
    "    PostprocessRulesWithAttributes(Pattern,OldTag,Tag),\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    rgx(Pattern,Sent)->(ContextSpan),\\\n",
    "    span_contained(Mention,ContextSpan)->(True)\n",
    "\n",
    "# post processing based on pattern in the next sentence\n",
    "CovidTags(Path,Mention,Tag,\"next sentence\")<-\\\n",
    "    CovidMentionSents(Path,Mention,Sent),\\\n",
    "    SentPairs(Path,Sent,NextSent),\\\n",
    "    PostprocessPatternRules(Pattern,Tag),\\\n",
    "    rgx(Pattern,NextSent)->(ContextSpan)\n",
    "\n",
    "AggregatedCovidTags(Path,Mention,agg_mention(Tag))<-\\\n",
    "    CovidTags(Path,Mention,Tag,Derivation)\n",
    "\n",
    "DocumentTags(Path,agg_doc_tags(Tag))<-\\\n",
    "    AggregatedCovidTags(Path,Mention,Tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IE and Agg functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(text):\n",
    "    \"\"\"\n",
    "    Splits a text into individual sentences. using spacy's sentence detection.\n",
    "    \n",
    "    Returns:\n",
    "        str: Individual sentences extracted from the input text.\n",
    "    \"\"\"\n",
    "\n",
    "    doc = nlp(str(text))\n",
    "    start = 0\n",
    "    for sentence in doc.sents:\n",
    "        end = start+len(sentence.text)\n",
    "        # note that we yield a Span object, so we can keep track of the locations of the sentences\n",
    "        yield Span(text,start,end)\n",
    "        start = end + 1\n",
    "\n",
    "class LemmaFromList():\n",
    "    def __init__(self,lemma_list):\n",
    "        self.lemma_list = lemma_list\n",
    "\n",
    "    def __call__(self,text):\n",
    "        doc = nlp(str(text))\n",
    "        for word in doc:\n",
    "            start = word.idx\n",
    "            end = start + len(word.text)\n",
    "            if word.lemma_ in self.lemma_list:\n",
    "                yield (Span(text,start,end),word.lemma_)\n",
    "            elif word.like_num:\n",
    "                yield (Span(text,start,end),'like_num')\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "lemma_list = (data_dir/'lemma_words.txt').read_text().split()\n",
    "lemmatizer = LemmaFromList(lemma_list)\n",
    "\n",
    "class PosFromList():\n",
    "    def __init__(self,pos_list):\n",
    "        self.pos_list = pos_list\n",
    "    def __call__(self,text):\n",
    "        doc = nlp(str(text))\n",
    "        for word in doc:\n",
    "            start = word.idx\n",
    "            end = start + len(word.text)\n",
    "            if word.pos_ in self.pos_list:\n",
    "                yield (Span(text,start,end),word.pos_)\n",
    "\n",
    "pos_annotator = PosFromList([\"NOUN\", \"PROPN\", \"PRON\", \"ADJ\"])\n",
    "\n",
    "def agg_mention(group):\n",
    "    \"\"\"\n",
    "    aggregates attribute groups of covid spans\n",
    "    \"\"\"\n",
    "    if 'IGNORE' in group.values:\n",
    "        return 'IGNORE'\n",
    "    elif 'negated' in group.values and not 'no_negated' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'future' in group.values and not 'no_future' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'other experiencer' in group.values or 'not relevant' in group.values:\n",
    "        return 'negated'\n",
    "    elif 'positive' in group.values and not 'uncertain' in group.values and not 'no_positive' in group.values:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "def AggDocumentTags(group):\n",
    "    \"\"\"\n",
    "    Classifies a document as 'POS', 'UNK', or 'NEG' based on COVID-19 attributes.\n",
    "    \"\"\"\n",
    "    if 'positive' in group.values:\n",
    "        return 'POS'\n",
    "    elif 'uncertain' in group.values:\n",
    "        return 'UNK'\n",
    "    elif 'negated' in group.values:\n",
    "        return 'NEG'\n",
    "    else:\n",
    "        return 'UNK'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular python utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(text,span_label_pairs):\n",
    "    \"\"\"rewrites a string given a dataframe with spans and the string to rewrite them to\n",
    "    assumes that the spans belong to the text\n",
    "\n",
    "    Args:\n",
    "        text (str like): string to rewrite\n",
    "        span_label_pairs (pd.Dataframe) dataframe with two columns, first is spans in the doc to rewrite\n",
    "            second is what to rewrite to\n",
    "    Returns:\n",
    "        The rewritten string\n",
    "    \"\"\"    \n",
    "    if isinstance(text,Span):\n",
    "        text = text.as_str()\n",
    "    span_label_pairs = sorted(list(span_label_pairs.itertuples(index=False,name=None)), key=lambda x: x[0].start)\n",
    "\n",
    "    rewritten_text = ''\n",
    "    current_pos = 0\n",
    "    for span,label in span_label_pairs:\n",
    "        rewritten_text += text[current_pos:span.start] + label \n",
    "        current_pos = span.end\n",
    "\n",
    "    rewritten_text += text[current_pos:]\n",
    "\n",
    "    return rewritten_text\n",
    "\n",
    "\n",
    "def rewrite_docs(docs,span_label,new_version):\n",
    "    \"\"\"Given a dataframe of documents of the form (path,doc,version) and a dataframe of spans to rewrite\n",
    "    of the form (path,word,from_span,to_tag), rewrites the documents and returns a new dataframe of the form\n",
    "    (path,doc,new_version)\n",
    "\n",
    "    \"\"\"\n",
    "    new_tuples =[]\n",
    "    span_label.columns = ['P','D','W','L']\n",
    "    for path,doc,_ in docs.itertuples(index=False,name=None):\n",
    "        span_label_per_doc = span_label[span_label['P'] == path][['W','L']]\n",
    "        new_text = rewrite(doc,span_label_per_doc)\n",
    "        new_tuples.append((path,new_text,new_version))\n",
    "    return pd.DataFrame(new_tuples,columns=['P','D','V'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_dir,data_dir):\n",
    "    sess = Session()\n",
    "    # define callback functions\n",
    "    sess.register('split_sentence',split_sentence,[(str,Span)],[Span])\n",
    "    sess.register('pos',pos_annotator,[(Span,str)],[Span,str])\n",
    "    sess.register('lemma',lemmatizer,[(Span,str)],[Span,str])\n",
    "    sess.register_agg('agg_mention',agg_mention,[str],[str])\n",
    "    sess.register_agg('agg_doc_tags',AggDocumentTags,[str],[str])\n",
    "    \n",
    "    # bring in code as data\n",
    "    sess.import_rel(\"ConceptTagRules\",data_dir/\"concept_tags_rules.csv\" , delim=\",\")\n",
    "    sess.import_rel(\"TargetTagRules\",data_dir/\"target_rules.csv\",delim=\",\")\n",
    "    sess.import_rel(\"SectionTags\",data_dir/\"section_tags.csv\",delim=\",\")\n",
    "    sess.import_rel(\"PositiveSectionTags\",data_dir/\"positive_section_tags.csv\",delim=\",\")\n",
    "    sess.import_rel(\"SentenceContextRules\",data_dir/'sentence_context_rules.csv',delim=\"#\")\n",
    "    sess.import_rel(\"PostprocessPatternRules\",data_dir/'postprocess_pattern_rules.csv',delim=\"#\")\n",
    "    sess.import_rel(\"PostprocessRulesWithAttributes\",data_dir/'postprocess_attributes_rules.csv',delim=\"#\")\n",
    "    sess.import_rel(\"NextSentencePostprocessPatternRules\",data_dir/'postprocess_pattern_next_sentence_rules.csv',delim=',')\n",
    "\n",
    "\n",
    "    # we will programatically build a regex that matches all the section patterns\n",
    "    section_tags = pd.read_csv(data_dir/'section_tags.csv',names=['literal','tag'])\n",
    "    section_delimeter_pattern = section_tags['literal'].str.cat(sep='|')\n",
    "    sess.import_var('section_delimeter_pattern',section_delimeter_pattern)\n",
    "\n",
    "    # bring in data\n",
    "    file_paths = [Path(p) for p in glob(str(input_dir/'*.txt'))]\n",
    "    raw_docs = pd.DataFrame([\n",
    "        [p.name,p.read_text(),'raw_text'] for p in file_paths\n",
    "    ],columns=['Path','Doc','Version']\n",
    "    )\n",
    "    sess.import_rel('Docs',raw_docs)\n",
    "\n",
    "    # load logic, note that since we did not define the data relations in the logic file,\n",
    "    # we need to load the logic after the data has been loaded\n",
    "    sess.export(logic_file.read_text())\n",
    "\n",
    "    ## Rewritting the documents\n",
    "    lemma_tags = sess.export('?Lemmas(P,D,W,L)')\n",
    "    lemma_docs = rewrite_docs(raw_docs,lemma_tags,'lemma')\n",
    "    sess.import_rel('Docs',lemma_docs)\n",
    "\n",
    "    lemma_concept_matches = sess.export('?LemmaConceptMatches(Path,Doc,Span,Label)')\n",
    "    lemma_concepts = rewrite_docs(lemma_docs,lemma_concept_matches,'lemma_concept')\n",
    "    sess.import_rel('Docs',lemma_concepts)\n",
    "\n",
    "    pos_concept_matches = sess.export('?PosConceptMatches(P,D,W,L)')\n",
    "    pos_concept_docs = rewrite_docs(lemma_concepts,pos_concept_matches,'pos_concept')\n",
    "    sess.import_rel('Docs',pos_concept_docs)\n",
    "\n",
    "    target_matches = sess.export('?TargetMatches(P,D,W,L)')\n",
    "    target_rule_docs = rewrite_docs(pos_concept_docs,target_matches,'target_concept')\n",
    "    sess.import_rel('Docs',target_rule_docs)\n",
    "\n",
    "    ## computing the tags based on the target concept documents\n",
    "    doc_tags = sess.export('?DocumentTags(P,T)')\n",
    "\n",
    "    # handling files with no mentions\n",
    "    paths = pd.DataFrame(file_paths,columns=['P'])\n",
    "    classification = paths.merge(doc_tags,on='P',how='outer')\n",
    "    classification['T']=classification['T'].fillna('UNK')\n",
    "    classification\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing the line of code analysis for both implementations we get:\n",
    "\n",
    "| Implementation            | Code Type         | ~#code lines |\n",
    "|---------------------------|-------------------|--------------|\n",
    "| Original Implementation   | Rules Collections | 3903         |\n",
    "|                           | Vanilla Python    | 639          |\n",
    "| Spannerlib Implementation | Data              | 378          |\n",
    "|                           | IE/AGG functions  | 76           |\n",
    "|                           | Spannerlog        | 79           |\n",
    "|                           | Vanilla python    | 118          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we see that the different type of rules, which were basically data as code and made up the majority of the code base,\n",
    "shrank by a factor of 10 (~3900 to ~380). Moreover the Vanilla python code, over 600 lines long, shrank to less than 300 lines of code, over half of which were either Spannerlog code, or stateless IE/AGG functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software engineering perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to \n",
    "* fully appreciate the strengths of the spannerlib framework.\n",
    "* Understand our reasoning behind dividing the code into the four modalities mentioned above in our analysis.\n",
    "\n",
    "In this section we will refer to our covid pipeline refactoring as an example that helps highlight the benefits of the framework in general.\n",
    "\n",
    "We will remind the reader of a several important concepts:\n",
    "\n",
    "Decomposition/Factoring:\n",
    "* The breaking apart of code into parts that are easier to understand, program and maintain\n",
    "\n",
    "Separation of concerns:\n",
    "* A design principle that states that each section in a code should address a separate concern\n",
    "* The goal of this principle is to make code easier to program and maintain by having the programmer:\n",
    "  * required to reason about less concept when working on a section of code.\n",
    "  * required to reason about less sections of code when trying to modify an aspect of the program.\n",
    "\n",
    "Bug surface area:\n",
    "* Is also affected by complexity of the state of the program\n",
    "* Bug surface area is often divided into compile (static) surface area and run time (dynamic) surface area\n",
    "  * Looking at static and dynamic surface area separately is important since static bugs can be caught easily using a compiler/interpreter, can be proved to exist/not exist and do not require building tests to catch.\n",
    "\n",
    "Readability:\n",
    "* A measure of how easy it is to understand code.\n",
    "\n",
    "Debugability:\n",
    "* A measure of how easy it is to find bugs in a code base.\n",
    "  * This measure does not always coincide with readability, for example, multithreaded code is a clear example where the intent of the code might be easy to understand, but the non deterministic nature of the execution will make debugging hard.\n",
    "\n",
    "Barriers of entry:\n",
    "* The difficulties in programming effectively in an existing codebase that stem from\n",
    "  * The technical complexity of the codebase\n",
    "  * the learning curve of the specific libraries, concepts or technologies used in the project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why does it matter how many lines of code **per modality** an implementation has? Why do we separate vanilla python code from IE functions?\n",
    "Because different modalities (as well as different programming languages) have different costs with respect to:\n",
    "* readability\n",
    "* debugability\n",
    "* and bug surface area\n",
    "per volume of code (which we approximate via lines of code in this discussion).\n",
    "\n",
    "This fact is well known across programming languages, for example:\n",
    "A typical python function `f` is more readable than its C counterpart `g`, but `f`s bug surface area is greater even though `g` will often be much longer.\n",
    "This is mainly due to the fact the C is a statically typed language that chooses to reduce run time bug surface area in favor of less readability.\n",
    "\n",
    "The same is true to the four different modalities we analyze here:\n",
    "* Code as Data\n",
    "* Declerative Code (and specificall python)\n",
    "* Stateless python code (IE functions)\n",
    "* General python code\n",
    "As we move up this list, we have more and more freedom, the code\n",
    "* becomes less readable\n",
    "* has a larger bug surface area\n",
    "* and is harder to debug\n",
    "\n",
    "A csv line's is much simpler to verify than a line of spannerlog than a line of stateless python than a line of generic python. \n",
    "Put more techincally, the scaling factors of these code measures get worse as we move up the chain.\n",
    "\n",
    "For this reason, we do not only care how many lines of code we removed from an implementation, but how many lines of code became more readable debugable etc due to a change in modality.\n",
    "The `Rules` in the original implementation turned into csv files, which are easier to statically verify, making the reduction of overall complexity more substantial than the reduction in lines of code. The regex patterns, per line of code, are harder to read for a human but are easier for a machine to verify the correctness of.\n",
    "\n",
    "As for the vanilla python code in the original implementation, the reduction of complexity of the code does not simply come from the >2x reduction in lines of code, but comes from the fact that over half of said code in the new implementation is either declarative or stateless.\n",
    "An example of this are the callback functions added to the post processing section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So programming in the spannerlib framework, when the task can be partially modelled as an IE task, simplifies programming not only by reducing total volume of code, but by reducing the bug surface area, readability and debugability of conceptually simpler code by moving it to an appropriate modality with better scaling factors for these measures.\n",
    "\n",
    "But there is another advantages to programming in spannerlib, namely:\n",
    "* Better separation of concerns\n",
    "* Better inspectability of state\n",
    "\n",
    "The separation of spannerlib code into Data, Logic and stateless computation matches 4 distinct concerns in programming, each programmed in a modality suited to it namely:\n",
    "*  State management - using relational databases\n",
    "*  Data representation - using relation databases\n",
    "*  Algorithmic code - using state less IE functions\n",
    "*  Business Logic / Compositional Logic - Decleratve language that can orchestrate IE functions.\n",
    "\n",
    "This separation of concerns make the code better factored but also gives us better tools for common code maintenance tasks:\n",
    "* When we:\n",
    "  * want to reason about program state\n",
    "* Instead of:\n",
    "  * inspecting state by going through long runtime inspections using debugger\n",
    "  * or changing existing code to add more logging or debugging prints\n",
    "* We can:\n",
    "  * query the DB for the state\n",
    "* Example:\n",
    "  * our debugging queries that looked at the document's per version.\n",
    "  * Note that even when we used vanilla python code, we still saved the state in spannerlib so we could inspect it\n",
    "\n",
    "* When we:\n",
    "  * want to trace intermediate state, for data provenance\n",
    "* Instead of:\n",
    "  * having to add support for this throughout the class hierarchy in our code\n",
    "  * or add logs and parse them\n",
    "* We can:\n",
    "  * extend the schema of rules to save auxiliary information.\n",
    "* Example:\n",
    "  * Adding the `Derived` from column in the `CovidTags` relation so we can see where each tuple came from.\n",
    "\n",
    "* When: \n",
    "  * writing algorithmic code,\n",
    "* Instead of \n",
    "  * reasoning about state or making decisions about data representation.\n",
    "* We can:\n",
    "  * simply find a relational schema that matches\n",
    "\n",
    "* When \n",
    "  * business logic changes,\n",
    "  * changeing the compositional logic of the pipeline but not the core of the product\n",
    "  *  which is most of the time\n",
    "* Intead of:\n",
    "  * having to change both the class structure to support the additional data\n",
    "  * and the pipeline code\n",
    "* We can \n",
    "  * simply refactor the declarative code, which automatically refactors the data representation with it. \n",
    "* Example:\n",
    "  * Adding the PostProcessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But how much of this is really new?\n",
    "\n",
    "Spannerlib's approach while innovative, is combination of several known techniques and approaches in the IE and Programming Languages literature namely:\n",
    "- [Document Spanners](https://dl.acm.org/doi/10.1145/2699442)\n",
    "  - Which gives us the `Span` primitives that simplify a lot of extraction tasks on text.\n",
    "- [Declarative Information Extraction with Embedded Extraction Predicates](https://pages.cs.wisc.edu/~naughton/includes/papers/declarativeInformationExtraction.pdf)\n",
    "  - Which allows us to simplify imperative compositional code via declarative code over imperative stateless functions.\n",
    "  - This is the python in Spannerlog embedding.\n",
    "- [Generative Programming](https://dl.acm.org/doi/10.5555/345203)\n",
    "  - Which gives describes techniques for reducing repetitive code by:\n",
    "    - Using a high level programming language as a composition engine of\n",
    "    - A DSL which is suited to the programming domain which\n",
    "    - Generates lower level code.\n",
    "  - This gives us the Spannerlog in python embedding.\n",
    "\n",
    "Spannerlib's innovation comes from several key nuances that reduces the barrier of entry to the benefit of formal IE, and enables it to be used as a generative programming engine for a very wide array of tasks.\n",
    "* We realize, following the IE literature, that declarative query languages, onces paired with imperative callbacks, provide a very generic DSL for function composition, that encompasses a large percentage of pipeline composition code today.\n",
    "  * Combining the Generative programming paradigm with formal IE systems.\n",
    "* Unlike existing formal IE systems, like [SystemT](https://aclanthology.org/N18-3010/), we reduce the barrier of entry for new programmers by\n",
    "  * reducing the barrier of entry for lay programmers to insert IE functions into our system.\n",
    "  * reduce the learning curve for our system by formally extending existing, well known, and simple declarative languages (Datalog).\n",
    "* Improving adoption and developer velocity by\n",
    "  * Putting an emphasis on concise interplay and a tiny interphase for communicating between the host language (python) and our framework\n",
    "  * Packaging it as a python library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full break down of lines of code of the spannerlib implementation divided into sections of the original code.\n",
    "\n",
    "| Section                 | Code Type      | ~#code lines       | Comment                                                                             |\n",
    "|-------------------------|----------------|--------------------|-------------------------------------------------------------------------------------|\n",
    "| Context Matcher         | Data           | 54                 | lemma words (33) and concept tag rules (19)                                         |\n",
    "|                         | IE functions   | 30                 | POS and lemma IEs                                                                   |\n",
    "|                         | Spannerlog     | 18                 |                                                                                     |\n",
    "|                         | Vanilla Python | 19                 | half of the rewritting logic                                                        |\n",
    "| Target Matcher          | Data           | 20                 | target rules                                                                        |\n",
    "|                         | Spannerlog     | 5                  |                                                                                     |\n",
    "|                         | vanila python  | 20                 | half of the rewritting logic                                                        |\n",
    "| Sectionizer             | Data           | 120                | Section rules and positive sections (need to squash the section rules per category) |\n",
    "|                         | Spannerlog     | 6                  |                                                                                     |\n",
    "| Context                 | Data           | 172                | sentence context rules                                                              |\n",
    "|                         | IE functions   | 16                 |                                                                                     |\n",
    "|                         | Spannerlog     | 22                 |                                                                                     |\n",
    "| Post Processing         | Data           | 12                 | different post processing rules                                                     |\n",
    "|                         | Spannerlog     | 22                 |                                                                                     |\n",
    "| Document Classification | Agg functions  | 30                 |                                                                                     |\n",
    "|                         | Spannerlog     | 6                  |                                                                                     |\n",
    "| Other                   | vanilla python | 79                 | imports, configurations and main pipeline                                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
