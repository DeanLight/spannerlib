{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_showdoc: true\n",
    "#| skip_exec: true\n",
    "# TODO opt redo this notebook after implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from spannerlib.general_utils import QUERY_RESULT_PREFIX\n",
    "from spannerlib.tests.utils import run_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.long\n",
    "def test_quote() -> None:\n",
    "    quoted_phrase = r'''\\\"I'm going to Hawaii.\\\"'''\n",
    "    commands = f\"\"\"sentence = \"In the summer Joe Smith decided to go on vacation.  He said, {quoted_phrase}. That July, vacationer Joe went to Hawaii.\"\n",
    "               cool_quote(A,S,D,F,G,H,J,K,L,P) <- Quote(sentence) -> (A,S,D,F,G,H,J,K,L,P)\n",
    "               ?cool_quote(A,S,D,F,G,H,J,K,L,P)\"\"\"\n",
    "\n",
    "    expected_result = (fr\"\"\"{QUERY_RESULT_PREFIX}'cool_quote(A, S, D, F, G, H, J, K, L, P)':\n",
    "                       A |           S           |   D |   F |   G |   H |   J |   K |     L     |     P\n",
    "                    -----+-----------------------+-----+-----+-----+-----+-----+-----+-----------+-----------\n",
    "                       0 | I'm going to Hawaii.\\ |  62 |  85 |  15 |  23 |   1 |   2 | Joe Smith | Joe Smith\n",
    "                       \"\"\")\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_quote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tokenize() -> None:\n",
    "    commands = \"\"\"\n",
    "                    sentence = \"Hello world. Hello world again.\"\n",
    "                    tokens(X, Y) <- Tokenize(sentence) -> (X, Y)\n",
    "                    ?tokens(Token, Span)\n",
    "                \"\"\"\n",
    "\n",
    "    expected_result = f\"\"\"{QUERY_RESULT_PREFIX}'tokens(Token, Span)':\n",
    "  Token  |   Span\n",
    "---------+----------\n",
    "    .    | [30, 31)\n",
    "  again  | [25, 30)\n",
    "  world  | [19, 24)\n",
    "  Hello  | [13, 18)\n",
    "    .    | [11, 12)\n",
    "  world  | [6, 11)\n",
    "  Hello  |  [0, 5)\n",
    "\"\"\"\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ssplit() -> None:\n",
    "    commands = \"\"\"\n",
    "                sentence = \"Hello world. Hello world again.\"\n",
    "                sentences(X) <- SSplit(sentence) -> (X)\n",
    "                ?sentences(Sentences)\n",
    "                \"\"\"\n",
    "\n",
    "    expected_result = f\"\"\"{QUERY_RESULT_PREFIX}'sentences(Sentences)':\n",
    "                          Sentences\n",
    "                    ---------------------\n",
    "                     Hello world again .\n",
    "                        Hello world .\n",
    "                    \"\"\"\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_ssplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pos() -> None:\n",
    "    commands = \"\"\"\n",
    "                sentence = \"Marie was born in Paris.\"\n",
    "                pos(X, Y, Z) <- POS(sentence) -> (X, Y, Z)\n",
    "                ?pos(Token, POS, Span)\n",
    "            \"\"\"\n",
    "\n",
    "    expected_result = f\"\"\"{QUERY_RESULT_PREFIX}'pos(Token, POS, Span)':\n",
    "                      Token  |  POS  |   Span\n",
    "                    ---------+-------+----------\n",
    "                        .    |   .   | [23, 24)\n",
    "                      Paris  |  NNP  | [18, 23)\n",
    "                       in    |  IN   | [15, 17)\n",
    "                      born   |  VBN  | [10, 14)\n",
    "                       was   |  VBD  |  [6, 9)\n",
    "                      Marie  |  NNP  |  [0, 5)\n",
    "                    \"\"\"\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_lemma() -> None:\n",
    "    commands = \"\"\"\n",
    "                sentence = \"I've been living a lie, there's nothing inside.\"\n",
    "                lemma(X, Y, Z) <- Lemma(sentence) -> (X, Y, Z)\n",
    "                ?lemma(Token, Lemma, Span)\n",
    "                 \"\"\"\n",
    "\n",
    "    expected_result = f\"\"\"{QUERY_RESULT_PREFIX}'lemma(Token, Lemma, Span)':\n",
    "                      Token  |  Lemma  |   Span\n",
    "                    ---------+---------+----------\n",
    "                        .    |    .    | [46, 47)\n",
    "                     inside  | inside  | [40, 46)\n",
    "                     nothing | nothing | [32, 39)\n",
    "                       's    |   be    | [29, 31)\n",
    "                      there  |  there  | [24, 29)\n",
    "                        ,    |    ,    | [22, 23)\n",
    "                       lie   |   lie   | [19, 22)\n",
    "                        a    |    a    | [17, 18)\n",
    "                     living  |  live   | [10, 16)\n",
    "                      been   |   be    |  [5, 9)\n",
    "                       've   |  have   |  [1, 4)\n",
    "                        I    |    I    |  [0, 1)\n",
    "                    \"\"\"\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_lemma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.long\n",
    "def test_ner() -> None:\n",
    "    commands = (\"\"\"sentence = \"While in France, Christine Lagarde discussed short-term stimulus \"\"\"\n",
    "                \"\"\"efforts in a recent interview with the Wall Street Journal.\"\n",
    "               ner(X, Y, Z) <- NER(sentence) -> (X, Y, Z)\n",
    "               ?ner(Token, NER, Span)\"\"\")\n",
    "\n",
    "    expected_result = f\"\"\"{QUERY_RESULT_PREFIX}'ner(Token, NER, Span)':\n",
    "                       Token   |     NER      |    Span\n",
    "                    -----------+--------------+------------\n",
    "                      Journal  | ORGANIZATION | [116, 123)\n",
    "                      Street   | ORGANIZATION | [109, 115)\n",
    "                       Wall    | ORGANIZATION | [104, 108)\n",
    "                      Lagarde  |    PERSON    |  [27, 34)\n",
    "                     Christine |    PERSON    |  [17, 26)\n",
    "                      France   |   COUNTRY    |  [9, 15)\n",
    "                    \"\"\"\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_ner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.long\n",
    "def test_entity_mentions() -> None:\n",
    "    commands = \"\"\"sentence = \"New York Times newspaper is distributed in California.\"\n",
    "            em(X, Y, Z, W, A, B, C, D, E) <- EntityMentions(sentence) -> (X, Y, Z, W, A, B, C, D, E)\n",
    "            ?em(DocTokenBegin, DocTokenEnd, TokenBegin, TokenEnd, Text, \\\n",
    "            CharacterOffsetBegin, CharacterOffsetEnd, Ner, NerConfidences) \"\"\"\n",
    "\n",
    "    expected_result = (f\"\"\"{QUERY_RESULT_PREFIX}'em(DocTokenBegin, DocTokenEnd, TokenBegin, TokenEnd, Text,\"\"\"\n",
    "                       \"\"\" CharacterOffsetBegin, CharacterOffsetEnd, Ner, NerConfidences)':\n",
    "                       DocTokenBegin |   DocTokenEnd |   TokenBegin |   TokenEnd |      Text      |   \"\"\"\n",
    "                       \"\"\"CharacterOffsetBegin |   CharacterOffsetEnd |        Ner        |           NerConfidences\n",
    "                    -----------------+---------------+--------------+------------+----------------+-----------\"\"\"\n",
    "                       \"\"\"-------------+----------------------+-------------------+------------------------------------\n",
    "                                   7 |             8 |            7 |          8 |   California   |             \"\"\"\n",
    "                       \"\"\"        43 |                   53 | STATE_OR_PROVINCE |   {'LOCATION': 0.99823619336706}\n",
    "                                   0 |             3 |            0 |          3 | New York Times |             \"\"\"\n",
    "                       \"\"\"         0 |                   14 |   ORGANIZATION    | {'ORGANIZATION': 0.98456891831803}\n",
    "                    \"\"\")\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_entity_mentions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parse() -> None:\n",
    "    commands = \"\"\"sentence = \"the quick brown fox jumps over the lazy dog\"\n",
    "           parse(X) <- Parse(sentence) -> (X)\n",
    "           ?parse(X)\"\"\"\n",
    "\n",
    "    expected_result = (f\"\"\"{QUERY_RESULT_PREFIX}'parse(X)':\n",
    "                                                                                                    X\n",
    "                    ----------------------------------------------------------------------------------------\"\"\"\n",
    "                       \"\"\"-------------------------------------------------------------------------\n",
    "                     (ROOT<nl>  (S<nl>    (NP (DT the) (JJ quick) (JJ brown) (NN fox))<nl>    (VP (VBZ jumps)<nl>\"\"\"\n",
    "                       \"\"\"      (PP (IN over)<nl>        (NP (DT the) (JJ lazy) (NN dog))))))\"\"\")\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.long\n",
    "def test_depparse() -> None:\n",
    "    commands = \"\"\"sentence = \"the quick brown fox jumps over the lazy dog\"\n",
    "                depparse(X, Y, Z, W, U) <- DepParse(sentence) -> (X, Y, Z, W, U)\n",
    "                ?depparse(Dep, Governor, GovernorGloss, Dependent, DependentGloss)\"\"\"\n",
    "\n",
    "    expected_result = f\"\"\"{QUERY_RESULT_PREFIX}'depparse(Dep, Governor, GovernorGloss, Dependent, DependentGloss)':\n",
    "                          Dep  |   Governor |  GovernorGloss  |   Dependent |  DependentGloss\n",
    "                        -------+------------+-----------------+-------------+------------------\n",
    "                          obl  |          5 |      jumps      |           9 |       dog\n",
    "                         amod  |          9 |       dog       |           8 |       lazy\n",
    "                          det  |          9 |       dog       |           7 |       the\n",
    "                         case  |          9 |       dog       |           6 |       over\n",
    "                         nsubj |          5 |      jumps      |           4 |       fox\n",
    "                         amod  |          4 |       fox       |           3 |      brown\n",
    "                         amod  |          4 |       fox       |           2 |      quick\n",
    "                          det  |          4 |       fox       |           1 |       the\n",
    "                         ROOT  |          0 |      ROOT       |           5 |      jumps\n",
    "                         \"\"\"\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_depparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.long\n",
    "def test_coref() -> None:\n",
    "    commands = \"\"\"sentence = \"The atom is a basic unit of matter, \\\n",
    "                    it consists of a dense central nucleus surrounded by a cloud of negatively charged electrons.\"\n",
    "            coref(X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12) <- \\\n",
    "            Coref(sentence) -> (X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12)\n",
    "            ?coref(Id, Text, Type, Number, Gender, Animacy, StartIndex, \\\n",
    "            EndIndex, HeadIndex, SentNum, Position, IsRepresentativeMention)\"\"\"\n",
    "\n",
    "    expected_result = (f\"\"\"{QUERY_RESULT_PREFIX}'coref(Id, Text, Type, Number, Gender, Animacy, StartIndex,\"\"\"\n",
    "                       \"\"\" EndIndex, HeadIndex, SentNum, Position, IsRepresentativeMention)':\n",
    "                           Id |   Text   |    Type    |  Number  |  Gender  |  Animacy  |   StartIndex |   EndIndex\"\"\"\n",
    "                       \"\"\" |   HeadIndex |   SentNum |  Position  |  IsRepresentativeMention\n",
    "                        ------+----------+------------+----------+----------+-----------+--------------+------------\"\"\"\n",
    "                       \"\"\"+-------------+-----------+------------+---------------------------\n",
    "                            3 |    it    | PRONOMINAL | SINGULAR | NEUTRAL  | INANIMATE |           10 |         11\"\"\"\n",
    "                       \"\"\" |          10 |         1 |   [1, 4)   |           False\n",
    "                            0 | The atom |  NOMINAL   | SINGULAR | NEUTRAL  | INANIMATE |            1 |          3\"\"\"\n",
    "                       \"\"\" |           2 |         1 |   [1, 1)   |           True\"\"\")\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_coref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.long\n",
    "def test_openie() -> None:\n",
    "    commands = \"\"\"sentence = \"the quick brown fox jumps over the lazy dog\"\n",
    "               openie(X1, X2, X3, X4, X5, X6) <- OpenIE(sentence) -> (X1, X2, X3, X4, X5, X6)\n",
    "               ?openie(Subject, SubjectSpan, Relation, RelationSpan, Object, ObjectSpan)\"\"\"\n",
    "\n",
    "    expected_result = (f\"\"\"{QUERY_RESULT_PREFIX}'openie(Subject, SubjectSpan, Relation, RelationSpan,\"\"\"\n",
    "                       \"\"\" Object, ObjectSpan)':\n",
    "                             Subject     |  SubjectSpan  |  Relation  |  RelationSpan  |  Object  |  ObjectSpan\n",
    "                        -----------------+---------------+------------+----------------+----------+--------------\n",
    "                            brown fox    |    [2, 4)     | jumps over |     [4, 6)     | lazy dog |    [7, 9)\n",
    "                               fox       |    [3, 4)     | jumps over |     [4, 6)     | lazy dog |    [7, 9)\n",
    "                            quick fox    |    [1, 4)     | jumps over |     [4, 6)     | lazy dog |    [7, 9)\n",
    "                            quick fox    |    [1, 4)     | jumps over |     [4, 6)     |   dog    |    [8, 9)\n",
    "                         quick brown fox |    [1, 4)     | jumps over |     [4, 6)     |   dog    |    [8, 9)\n",
    "                            brown fox    |    [2, 4)     | jumps over |     [4, 6)     |   dog    |    [8, 9)\n",
    "                               fox       |    [3, 4)     | jumps over |     [4, 6)     |   dog    |    [8, 9)\n",
    "                         quick brown fox |    [1, 4)     | jumps over |     [4, 6)     | lazy dog |    [7, 9)\n",
    "                        \"\"\")\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_openie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this test uses 3+ GB of RAM\n",
    "@pytest.mark.long\n",
    "def test_kbp() -> None:\n",
    "    commands = \"\"\"sentence = \"Joe Smith was born in Oregon.\"\n",
    "              kbp(X1, X2, X3, X4, X5, X6) <- KBP(sentence) -> (X1, X2, X3, X4, X5, X6)\n",
    "              ?kbp(Subject, SubjectSpan, Relation, RelationSpan, Object, ObjectSpan)\"\"\"\n",
    "\n",
    "    expected_result = (f\"\"\"{QUERY_RESULT_PREFIX}'kbp(Subject, SubjectSpan, Relation, RelationSpan, Object,\"\"\"\n",
    "                       \"\"\" ObjectSpan)':\n",
    "                          Subject  |  SubjectSpan  |           Relation           |  RelationSpan  |  Object  |\"\"\"\n",
    "                       \"\"\"  ObjectSpan\n",
    "                        -----------+---------------+------------------------------+----------------+----------+---\"\"\"\n",
    "                       \"\"\"-----------\n",
    "                         Joe Smith |    [0, 2)     | per:stateorprovince_of_birth |    [-2, -1)    |  Oregon  |    \"\"\"\n",
    "                       \"\"\"[5, 6)\"\"\")\n",
    "\n",
    "    # run_test(commands, expected_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentiment() -> None:\n",
    "    commands = \"\"\"sentence = \"But I do not want to go among mad people, Alice remarked.\\\n",
    "                Oh, you can not help that, said the Cat: we are all mad here. I am mad. You are mad.\\\n",
    "                How do you know I am mad? said Alice.\\\n",
    "                You must be, said the Cat, or you would not have come here. This is awful, bad, disgusting\"\n",
    "               sentiment(X, Y, Z) <- Sentiment(sentence) -> (X, Y, Z)\n",
    "               ?sentiment(SentimentValue, Sentiment, SentimentDistribution)\"\"\"\n",
    "\n",
    "    expected_result = (f\"\"\"{QUERY_RESULT_PREFIX}'sentiment(SentimentValue, Sentiment, SentimentDistribution)':\n",
    "                           SentimentValue |  Sentiment  |                                   SentimentDistribution\n",
    "                        ------------------+-------------+-------------------------------------------------------\"\"\"\n",
    "                       \"\"\"-------------------------------------\n",
    "                                        1 |  Negative   | [0.38530939547592, 0.40530204971517, 0.15108253421994, \"\"\"\n",
    "                       \"\"\"0.0344418112832, 0.02386420930578]\n",
    "                                        1 |  Negative   | [0.12830923590495, 0.37878858881094, 0.30518256399302,\"\"\"\n",
    "                       \"\"\" 0.1718067054989, 0.01591290579219]\n",
    "                                        2 |   Neutral   |  [4.32842857e-06, 0.00178165446312, 0.99514483788581,\"\"\"\n",
    "                       \"\"\" 0.00300054886868, 6.863035382e-05]\n",
    "                                        2 |   Neutral   | [0.05362880533407, 0.34651236390176, 0.49340993668151,\"\"\"\n",
    "                       \"\"\" 0.10427916689283, 0.00216972718983]\n",
    "                                        2 |   Neutral   | [0.02439193942712, 0.30967820316829, 0.58893236904834,\"\"\"\n",
    "                       \"\"\" 0.0763362330424, 0.00066125531385]\n",
    "                                        2 |   Neutral   | [0.01782223769627, 0.29955831565507, 0.61735992863662,\"\"\"\n",
    "                       \"\"\" 0.06487534397678, 0.00038417403527]\n",
    "                                        1 |  Negative   | [0.12830922491145, 0.37878858297753, 0.30518256852813,\"\"\"\n",
    "                       \"\"\" 0.17180671895586, 0.01591290462702]\n",
    "                                        1 |  Negative   | [0.10061981563996, 0.47061477615492, 0.34369414180068,\"\"\"\n",
    "                       \"\"\" 0.0811364260425, 0.00393484036195]\n",
    "                        \"\"\")\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.long\n",
    "def test_truecase() -> None:\n",
    "    commands = \"\"\"sentence = \"lonzo ball talked about kobe bryant after the lakers game.\"\n",
    "              truecase(X, Y, Z, W) <- TrueCase(sentence) -> (X, Y, Z, W)\n",
    "              ?truecase(Token, Span, Truecase, TruecaseText)\"\"\"\n",
    "\n",
    "    expected_result = f\"\"\"{QUERY_RESULT_PREFIX}'truecase(Token, Span, Truecase, TruecaseText)':\n",
    "                          Token  |   Span   |  Truecase  |  TruecaseText\n",
    "                        ---------+----------+------------+----------------\n",
    "                            .    | [57, 58) |     O      |       .\n",
    "                          game   | [53, 57) |   LOWER    |      game\n",
    "                         lakers  | [46, 52) | INIT_UPPER |     Lakers\n",
    "                           the   | [42, 45) |   LOWER    |      the\n",
    "                          after  | [36, 41) |   LOWER    |     after\n",
    "                         bryant  | [29, 35) | INIT_UPPER |     Bryant\n",
    "                          kobe   | [24, 28) | INIT_UPPER |      Kobe\n",
    "                          about  | [18, 23) |   LOWER    |     about\n",
    "                         talked  | [11, 17) |   LOWER    |     talked\n",
    "                          ball   | [6, 10)  | INIT_UPPER |      Ball\n",
    "                          lonzo  |  [0, 5)  | INIT_UPPER |     Lonzo\n",
    "                        \"\"\"\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "\n",
    "# test_truecase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clean_xml() -> None:\n",
    "    commands = \"\"\"sentence = \"<xml><to>Tove</to>\\\n",
    "       <from>Jani</Ffrom>\\\n",
    "       <heading>Reminder</heading>\\\n",
    "       <body>Don't forget me this weekend!</body></xml>\"\n",
    "           clean_xml(X, Y, Z, W, U) <- CleanXML(sentence) -> (X, Y, Z, W, U)\n",
    "           ?clean_xml(Index, Word, OriginalText, CharacterOffsetBegin, CharacterOffsetEnd)\"\"\"\n",
    "\n",
    "    expected_result = (f\"\"\"{QUERY_RESULT_PREFIX}'clean_xml(Index, Word, OriginalText, CharacterOffsetBegin,\"\"\"\n",
    "                       \"\"\" CharacterOffsetEnd)':\n",
    "                           Index |   Word   |  OriginalText  |   CharacterOffsetBegin |   CharacterOffsetEnd\n",
    "                        ---------+----------+----------------+------------------------+----------------------\n",
    "                              -1 |    !     |       !        |                    118 |                  119\n",
    "                              -1 | weekend  |    weekend     |                    111 |                  118\n",
    "                              -1 |   this   |      this      |                    106 |                  110\n",
    "                              -1 |    me    |       me       |                    103 |                  105\n",
    "                              -1 |  forget  |     forget     |                     96 |                  102\n",
    "                              -1 |   n't    |      n't       |                     92 |                   95\n",
    "                              -1 |    Do    |       Do       |                     90 |                   92\n",
    "                              -1 | Reminder |    Reminder    |                     59 |                   67\n",
    "                              -1 |   Jani   |      Jani      |                     31 |                   35\n",
    "                              -1 |   Tove   |      Tove      |                      9 |                   13\n",
    "                        \"\"\")\n",
    "\n",
    "    run_test(commands, expected_result)\n",
    "# test_clean_xml()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
