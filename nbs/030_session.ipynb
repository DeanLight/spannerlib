{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Session Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Union, Optional, Callable, Type, Iterable, no_type_check, Sequence\n",
    "from fastcore.basics import patch\n",
    "from IPython import display\n",
    "from singleton_decorator import singleton\n",
    "from numbers import Real\n",
    "import pandas as pd\n",
    "import os\n",
    "from itables import init_notebook_mode,show\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from graph_rewrite import draw\n",
    "\n",
    "from spannerflow.span import Span\n",
    "from spannerlib.utils import checkLogs,get_base_file_path,assert_df_equals,DefaultIEs,DefaultAGGs\n",
    "from spannerlib.grammar import parse_spannerlog,reconstruct\n",
    "from spannerlib.data_types import (\n",
    "    _infer_relation_schema,\n",
    "     Var,\n",
    "    FreeVar,\n",
    "    RelationDefinition,\n",
    "    Relation,\n",
    "    IEFunction,\n",
    "    AGGFunction,\n",
    "    IERelation,\n",
    "    Rule,\n",
    "    pretty,\n",
    ")\n",
    "from spannerlib.engine import Engine\n",
    "\n",
    "from spannerlib.micro_passes import (\n",
    "    convert_primitive_values_to_objects,\n",
    "    CheckReservedRelationNames,\n",
    "    dereference_vars,\n",
    "    check_referenced_paths_exist,\n",
    "    inline_aggregation,\n",
    "    relations_to_dataclasses,\n",
    "    verify_referenced_relations_and_functions,\n",
    "    rules_to_dataclasses,\n",
    "    check_rule_safety,\n",
    "    consistent_free_var_types_in_rule,\n",
    "    assignments_to_name_val_tuple,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _load_stdlib():\n",
    "    # make sure we import the modules that register the stdlib\n",
    "    import spannerlib.ie_func.basic \n",
    "    import spannerlib.ie_func.json_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _class_repr(x):\n",
    "    \"\"\"returns the repr of x if x is a Span, else returns x\n",
    "    used to display spans in a more readable way in pandas \n",
    "    \"\"\"\n",
    "    if not isinstance(x,(str,float,int,bool)):\n",
    "        return f\"{repr(x)}\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Session():\n",
    "    def __init__(self,\n",
    "    register_stdlib=True, # if True, registers the standard library of IEs and AGGs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A Session object is the main interface to the spannerlog engine. \n",
    "        It is used to parse, check semantics, plan and execute queries.\n",
    "        It allows importing data and callbacks to the Spannerlog engine and exporting data from the engine back to python.\n",
    "        \"\"\"\n",
    "\n",
    "        self.pass_stack = [\n",
    "            convert_primitive_values_to_objects,\n",
    "            CheckReservedRelationNames('spanner_'),\n",
    "            check_referenced_paths_exist,\n",
    "            dereference_vars,\n",
    "            inline_aggregation,\n",
    "            relations_to_dataclasses,\n",
    "            verify_referenced_relations_and_functions,\n",
    "            rules_to_dataclasses,\n",
    "            check_rule_safety,\n",
    "            consistent_free_var_types_in_rule,\n",
    "            assignments_to_name_val_tuple,\n",
    "        ]\n",
    "\n",
    "        self.clear(register_stdlib=register_stdlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def clear(self:Session,\n",
    "    register_stdlib=True, # if True, registers the standard library of IEs and AGGs\n",
    "    ):\n",
    "    \"\"\"Resets the engine and clears all relations, functions and rules.\"\"\"\n",
    "    self.engine = Engine()\n",
    "    if not register_stdlib:\n",
    "        return\n",
    "    _load_stdlib()\n",
    "    for ie_def in DefaultIEs().as_list():\n",
    "        self.register(*ie_def)\n",
    "    for agg_def in DefaultAGGs().as_list():\n",
    "        self.register_agg(*agg_def)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing information to spannerlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def register(self:Session,\n",
    "    name, # name of the IE function in spannerlog\n",
    "    func, # the python function that implements the IE\n",
    "    in_schema, # the schema of the input relation\n",
    "    out_schema, # the schema of the output relation\n",
    "    ):\n",
    "    \"\"\"Registers an IE function with the spannerlog engine.\"\"\"\n",
    "    ie_func_obj = IEFunction(name=name,func=func,in_schema=in_schema,out_schema=out_schema)\n",
    "    self.engine.set_ie_function(ie_func_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def register_agg(self:Session,\n",
    "        name, # name of the AGG function in spannerlog\n",
    "        func, # the python function that implements the AGG\n",
    "        in_schema, # the schema of the input relation, can be of arity 1 only\n",
    "        out_schema # the schema of the output relation, can be of arity 1 only\n",
    "    ):\n",
    "    \"\"\"Registers an AGG function with the spannerlog engine.\"\"\"\n",
    "    agg_func_obj = AGGFunction(name=name,func=func,in_schema=in_schema,out_schema=out_schema)\n",
    "    self.engine.set_agg_function(agg_func_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def import_csv(self:Session,\n",
    "        name:str, # name of the relation in spannerlog\n",
    "        csv_filepath:Union[str,Path], # path to the csv file\n",
    "        delim:str = None, # the delimiter of the csv file\n",
    "        has_header: bool = False, # does the first line is a header line\n",
    "    ):\n",
    "    \"\"\"Imports a csv file into the current session.\"\"\"\n",
    "    csv_file_name = Path(csv_filepath)\n",
    "    if not csv_file_name.is_file():\n",
    "        raise IOError(\"csv file does not exist\")\n",
    "    if os.stat(csv_file_name).st_size == 0:\n",
    "        raise IOError(\"csv file is empty\")\n",
    "    \n",
    "    with open(csv_file_name) as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter=delim)\n",
    "        first_row = next(reader)\n",
    "        if has_header:\n",
    "            first_row = next(reader)\n",
    "    scheme = _infer_relation_schema(first_row)\n",
    "    rel_def = RelationDefinition(name=name,scheme=scheme)\n",
    "    \n",
    "    if self.engine.get_relation(name):\n",
    "        if self.engine.get_relation(name) != rel_def:\n",
    "            raise ValueError(f\"Relation {name} already exists with a different schema\")\n",
    "    else:\n",
    "        self.engine.set_relation(rel_def)\n",
    "    self.engine.load_csv(name, csv_file_name, delim=delim, has_header=has_header)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def import_rel(self:Session,\n",
    "    name:str, # name of the relation in spannerlog\n",
    "    data:Union[str,Path,pd.DataFrame], # either a pandas dataframe or a path to a csv file\n",
    "    delim:str = None, # the delimiter of the csv file\n",
    "    has_header: bool = None, # does the first line is a header line\n",
    "    ):\n",
    "    \"\"\"Imports a relation into the current session, either from a dataframe or from a csv file.\"\"\"\n",
    "\n",
    "    if isinstance(data, (Path,str)):\n",
    "        self.import_csv(name,data,delim=delim,has_header=has_header)\n",
    "        return\n",
    "        \n",
    "    first_row = list(data.iloc[0,:])\n",
    "    scheme = _infer_relation_schema(first_row)\n",
    "    rel_def = RelationDefinition(name=name,scheme=scheme)\n",
    "    \n",
    "    if self.engine.get_relation(name):\n",
    "        if self.engine.get_relation(name) != rel_def:\n",
    "            raise ValueError(f\"Relation {name} already exists with a different schema\")\n",
    "    else:\n",
    "        self.engine.set_relation(rel_def)\n",
    "    self.engine.add_facts(name,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def import_var(self:Session,\n",
    "    name, # name of the variable in spannerlog\n",
    "    value, # the value of the variable\n",
    "    ):\n",
    "    \"\"\"Imports a variable into the current session.\"\"\"\n",
    "    self.engine.set_var(name,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data from spannerlog to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# parsing statements\n",
    "#TODO from here seperate parse and check semantics so we can know the number of statements\n",
    "# before we iterate on semantic checks that might depend on execution of previous statements\n",
    "@patch\n",
    "def _parse_code(self:Session,code):\n",
    "    \"\"\"Parses a spannerlog code snippet and returns a list of statements.\"\"\"\n",
    "    try:\n",
    "        statements = parse_spannerlog(code,split_statements=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Syntax ERROR:\\n{e}\\n\")\n",
    "        raise e\n",
    "    return statements\n",
    "\n",
    "@patch\n",
    "def _check_semantics(self:Session,statements):\n",
    "    \"\"\"An iterator for performing semantic checks on a list of statements.\n",
    "    Yields the AST and the Lark parse tree of each statement.\n",
    "\n",
    "    Each statement must be executed, between yields in order to check the semantics\n",
    "    of the next statement based on the side effects of the previous statement.\n",
    "    \"\"\"\n",
    "    for statement_nx,statement_lark in statements:\n",
    "        ast = statement_nx\n",
    "        for pass_ in self.pass_stack:\n",
    "            try:\n",
    "                pass_(ast,self.engine)\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"SEMANTIC ERROR:\\n\"\n",
    "                    f\"During semantic checks for statement \\n\\\"{reconstruct(statement_lark)}\\\"\\n\"\n",
    "                    f\"in pass {pass_} the following exception was raised:\\n{e}\\n\"\n",
    "                    )\n",
    "                raise e\n",
    "        yield ast,statement_lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "## executing statements\n",
    "def _statement_type_and_value(ast):\n",
    "    \"\"\"gets the type and value of a statement from the ast\n",
    "    assumes an ast with a single node\n",
    "    \"\"\"\n",
    "    statement_node = list(ast.nodes)[0]\n",
    "    node_data = ast.nodes[statement_node]\n",
    "    statement = node_data['type']\n",
    "    value = node_data['val']\n",
    "    return statement,value\n",
    "\n",
    "\n",
    "def _execute_statement(\n",
    "    ast, # networkx ast after semantic checks, should have a single node with a single statement\n",
    "    engine, # the spannerlog engine to execute the statement on\n",
    "    plan_only=False, # if True, plans queries returns the graph and root, but does not execute them\n",
    "    draw_graph=False, # if True, draws the graph of the query plan\n",
    "    ):\n",
    "    \"\"\"executes a single statement from the ast\n",
    "    \"\"\"\n",
    "    statement,value = _statement_type_and_value(ast)\n",
    "    match statement:\n",
    "        case 'assignment':\n",
    "            engine.set_var(*value)\n",
    "        case 'read_assignment':\n",
    "            engine.set_var(*value,read_from_file=True)\n",
    "        case 'add_fact':\n",
    "            engine.add_fact(value)\n",
    "        case 'remove_fact':\n",
    "            engine.del_fact(value)\n",
    "        case 'relation_declaration':\n",
    "            engine.set_relation(value)\n",
    "        case 'rule':\n",
    "            engine.add_rule(value)\n",
    "        case 'query':\n",
    "            graph,root = engine.plan_query(value)\n",
    "            if draw_graph:\n",
    "                draw(graph)\n",
    "            if plan_only:\n",
    "                return graph,root\n",
    "            return engine.execute_plan(graph,root)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown statement type {statement}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# formatting query results\n",
    "def _sort_df(df):\n",
    "    \"\"\"sort df, if possible by value of rows else sort by string representation of rows.        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        sorted_df = df.sort_values(by=list(df.columns))\n",
    "    except TypeError as e:\n",
    "        sorted_df = df.sort_values(by=list(df.columns),key=lambda x: tuple(str(i) for i in x) ) \n",
    "    return sorted_df\n",
    "\n",
    "def _format_results(res):\n",
    "    \"\"\"format the results of a query. if a boolean dataframe is returned, return the boolean value,\n",
    "    else sort the dataframe and reset the index.\n",
    "    \"\"\"\n",
    "    if not isinstance(res,pd.DataFrame):\n",
    "        return res\n",
    "    if res.shape == (1,0):\n",
    "        return True\n",
    "    elif res.shape == (0,0):\n",
    "        return False\n",
    "    else:\n",
    "        return _sort_df(res).reset_index(drop=True)\n",
    "\n",
    "def _display_result(result,statement_lark):\n",
    "    \"\"\"format the results and display it and the query that generated it to stdout\n",
    "    if its a dataframe, display it using itables\"\"\"\n",
    "    if result is None:\n",
    "        pass\n",
    "    elif isinstance(result,pd.DataFrame):\n",
    "        display.display(reconstruct(statement_lark))\n",
    "        show(_format_results(result).map(_class_repr)\n",
    "            .style.set_properties(**{\n",
    "                'overflow-wrap': 'break-word',\n",
    "                'max-width': '800px',\n",
    "                'text-align': 'left'}),\n",
    "            columnDefs=[{\n",
    "                \"targets\": list(result.columns),\n",
    "                \"render\": \"\"\"function(data, type, row) {\n",
    "                    return '<div style=\"white-space: normal; word-wrap: break-word;\">' + data + '</div>';\n",
    "                }\"\"\",\n",
    "                \"width\": \"300px\"\n",
    "            }],\n",
    "            eval_functions=True,\n",
    "            escape=True)\n",
    "    elif isinstance(result,bool):\n",
    "        display.display(reconstruct(statement_lark))\n",
    "        display.display(result)\n",
    "    else:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def export(self:Session,\n",
    "    code:str , # the spannerlog code to execute\n",
    "    display_results=False, # if True, displays the results of the query to screen\n",
    "    draw_query=False, # if True, draws the query graph of queries to screen\n",
    "    plan_query=False, # if True, if last statement is a query, plans the query and returns the query graph and root node.\n",
    "    return_statements_meta=False, # if True, returns both the return value and the statements meta data, used internally.\n",
    "    ):\n",
    "    \"\"\"Takes a string of spannerlog code, and executes it, returning the value of the last statement in the code string.\n",
    "    All statements that are not queries, return None.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    statements = []\n",
    "    parsed_statements = self._parse_code(code)\n",
    "    num_statements = len(parsed_statements)\n",
    "    \n",
    "    for statement_index,(clean_ast,statement_lark) in enumerate(self._check_semantics(parsed_statements)):\n",
    "        is_last_statement = statement_index == num_statements - 1\n",
    "        plan_only = plan_query and is_last_statement\n",
    "        try:\n",
    "            result = _execute_statement(clean_ast,self.engine,draw_graph=draw_query,plan_only=plan_only)\n",
    "            result = _format_results(result)\n",
    "        except Exception as e:\n",
    "            print(f\"RUNTIME ERROR:\\n\"\n",
    "                f\"During execution of statement \\n\\\"{reconstruct(statement_lark)}\\\"\\n\"\n",
    "                f\"the following exception was raised:\\n\"\n",
    "                )\n",
    "            raise e\n",
    "        \n",
    "        s_type,s_dataclass = _statement_type_and_value(clean_ast)\n",
    "        statements.append((s_type,s_dataclass,reconstruct(statement_lark)))\n",
    "        results.append(result)\n",
    "        if display_results:\n",
    "            _display_result(result,statement_lark)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        ret_val =  None\n",
    "    else:\n",
    "        ret_val =  results[-1]\n",
    "\n",
    "    if return_statements_meta:\n",
    "        return ret_val,statements\n",
    "    else:\n",
    "        return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch  \n",
    "def print_rules(self:Session):\n",
    "    \"\"\"Prints all the rules in the engine. and returns them as a list\"\"\"\n",
    "    rules = list(self.engine.rules_to_ids.keys())\n",
    "    for rule in rules:\n",
    "        print(rule)\n",
    "    return rules\n",
    "\n",
    "@patch\n",
    "def get_all_functions(self:Session):\n",
    "    \"\"\"Returns all the IEs and AGGs in the engine, as a nested dictionary of the form:\n",
    "    {\n",
    "        'ie':{name:IEFunction},\n",
    "        'agg':{name:AGGFunction}\n",
    "    }\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'ie':self.engine.ie_functions.copy(),\n",
    "        'agg':self.engine.agg_functions.copy()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are mostly used when debugging spannerlog code, to remove rules and relations we want to redefine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def remove_rule(self:Session,\n",
    "    rule:str # the rule string to remove\n",
    "    ):\n",
    "    \"\"\"removes a rule from the engine, rule string must be identical to the rule defined previously\n",
    "    \"\"\"\n",
    "    self.engine.del_rule(rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def remove_head(self:Session,head:str):\n",
    "    \"\"\"removes all rules of a given head relation\n",
    "    \"\"\"\n",
    "    self.engine.del_head(head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def remove_all_rules(self:Session):\n",
    "    \"\"\"removes all rules from the engine\n",
    "    \"\"\"\n",
    "    rules = list(self.engine.rules_to_ids.keys())\n",
    "    for rule in rules:\n",
    "        self.remove_rule(rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def remove_relation(self:Session,relation:str):\n",
    "    \"\"\"removes a relation from the engine, either a extrinsic or intrinsic relation\n",
    "    \"\"\"\n",
    "    self.engine.del_relation(relation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Test scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def test_session(\n",
    "    code_strings,\n",
    "    expected_outputs=None,# list of expected dfs\n",
    "    ie_funcs=None,# List of [name,func,in_scheme,out_scheme]\n",
    "    agg_funcs=None,\n",
    "    csvs=None,# List of [name,df]\n",
    "    debug=False,\n",
    "    display_results=True,\n",
    "    ):\n",
    "\n",
    "    sess=Session()\n",
    "\n",
    "    # add data\n",
    "    if csvs:\n",
    "        for name,df in csvs:\n",
    "            sess.import_rel(name,df)\n",
    "    # add ies\n",
    "    if ie_funcs:\n",
    "        for name,func,in_scheme,out_scheme in ie_funcs:\n",
    "            sess.register(name,func,in_scheme,out_scheme)\n",
    "    \n",
    "    if agg_funcs:\n",
    "        for name,func,in_scheme,out_scheme in agg_funcs:\n",
    "            sess.register_agg(name,func,in_scheme,out_scheme)\n",
    "\n",
    "    # normalize code strings and expected outputs to lists\n",
    "    if not isinstance(code_strings,list):\n",
    "        code_strings = [code_strings]\n",
    "    if expected_outputs is None:\n",
    "        expected_outputs = [None]*len(queries)\n",
    "        dont_assert = True\n",
    "    else:\n",
    "        dont_assert = False\n",
    "    if not isinstance(expected_outputs,list):\n",
    "        expected_outputs = [expected_outputs]\n",
    "\n",
    "    \n",
    "    for code,expected in zip(code_strings,expected_outputs):\n",
    "        try:\n",
    "            res = sess.export(code,display_results=True,draw_query=debug)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in code {code}\")\n",
    "            raise e\n",
    "        \n",
    "        if dont_assert:\n",
    "            continue\n",
    "        if isinstance(expected,pd.DataFrame) and isinstance(res,pd.DataFrame):\n",
    "            assert_df_equals(res,expected)\n",
    "        else:\n",
    "            assert res == expected, f\"expected {expected}, got {res}\"\n",
    "    return sess\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = Session()\n",
    "df1 = pd.DataFrame([['John Doe', 35],['Jane Smith', 28]],columns=['X','Y'])\n",
    "df2 = pd.DataFrame([['John Doe', 30]],columns=['X','Y'])\n",
    "\n",
    "sess.import_rel(\"AgeOfKids\",df1)\n",
    "display.display(sess.export(\"?AgeOfKids(X,Y)\"))\n",
    "sess.import_rel(\"AgeOfKids\",df2)\n",
    "display.display(sess.export(\"?AgeOfKids(X,Y)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#| hide\n",
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic export with metadata\n",
    "sess = Session()\n",
    "\n",
    "res = sess.export(\"\"\"\n",
    "new A(int)\n",
    "\"\"\")\n",
    "display.display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.engine.Relation_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# basic export with metadata\n",
    "sess = Session()\n",
    "\n",
    "res,meta = sess.export(\"\"\"\n",
    "new A(int)\n",
    "A(1)\n",
    "?A(X)\n",
    "\"\"\",return_statements_meta=True)\n",
    "display.display(res)\n",
    "\n",
    "assert meta == [\n",
    "    ('relation_declaration',\n",
    "        RelationDefinition(name='A', scheme=[int]),\n",
    "        'new A(int)'),\n",
    " ('add_fact', Relation(name='A', terms=[1], agg=None), 'A(1)'),\n",
    " ('query', Relation(name='A', terms=[FreeVar(name='X')], agg=None), '?A(X)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# test rule removal\n",
    "sess = Session()\n",
    "_ = sess.export('''\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    parent(\"Noah\", \"Oliver\")\n",
    "    parent(\"James\", \"Lucas\")\n",
    "    parent(\"Noah\", \"Benjamin\")\n",
    "    parent(\"Benjamin\", \"Mason\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y).\n",
    "    ancestor(X,Y) <- grandparent(X,Y).\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y).\n",
    "''')\n",
    "\n",
    "\n",
    "rules = sess.print_rules()\n",
    "assert rules == ['ancestor(X,Y) <- parent(X,Y).',\n",
    "'ancestor(X,Y) <- grandparent(X,Y).',\n",
    "'ancestor(X,Y) <- parent(X,Z),ancestor(Z,Y).',]\n",
    "\n",
    "sess.remove_rule(\"ancestor(X,Y) <- parent(X,Y).\")\n",
    "print(\"=\"*50)\n",
    "rules = sess.print_rules()\n",
    "assert rules == ['ancestor(X,Y) <- grandparent(X,Y).',\n",
    "'ancestor(X,Y) <- parent(X,Z),ancestor(Z,Y).',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# test clearing the engine\n",
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y).\n",
    "    ancestor(X,Y) <- grandparent(X,Y).\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y).\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.export(commands)\n",
    "session.print_rules()\n",
    "session.clear()\n",
    "assert session.print_rules() == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# importing relations from csv\n",
    "session = Session()\n",
    "session.import_rel(name=\"enrolled\",data=\"./sample_data/enrolled.csv\", delim=\",\")\n",
    "commands = \"\"\"\n",
    "enrolled(\"abigail\", \"chemistry\")\n",
    "?enrolled(X,Y)\n",
    "\"\"\"\n",
    "res = session.export(commands)\n",
    "assert_df_equals(res,pd.DataFrame([\n",
    "    [\"abigail\", \"chemistry\"],\n",
    "    [\"gale\", \"operating_systems\"],\n",
    "    [\"howard\", \"chemistry\"],\n",
    "    [\"howard\", \"physics\"],\n",
    "    [\"jordan\", \"chemistry\"],\n",
    "    [\"abigail\", \"operating_systems\"],\n",
    "],columns=[\"X\",\"Y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# importing relations from dataframe\n",
    "session = Session()\n",
    "lecturer_df = pd.DataFrame(([[\"walter\",\"chemistry\"], [\"linus\", \"operating_systems\"]]))\n",
    "session.import_rel(\"lecturer\",lecturer_df)\n",
    "commands = \"\"\" \n",
    "?lecturer(X,Y)\n",
    "\"\"\"\n",
    "res = session.export(commands)\n",
    "assert_df_equals(res,pd.DataFrame([\n",
    "    [\"walter\",\"chemistry\"],\n",
    "    [\"linus\", \"operating_systems\"]\n",
    "],columns=[\"X\",\"Y\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "test_session(\n",
    "    [\n",
    "        \"\"\"\n",
    "        new Parent(str, str)\n",
    "        Parent(\"Sam\", \"Noah\")\n",
    "        Parent(\"Noah\", \"Austin\")\n",
    "        Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "        GrandParent(G, C) <- Parent(G, M), Parent(M, C).\n",
    "        \"\"\",\n",
    "        \"\"\"?GrandParent(X, \"Austin\")\"\"\"\n",
    "    ],\n",
    "    expected_outputs = [\n",
    "        None,\n",
    "        pd.DataFrame({'X':['Sam']})\n",
    "    ],\n",
    "    # debug=True\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# constants in rule heads\n",
    "test_session(\n",
    "    [\n",
    "        \"\"\"\n",
    "        new Parent(str, str)\n",
    "        Parent(\"Sam\", \"Noah\")\n",
    "        Parent(\"Noah\", \"Austin\")\n",
    "        Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "        GrandParent(G, C) <- Parent(G, M), Parent(M, C).\n",
    "        # all grand parents are fun\n",
    "        FunGrandParent(G,C,\"yes\")<- GrandParent(G,C).\n",
    "        \"\"\",\n",
    "        \"\"\"?FunGrandParent(X, \"Austin\",AreFun)\"\"\"\n",
    "    ],\n",
    "    expected_outputs = [\n",
    "        None,\n",
    "        pd.DataFrame([\n",
    "            [\"Sam\",\"yes\"]\n",
    "        ],columns=[\"X\",\"AreFun\"])\n",
    "    ],\n",
    "    # debug=True\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def length(string: str) -> Iterable[int]:\n",
    "        yield (len(string),)\n",
    "\n",
    "_ =test_session(\n",
    "    [\"\"\"new string(str)\n",
    "    string(\"a\")\n",
    "    string(\"d\")\n",
    "    string(\"a\")\n",
    "    string(\"ab\")\n",
    "    string(\"abc\")\n",
    "    string(\"abcd\")\n",
    "\n",
    "    string_length(Str, Len) <- string(Str), Length(Str) -> (Len).\n",
    "\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    ?string_length(Str, Len)\n",
    "    \"\"\"],\n",
    "    [\n",
    "        None,\n",
    "        pd.DataFrame({'Str':['a','d','ab','abc','abcd'],'Len':[1,1,2,3,4]}),\n",
    "    ],\n",
    "    ie_funcs=[\n",
    "        ['Length',length,[str],[int]]\n",
    "    ],\n",
    "    # debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def ID(string: str):\n",
    "        yield f'{string}_id',\n",
    "\n",
    "def ID2(string: str):\n",
    "        yield f'{string}_id2_z',f'{string}_id2_w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# empty input to ie functions\n",
    "test_session(\n",
    "        \"\"\"\n",
    "        new A(str, str)\n",
    "        new B(str, str)\n",
    "        A(\"1\", \"2\")\n",
    "        B(\"1\", \"3_id\")\n",
    "        C(X, Y) <- A(X, Y).\n",
    "        D(X, Y, X) <- C(X, Y).\n",
    "        # nothing will feed into ID but we still need output in the same schema as the first D rule\n",
    "        D(X, Y, Z) <- A(X, \"1\"), B(X, Y), ID(X) -> (Y), ID2(Y)->(Z,W).\n",
    "        ?D(X, Y, Z)\n",
    "    \"\"\",\n",
    "    pd.DataFrame([['1','2','1']],columns=['X','Y','Z']),\n",
    "    ie_funcs=[\n",
    "        ['ID',ID,[str],[str]],\n",
    "        ['ID2',ID2,[str],[str,str]]\n",
    "    ] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "#multiple ie functions\n",
    "test_session(\n",
    "        \"\"\"\n",
    "        new A(str, str)\n",
    "        new B(str, str)\n",
    "        A(\"1\", \"2\")\n",
    "        B(\"1\", \"1_id\")\n",
    "        C(X, Y) <- A(X, Y).\n",
    "        D(X, Y, X) <- C(X, Y).\n",
    "        # nothing will feed into ID but we still need output in the same schema as the first D rule\n",
    "        D(X, Y, Z) <- A(X, \"2\"), B(X, Y), ID(X) -> (Y), ID2(Y)->(Z,W).\n",
    "        ?D(X, Y, Z)\n",
    "    \"\"\",\n",
    "    pd.DataFrame([('1', '1_id', '1_id_id2_z'), ('1', '2', '1')],columns=['X','Y','Z']),\n",
    "    ie_funcs=[\n",
    "        ['ID',ID,[str],[str]],\n",
    "        ['ID2',ID2,[str],[str,str]]\n",
    "    ] \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# ie functions bounded by constants\n",
    "def split(string: str):\n",
    "    for part in string.split():\n",
    "        yield (part,)\n",
    "\n",
    "test_session(\n",
    "    [\"\"\"\n",
    "    new String(str)\n",
    "    String(\"he\")\n",
    "    String(\"hehe\")\n",
    "    Text(T) <- Split(\"he ho hehe hoho\")->(T).\n",
    "    StringFromText(S) <- String(S), Split(\"he ho hehe hoho\")->(S).\n",
    "    ?StringFromText(S)\n",
    "    \"\"\",\n",
    "    \"\"\"?Text(T)\"\"\"\n",
    "    ],\n",
    "    [\n",
    "        pd.DataFrame({'S':['he','hehe']}),\n",
    "        pd.DataFrame({'T':['he','ho','hehe','hoho']})\n",
    "    ],   \n",
    "    ie_funcs=[\n",
    "        ['Split',split,[str],[str]]\n",
    "    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Boolean queries\n",
    "\n",
    "test_session(\n",
    "    [\"\"\"\n",
    "    new Parent(str, str)\n",
    "    Parent(\"Sam\", \"Noah\")\n",
    "    Parent(\"Noah\", \"Austin\")\n",
    "    Parent(\"Austin\", \"Stephen\")\n",
    "    GrandParent(G, C) <- Parent(G, M), Parent(M, C).\n",
    "    ?GrandParent(\"Sam\", \"Austin\")\n",
    "    \"\"\",\n",
    "    \"\"\"?GrandParent(\"Bob\", \"Austin\")\"\"\"\n",
    "    ],\n",
    "    [\n",
    "        True,\n",
    "        False\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# use of ie functions with variable output arity\n",
    "sess = test_session(\n",
    "    [\"\"\"\n",
    "    input_string = \"John Doe: 35 years old, Jane Smith: 28 years old\"\n",
    "    AgeOf(Name,Age) <- \n",
    "        rgx(\"(\\w+\\s\\w+):\\s(\\d+)\",$input_string) -> (NameSpan,AgeSpan),\n",
    "        as_str(NameSpan)->(Name),\n",
    "        as_str(AgeSpan)->(Age).\n",
    "    \"\"\",\"\"\"\n",
    "    ?AgeOf(X,Y)\n",
    "    \"\"\"],\n",
    "    [\n",
    "        None,\n",
    "        pd.DataFrame({'X':[\"John Doe\",\"Jane Smith\"],'Y':[\"35\",\"28\"]}),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def format_ie(f_string,*params):\n",
    "    yield f_string.format(*params),\n",
    "\n",
    "string_schema = lambda x: ([str]*x)\n",
    "\n",
    "test_session(\n",
    "\"\"\"\n",
    "new AgeOf(str, str)\n",
    "AgeOf(\"John Doe\", \"35\")\n",
    "AgeOf(\"Jane Smith\", \"28\")\n",
    "age_description(Desc) <- AgeOf(Name, Age), format(\"{} is {} years old\",Name,Age) -> (Desc).\n",
    "?age_description(D)\n",
    "\"\"\",\n",
    "pd.DataFrame({'D':['Jane Smith is 28 years old','John Doe is 35 years old']}),\n",
    "ie_funcs=[['format',format_ie,string_schema,[str]]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "test_session(\n",
    "\"\"\"\n",
    "new AgeOfKids(str, int)\n",
    "AgeOfKids(\"John Doe\", 35)\n",
    "AgeOfKids(\"John Doe\", 30)\n",
    "AgeOfKids(\"Jane Smith\", 28)\n",
    "total_age(X,sum(Y)) <- AgeOfKids(X,Y).\n",
    "?total_age(X,T)\n",
    "\"\"\",\n",
    "pd.DataFrame({'X':['John Doe','Jane Smith'],'T':[65,28]}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
