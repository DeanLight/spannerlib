{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro Passes\n",
    "> passes over the AST of a statement to do semantic checks and register state in the session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp micro_passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "import pytest\n",
    "\n",
    "# from lark import Transformer, Token\n",
    "# from lark import Tree as LarkNode\n",
    "# from lark.visitors import Interpreter, Visitor_Recursive, Visitor\n",
    "from pathlib import Path\n",
    "from typing import no_type_check, Set, Sequence, Any,Optional,List,Callable,Dict,Union\n",
    "from pydantic import BaseModel\n",
    "import networkx as nx\n",
    "\n",
    "# from spannerlib.ast_node_types import (Assignment, ReadAssignment, AddFact, RemoveFact, Query, Rule, IERelation, RelationDeclaration, Relation)\n",
    "from spannerlib.primitive_types import Span, DataTypes, DataTypeMapping\n",
    "# from spannerlib.engine import RESERVED_RELATION_PREFIX\n",
    "# # from spannerlib.graphs import NetxStateGraph\n",
    "# from spannerlib.symbol_table import SymbolTableBase\n",
    "# from spannerlib.general_utils import (get_free_var_names, get_output_free_var_names, get_input_free_var_names, fixed_point, check_properly_typed_relation, type_check_rule_free_vars)\n",
    "# from spannerlib.passes_utils import assert_expected_node_structure, unravel_lark_node,ParseNodeType\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from graph_rewrite import draw, draw_match, rewrite, rewrite_iter\n",
    "from spannerlib.utils import checkLogs,serialize_df_values,serialize_tree\n",
    "from spannerlib.grammar import parse_spannerlog\n",
    "from spannerlib.span import Span\n",
    "from spannerlib.engine import (\n",
    "    Engine,\n",
    "    Var,\n",
    "    FreeVar,\n",
    "    RelationDefinition,\n",
    "    Relation,\n",
    "    IEFunction,\n",
    "    IERelation,\n",
    "    Rule,\n",
    "    pretty,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummySession():\n",
    "    def __init__(self,passes=None,execution_function=None):\n",
    "        if passes is None:\n",
    "            passes = []\n",
    "        self.passes = passes\n",
    "        self.engine=Engine()\n",
    "        self.should_execute = execution_function is not None\n",
    "        self.execution_function = execution_function\n",
    "\n",
    "    def run_query(self,query):\n",
    "        statements = parse_spannerlog(query,split_statements=True)\n",
    "        clean_asts = []\n",
    "        results = []\n",
    "        for statement in statements:\n",
    "            ast = statement\n",
    "            for pass_ in self.passes:\n",
    "                pass_(ast,self.engine)\n",
    "            clean_asts.append(ast)\n",
    "\n",
    "            if self.should_execute:\n",
    "                results.append(self.execution_function(ast,self.engine))\n",
    "        if self.should_execute:\n",
    "            return results\n",
    "        else:\n",
    "            return clean_asts\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVsYXRpb25fZGVjbGFyYXRpb24jcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjJbIjIKdmFsPSNxdW90O3N0cmluZyNxdW90OyJdCjNbIjMKdHlwZT0jcXVvdDtkZWNsX3Rlcm1fbGlzdCNxdW90OyJdCjRbIjQKdmFsPSNxdW90O2RlY2xfc3RyaW5nI3F1b3Q7Il0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCjEgLS0+fCJpZHg9MCJ8IDIKMyAtLT58ImlkeD0wInwgNAo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjJbIjIKdmFsPSNxdW90O3N0cmluZyNxdW90OyJdCjNbIjMKdHlwZT0jcXVvdDtjb25zdF90ZXJtX2xpc3QjcXVvdDsiXQo0WyI0CnR5cGU9I3F1b3Q7c3RyaW5nI3F1b3Q7Il0KNVsiNQp2YWw9I3F1b3Q7I3F1b3Q7YSNxdW90OyNxdW90OyJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgMwoxIC0tPnwiaWR4PTAifCAyCjMgLS0+fCJpZHg9MCJ8IDQKNCAtLT58ImlkeD0wInwgNQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDtydWxlX2hlYWQjcXVvdDsiXQoyWyIyCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjNbIjMKdmFsPSNxdW90O3N0cmluZ19sZW5ndGgjcXVvdDsiXQo0WyI0CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZV9saXN0I3F1b3Q7Il0KNVsiNQp0eXBlPSNxdW90O2ZyZWVfdmFyX25hbWUjcXVvdDsiXQo2WyI2CnZhbD0jcXVvdDtTdHIjcXVvdDsiXQo3WyI3CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OyJdCjhbIjgKdmFsPSNxdW90O0xlbiNxdW90OyJdCjlbIjkKdHlwZT0jcXVvdDtydWxlX2JvZHlfcmVsYXRpb25fbGlzdCNxdW90OyJdCjEwWyIxMAp0eXBlPSNxdW90O3JlbGF0aW9uI3F1b3Q7Il0KMTFbIjExCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OyJdCjEyWyIxMgp2YWw9I3F1b3Q7c3RyaW5nI3F1b3Q7Il0KMTNbIjEzCnR5cGU9I3F1b3Q7dGVybV9saXN0I3F1b3Q7Il0KMTRbIjE0CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OyJdCjE1WyIxNQp2YWw9I3F1b3Q7U3RyI3F1b3Q7Il0KMTZbIjE2CnR5cGU9I3F1b3Q7aWVfcmVsYXRpb24jcXVvdDsiXQoxN1siMTcKdHlwZT0jcXVvdDtyZWxhdGlvbl9uYW1lI3F1b3Q7Il0KMThbIjE4CnZhbD0jcXVvdDtMZW5ndGgjcXVvdDsiXQoxOVsiMTkKdHlwZT0jcXVvdDt0ZXJtX2xpc3QjcXVvdDsiXQoyMFsiMjAKdHlwZT0jcXVvdDtmcmVlX3Zhcl9uYW1lI3F1b3Q7Il0KMjFbIjIxCnZhbD0jcXVvdDtTdHIjcXVvdDsiXQoyMlsiMjIKdHlwZT0jcXVvdDt0ZXJtX2xpc3QjcXVvdDsiXQoyM1siMjMKdHlwZT0jcXVvdDtmcmVlX3Zhcl9uYW1lI3F1b3Q7Il0KMjRbIjI0CnZhbD0jcXVvdDtMZW4jcXVvdDsiXQowIC0tPnwiaWR4PTAifCAxCjAgLS0+fCJpZHg9MSJ8IDkKMSAtLT58ImlkeD0wInwgMgoxIC0tPnwiaWR4PTEifCA0CjIgLS0+fCJpZHg9MCJ8IDMKNCAtLT58ImlkeD0wInwgNQo0IC0tPnwiaWR4PTEifCA3CjUgLS0+fCJpZHg9MCJ8IDYKNyAtLT58ImlkeD0wInwgOAo5IC0tPnwiaWR4PTAifCAxMAo5IC0tPnwiaWR4PTEifCAxNgoxMCAtLT58ImlkeD0wInwgMTEKMTAgLS0+fCJpZHg9MSJ8IDEzCjExIC0tPnwiaWR4PTAifCAxMgoxMyAtLT58ImlkeD0wInwgMTQKMTQgLS0+fCJpZHg9MCJ8IDE1CjE2IC0tPnwiaWR4PTAifCAxNwoxNiAtLT58ImlkeD0xInwgMTkKMTYgLS0+fCJpZHg9MiJ8IDIyCjE3IC0tPnwiaWR4PTAifCAxOAoxOSAtLT58ImlkeD0wInwgMjAKMjAgLS0+fCJpZHg9MCJ8IDIxCjIyIC0tPnwiaWR4PTAifCAyMwoyMyAtLT58ImlkeD0wInwgMjQK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sess = DummySession()\n",
    "asts = sess.run_query(\"\"\"\n",
    "            new string(str)\n",
    "            string(\"a\")\n",
    "            string_length(Str, Len) <- string(Str), Length(Str) -> (Len)\n",
    "            \"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert_primitive_values_to_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_primitive_values_to_objects(ast,session):\n",
    "\n",
    "    # primitive values\n",
    "    def cast_new_value(match):\n",
    "        val_type = match['var']['type']\n",
    "        value = match['val_node']['val']\n",
    "        if val_type == 'integer':\n",
    "            value = int(value)\n",
    "        elif val_type == 'var_name':\n",
    "            value = Var(name=value)\n",
    "        elif val_type == 'free_var_name':\n",
    "            value = FreeVar(name=value)\n",
    "        else:#str\n",
    "            value = str(value)\n",
    "        return value\n",
    "    \n",
    "    rewrite(ast,\n",
    "        lhs='var[type]->val_node[val]',\n",
    "        p='var[type]',\n",
    "        rhs='var[type,val={{new_val}}]',\n",
    "        condition= lambda match: match['var']['type'] in ['string','integer','var_name','relation_name','free_var_name'],\n",
    "        render_rhs={'new_val': cast_new_value},\n",
    "        # display_matches=True\n",
    "        )\n",
    "\n",
    "    # span object from 2 integers\n",
    "    for match in rewrite_iter(ast,\n",
    "        lhs='u[type=\"span\"]-[idx=0]->v;u-[idx=1]->w',\n",
    "        p='u[type]'):\n",
    "        match['u']['val']=Span(match['v']['val'],match['w']['val'])\n",
    "\n",
    "    # schema types into class types\n",
    "    decl_type_to_class = {\n",
    "        'decl_string':str,\n",
    "        'decl_int':int,\n",
    "        'decl_span':Span,\n",
    "    }\n",
    "\n",
    "    for decl_type,decl_class in decl_type_to_class.items():\n",
    "        for match in rewrite_iter(ast,lhs=f'x[val=\"{decl_type}\"]'):\n",
    "            match['x']['val']=decl_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDt2YXJfbmFtZSNxdW90OyJdCjJbIjIKdmFsPSNxdW90O3gjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7c3RyaW5nI3F1b3Q7Il0KNFsiNAp2YWw9I3F1b3Q7I3F1b3Q7YSNxdW90OyNxdW90OyJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgMwoxIC0tPnwiaWR4PTAifCAyCjMgLS0+fCJpZHg9MCJ8IDQK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "  # convert_primitive_values_to_objects\n",
    "  ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "            x=\"a\"\n",
    "            \"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDt2YXJfbmFtZSNxdW90OywgdmFsPVZhcihuYW1lPSNxdW90O3gjcXVvdDspIl0KM1siMwp0eXBlPSNxdW90O2ludGVnZXIjcXVvdDssIHZhbD0xIl0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1MjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7Y29uc3RfdGVybV9saXN0I3F1b3Q7Il0KNFsiNAp0eXBlPSNxdW90O3N0cmluZyNxdW90OywgdmFsPSNxdW90OyNxdW90O2EjcXVvdDsjcXVvdDsiXQo2WyI2CnR5cGU9I3F1b3Q7aW50ZWdlciNxdW90OywgdmFsPTEiXQo4WyI4CnR5cGU9I3F1b3Q7c3BhbiNxdW90OywgdmFsPVs0LDUpIl0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCjMgLS0+fCJpZHg9MCJ8IDQKMyAtLT58ImlkeD0xInwgNgozIC0tPnwiaWR4PTIifCA4Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVsYXRpb25fZGVjbGFyYXRpb24jcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1IjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7ZGVjbF90ZXJtX2xpc3QjcXVvdDsiXQo0WyI0CnZhbD0jbHQ7Y2xhc3MgI3F1b3Q7aW50I3F1b3Q7I2d0OyJdCjVbIjUKdmFsPSNsdDtjbGFzcyAjcXVvdDtzdHIjcXVvdDsjZ3Q7Il0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCjMgLS0+fCJpZHg9MCJ8IDQKMyAtLT58ImlkeD0xInwgNQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cXVlcnkjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1IjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7dGVybV9saXN0I3F1b3Q7Il0KNFsiNAp0eXBlPSNxdW90O3Zhcl9uYW1lI3F1b3Q7LCB2YWw9VmFyKG5hbWU9I3F1b3Q7eCNxdW90OykiXQo2WyI2CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OywgdmFsPUZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgMwozIC0tPnwiaWR4PTAifCA0CjMgLS0+fCJpZHg9MSJ8IDYK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDtydWxlX2hlYWQjcXVvdDsiXQoyWyIyCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1IjcXVvdDsiXQo0WyI0CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZV9saXN0I3F1b3Q7Il0KNVsiNQp0eXBlPSNxdW90O2ZyZWVfdmFyX25hbWUjcXVvdDssIHZhbD1GcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OykiXQo3WyI3CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OywgdmFsPUZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSJdCjlbIjkKdHlwZT0jcXVvdDtydWxlX2JvZHlfcmVsYXRpb25fbGlzdCNxdW90OyJdCjEwWyIxMAp0eXBlPSNxdW90O3JlbGF0aW9uI3F1b3Q7Il0KMTFbIjExCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1MjcXVvdDsiXQoxM1siMTMKdHlwZT0jcXVvdDt0ZXJtX2xpc3QjcXVvdDsiXQoxNFsiMTQKdHlwZT0jcXVvdDtmcmVlX3Zhcl9uYW1lI3F1b3Q7LCB2YWw9RnJlZVZhcihuYW1lPSNxdW90O1gjcXVvdDspIl0KMTZbIjE2CnR5cGU9I3F1b3Q7ZnJlZV92YXJfbmFtZSNxdW90OywgdmFsPUZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSJdCjAgLS0+fCJpZHg9MCJ8IDEKMCAtLT58ImlkeD0xInwgOQoxIC0tPnwiaWR4PTAifCAyCjEgLS0+fCJpZHg9MSJ8IDQKNCAtLT58ImlkeD0wInwgNQo0IC0tPnwiaWR4PTEifCA3CjkgLS0+fCJpZHg9MCJ8IDEwCjEwIC0tPnwiaWR4PTAifCAxMQoxMCAtLT58ImlkeD0xInwgMTMKMTMgLS0+fCJpZHg9MCJ8IDE0CjEzIC0tPnwiaWR4PTEifCAxNgo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[convert_primitive_values_to_objects])\n",
    "asts = sess.run_query(\"\"\"\n",
    "            x=1\n",
    "            S(\"a\",1,[4,5))\n",
    "            new R(int,str)\n",
    "            ?R(x,X)\n",
    "            R(X,Y)<-S(X,Y)\n",
    "            \"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "assert ([serialize_tree(ast) for ast in asts] ==  [{'type': 'assignment',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'var_name', 'val': Var(name='x'), 'id': 1},\n",
    "   {'type': 'integer', 'val': 1, 'id': 3}]},\n",
    " {'type': 'add_fact',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'relation_name', 'val': 'S', 'id': 1},\n",
    "   {'type': 'const_term_list',\n",
    "    'id': 3,\n",
    "    'children': [{'type': 'string', 'val': '\"a\"', 'id': 4},\n",
    "     {'type': 'integer', 'val': 1, 'id': 6},\n",
    "     {'type': 'span', 'val': Span(start=4, end=5), 'id': 8}]}]},\n",
    " {'type': 'relation_declaration',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'relation_name', 'val': 'R', 'id': 1},\n",
    "   {'type': 'decl_term_list',\n",
    "    'id': 3,\n",
    "    'children': [{'val': int, 'id': 4}, {'val': str, 'id': 5}]}]},\n",
    " {'type': 'query',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'relation_name', 'val': 'R', 'id': 1},\n",
    "   {'type': 'term_list',\n",
    "    'id': 3,\n",
    "    'children': [{'type': 'var_name', 'val': Var(name='x'), 'id': 4},\n",
    "     {'type': 'free_var_name', 'val': FreeVar(name='X'), 'id': 6}]}]},\n",
    " {'type': 'rule',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'rule_head',\n",
    "    'id': 1,\n",
    "    'children': [{'type': 'relation_name', 'val': 'R', 'id': 2},\n",
    "     {'type': 'free_var_name_list',\n",
    "      'id': 4,\n",
    "      'children': [{'type': 'free_var_name',\n",
    "        'val': FreeVar(name='X'),\n",
    "        'id': 5},\n",
    "       {'type': 'free_var_name', 'val': FreeVar(name='Y'), 'id': 7}]}]},\n",
    "   {'type': 'rule_body_relation_list',\n",
    "    'id': 9,\n",
    "    'children': [{'type': 'relation',\n",
    "      'id': 10,\n",
    "      'children': [{'type': 'relation_name', 'val': 'S', 'id': 11},\n",
    "       {'type': 'term_list',\n",
    "        'id': 13,\n",
    "        'children': [{'type': 'free_var_name',\n",
    "          'val': FreeVar(name='X'),\n",
    "          'id': 14},\n",
    "         {'type': 'free_var_name', 'val': FreeVar(name='Y'), 'id': 16}]}]}]}]}] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove newlines from strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_new_lines_from_strings(ast,engine):\n",
    "    for match in rewrite_iter(ast,\n",
    "        lhs='v[type=\"string\",val]'):\n",
    "        # TODO we also remove the starting and ending quotes, TODO make them disapear in the parsing stage\n",
    "        match['v']['val'] = match['v']['val'].replace('\\\\\\n','')[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDt2YXJfbmFtZSNxdW90OywgdmFsPVZhcihuYW1lPSNxdW90O3gjcXVvdDspIl0KM1siMwp0eXBlPSNxdW90O3N0cmluZyNxdW90OywgdmFsPSNxdW90O2hlbGxvIHdvcmxkI3F1b3Q7Il0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCAzCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "x=\"hello \\\n",
    "world\"\n",
    "\"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "ast = asts[0]\n",
    "assert serialize_tree(ast) == {'type': 'assignment',\n",
    " 'id': 0,\n",
    " 'children': [{'type': 'var_name', 'val': Var(name='x'), 'id': 1},\n",
    "  {'type': 'string', 'val': 'hello world', 'id': 3}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check reserved relation names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckReservedRelationNames():\n",
    "    def __init__(self,reserved_prefix):\n",
    "        self.reserved_prefix = reserved_prefix\n",
    "    def __call__(self,ast,engine):\n",
    "        for match in rewrite_iter(ast,lhs='X[type=\"relation_name\",val]'):\n",
    "            relation_name = match['X']['val']\n",
    "            if relation_name.startswith(self.reserved_prefix):\n",
    "                raise ValueError(f\"Relation name '{relation_name}' starts with reserved prefix '{self.reserved_prefix}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation name 'spanner_S' starts with reserved prefix 'spanner_'\n"
     ]
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "            S(\"a\",1)\n",
    "            R(X,Y)<-S(X,Y),T(X,Y)\n",
    "            \"\"\")\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "            spanner_S(\"a\",1)\n",
    "            \"\"\")\n",
    "print(exc_info.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDsiXQoxWyIxCnR5cGU9I3F1b3Q7cmVsYXRpb25fbmFtZSNxdW90OywgdmFsPSNxdW90O1MjcXVvdDsiXQozWyIzCnR5cGU9I3F1b3Q7Y29uc3RfdGVybV9saXN0I3F1b3Q7Il0KNFsiNAp0eXBlPSNxdW90O3N0cmluZyNxdW90OywgdmFsPSNxdW90O2EjcXVvdDsiXQo2WyI2CnR5cGU9I3F1b3Q7aW50ZWdlciNxdW90OywgdmFsPTEiXQowIC0tPnwiaWR4PTAifCAxCjAgLS0+fCJpZHg9MSJ8IDMKMyAtLT58ImlkeD0wInwgNAozIC0tPnwiaWR4PTEifCA2Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(asts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check read assignments got existing path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def check_referenced_paths_exist(ast,engine):\n",
    "    for match in rewrite_iter(ast,\n",
    "    lhs='X[type=\"read_assignment\"]-[idx=1]->PathNode[val]',\n",
    "    # display_matches=True\n",
    "    ):\n",
    "        path = Path(match['PathNode']['val'])\n",
    "        if not path.exists():\n",
    "            raise ValueError(f'path {path} was not found in {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path not_existing_file.txt was not found in /Users/dean/tdk/spannerlib/nbs\n"
     ]
    }
   ],
   "source": [
    "# check that read assignments got a string which is an existing path\n",
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    ])\n",
    "\n",
    "file = Path(\"file.txt\")\n",
    "file.touch()\n",
    "\n",
    "# TODO figure out why this doesnt work\n",
    "asts = sess.run_query(f\"\"\"\n",
    "            x=read(\"file.txt\")\n",
    "            \"\"\")\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "            x=read(\"not_existing_file.txt\")\n",
    "            \"\"\")\n",
    "print(exc_info.value)\n",
    "\n",
    "file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check reference vars are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def check_referenced_vars_exist(ast,engine):\n",
    "\n",
    "    # first rename all left hand sign variables \n",
    "    # as type \"var_name_lhs\"\n",
    "    # so we can seperate them from reference variables\n",
    "    for assignment_type in [\"assignment\",\"read_assignment\"]:\n",
    "        for match in rewrite_iter(ast,\n",
    "                lhs=f\"\"\"X[type=\"{assignment_type}\"]-[idx=0]->LHS[type=\"var_name\",val]\"\"\"\n",
    "                ):\n",
    "            match['LHS']['type'] = \"var_name_lhs\"\n",
    "\n",
    "    # now for each reference variable check if it is in the symbol table\n",
    "    for match in rewrite_iter(ast,lhs=f\"\"\"X[type=\"var_name\",val]\"\"\"):\n",
    "        var_name = match['X']['val'].name\n",
    "        if not engine.get_var(var_name):\n",
    "            raise ValueError(f'Variable {var_name} is not defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable z is not defined\n"
     ]
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    ])\n",
    "\n",
    "sess.engine.set_var('y',1)\n",
    "sess.engine.set_var('x',\"hello\")\n",
    "\n",
    "asts = sess.run_query(f\"\"\"\n",
    "            z=1\n",
    "            x=y\n",
    "            R(x,y)\n",
    "            \"\"\")\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(x,z)\n",
    "                \"\"\")\n",
    "assert 'Variable z is not defined' in str(exc_info.value)\n",
    "print(exc_info.value)\n",
    "\n",
    "# for ast in asts:\n",
    "#     draw(ast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast relations to python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relations_to_dataclasses(ast,engine):\n",
    "\n",
    "   # regular relations\n",
    "   #TODO another example where i need to edit the graph imperatively because i dont have horizontal recursion in LHS\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type]->name[type=\"relation_name\",val];\n",
    "         statement->terms[type]\n",
    "         ''',\n",
    "         #TODO i expect to be able to put an rhs here only, and if a p is not given, assume it is the identity over nodes in LHS\n",
    "         p='statement[type]',\n",
    "         condition=lambda match: (match['statement']['type'] in ['add_fact','remove_fact','relation','rule_head','query']\n",
    "                                   and match['terms']['type'] in ['const_term_list','term_list','free_var_name_list']),\n",
    "         # display_matches=True,\n",
    "         ):\n",
    "      term_nodes = list(ast.successors(match.mapping['terms']))\n",
    "      #TODO check we iterate in order on the children\n",
    "      logger.debug(f\"casting relation to dataclasses - term_nodes: {term_nodes}\")\n",
    "      match['statement']['val'] = Relation(name=match['name']['val'],terms=[ast.nodes[term_node]['val'] for term_node in term_nodes])\n",
    "      ast.remove_nodes_from(term_nodes)\n",
    "   # relation declerations\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type=\"relation_declaration\"]->name[type=\"relation_name\",val];\n",
    "         statement->terms[type=\"decl_term_list\"]\n",
    "         ''',\n",
    "         p='statement[type]'):\n",
    "      term_nodes = list(ast.successors(match.mapping['terms']))\n",
    "      match['statement']['val'] = RelationDefinition(name=match['name']['val'],scheme=[ast.nodes[term_node]['val'] for term_node in term_nodes])\n",
    "      ast.remove_nodes_from(term_nodes)\n",
    "\n",
    "   # ie relations\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type=\"ie_relation\"]->name[type=\"relation_name\",val];\n",
    "         statement-[idx=1]->in_terms[type=\"term_list\"];\n",
    "         statement-[idx=2]->out_terms[type=\"term_list\"]\n",
    "      ''',p='statement[type]'):\n",
    "      in_term_nodes = list(ast.successors(match.mapping['in_terms']))\n",
    "      out_term_nodes = list(ast.successors(match.mapping['out_terms']))\n",
    "\n",
    "      match['statement']['val'] = IERelation(name=match['name']['val'],\n",
    "                                             in_terms=[ast.nodes[term_node]['val'] for term_node in in_term_nodes],\n",
    "                                             out_terms=[ast.nodes[term_node]['val'] for term_node in out_term_nodes]\n",
    "                                             )\n",
    "      ast.remove_nodes_from(in_term_nodes+out_term_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__ - DEBUG - casting relation to dataclasses - term_nodes: [4, 6]\n",
      "__main__ - DEBUG - casting relation to dataclasses - term_nodes: [4, 6]\n",
      "__main__ - DEBUG - casting relation to dataclasses - term_nodes: [4, 6]\n",
      "__main__ - DEBUG - casting relation to dataclasses - term_nodes: [4, 6]\n",
      "__main__ - DEBUG - casting relation to dataclasses - term_nodes: [5, 7]\n",
      "__main__ - DEBUG - casting relation to dataclasses - term_nodes: [14, 16]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgNl0pIl0K\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgWzQsNSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVtb3ZlX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgWzQsNSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVsYXRpb25fZGVjbGFyYXRpb24jcXVvdDssIHZhbD1SZWxhdGlvbkRlZmluaXRpb24obmFtZT0jcXVvdDtSI3F1b3Q7LCBzY2hlbWU9WyNsdDtjbGFzcyAjcXVvdDtzdHIjcXVvdDsjZ3Q7LCAjbHQ7Y2xhc3MgI3F1b3Q7c3Bhbm5lcmxpYi5zcGFuLlNwYW4jcXVvdDsjZ3Q7LCAjbHQ7Y2xhc3MgI3F1b3Q7aW50I3F1b3Q7I2d0OywgI2x0O2NsYXNzICNxdW90O2ludCNxdW90OyNndDtdKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cXVlcnkjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSkiXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDtydWxlX2hlYWQjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KV0pIl0KOVsiOQp0eXBlPSNxdW90O3J1bGVfYm9keV9yZWxhdGlvbl9saXN0I3F1b3Q7Il0KMTBbIjEwCnR5cGU9I3F1b3Q7cmVsYXRpb24jcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1MjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KV0pIl0KMThbIjE4CnR5cGU9I3F1b3Q7aWVfcmVsYXRpb24jcXVvdDssIHZhbD1JRVJlbGF0aW9uKG5hbWU9I3F1b3Q7VCNxdW90OywgaW5fdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSwgb3V0X3Rlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WSNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtaI3F1b3Q7KV0pIl0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCA5CjkgLS0+fCJpZHg9MCJ8IDEwCjkgLS0+fCJpZHg9MSJ8IDE4Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses\n",
    "    ])\n",
    "\n",
    "with checkLogs():\n",
    "    asts = sess.run_query(\"\"\"\n",
    "    R(\"hello\",6)\n",
    "    R(\"hello\",[4,5))<-True\n",
    "    R(\"hello\",[4,5))<-False\n",
    "    new R(str,span,int,int)\n",
    "    ?R(\"hello\",Y)\n",
    "    R(X,Y)<-S(X,Y),T(X,Y)->(Y,Z)\n",
    "    \"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgNl0pIl0K\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YWRkX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgWzQsNSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVtb3ZlX2ZhY3QjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgWzQsNSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVsYXRpb25fZGVjbGFyYXRpb24jcXVvdDssIHZhbD1SZWxhdGlvbkRlZmluaXRpb24obmFtZT0jcXVvdDtSI3F1b3Q7LCBzY2hlbWU9WyNsdDtjbGFzcyAjcXVvdDtzdHIjcXVvdDsjZ3Q7LCAjbHQ7Y2xhc3MgI3F1b3Q7c3Bhbm5lcmxpYi5zcGFuLlNwYW4jcXVvdDsjZ3Q7LCAjbHQ7Y2xhc3MgI3F1b3Q7aW50I3F1b3Q7I2d0OywgI2x0O2NsYXNzICNxdW90O2ludCNxdW90OyNndDtdKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cXVlcnkjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVsjcXVvdDtoZWxsbyNxdW90OywgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSkiXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OyJdCjFbIjEKdHlwZT0jcXVvdDtydWxlX2hlYWQjcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KV0pIl0KOVsiOQp0eXBlPSNxdW90O3J1bGVfYm9keV9yZWxhdGlvbl9saXN0I3F1b3Q7Il0KMTBbIjEwCnR5cGU9I3F1b3Q7cmVsYXRpb24jcXVvdDssIHZhbD1SZWxhdGlvbihuYW1lPSNxdW90O1MjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KV0pIl0KMThbIjE4CnR5cGU9I3F1b3Q7aWVfcmVsYXRpb24jcXVvdDssIHZhbD1JRVJlbGF0aW9uKG5hbWU9I3F1b3Q7VCNxdW90OywgaW5fdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSwgb3V0X3Rlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WSNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtaI3F1b3Q7KV0pIl0KMCAtLT58ImlkeD0wInwgMQowIC0tPnwiaWR4PTEifCA5CjkgLS0+fCJpZHg9MCJ8IDEwCjkgLS0+fCJpZHg9MSJ8IDE4Cg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses\n",
    "    ])\n",
    "asts = sess.run_query(\"\"\"\n",
    "R(\"hello\",6)\n",
    "R(\"hello\",[4,5))<-True\n",
    "R(\"hello\",[4,5))<-False\n",
    "new R(str,span,int,int)\n",
    "?R(\"hello\",Y)\n",
    "R(X,Y)<-S(X,Y),T(X,Y)->(Y,Z)\n",
    "\"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "assert  [serialize_tree(ast) for ast in asts] == [{'type': 'add_fact',\n",
    "  'val': Relation(name='R', terms=['hello', 6]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'add_fact',\n",
    "  'val': Relation(name='R', terms=['hello', Span(start=4, end=5)]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'remove_fact',\n",
    "  'val': Relation(name='R', terms=['hello', Span(start=4, end=5)]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'relation_declaration',\n",
    "  'val': RelationDefinition(name='R', scheme=[str,Span,int,int]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'query',\n",
    "  'val': Relation(name='R', terms=['hello', FreeVar(name='Y')]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'rule',\n",
    "  'id': 0,\n",
    "  'children': [{'type': 'rule_head',\n",
    "    'val': Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    'id': 1},\n",
    "   {'type': 'rule_body_relation_list',\n",
    "    'id': 9,\n",
    "    'children': [{'type': 'relation',\n",
    "      'val': Relation(name='S', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "      'id': 10},\n",
    "     {'type': 'ie_relation',\n",
    "      'val': IERelation(name='T', in_terms=[FreeVar(name='X'), FreeVar(name='Y')], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')]),\n",
    "      'id': 18}]}]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation referencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check that referenced relations and ie relations:\n",
    "  * exist in the symbol table \n",
    "  * are called with the correct arity\n",
    "  * are called with correct constants or vars types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_referenced_relations(ast,engine):\n",
    "\n",
    "    def schema_match(types,vals):\n",
    "        for type_,val in zip(types,vals):\n",
    "            if isinstance(val,FreeVar):\n",
    "                continue # free vars can be anything\n",
    "            elif isinstance(val,Var):\n",
    "                var_type = engine.get_var(val.name)[0]\n",
    "                if not type_ == var_type:\n",
    "                    return False\n",
    "            elif not isinstance(val,type_):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    for match in rewrite_iter(ast,\n",
    "            lhs='''rel[type]''',\n",
    "            condition=lambda match: match['rel']['type'] in ['add_fact','remove_fact','relation','query'],\n",
    "            ):\n",
    "        rel:Relation = match['rel']['val']\n",
    "        if not engine.get_relation(rel.name):\n",
    "            raise ValueError(f\"Relation '{rel.name}' is not defined\")\n",
    "        expected_len = len(engine.get_relation(rel.name).scheme)\n",
    "        if len(rel.terms) != expected_len:\n",
    "            raise ValueError(f\"Relation '{pretty(rel)}' was called with {len(rel.terms)} terms but it was defined with {expected_len} terms\")\n",
    "        if not schema_match(engine.get_relation(rel.name).scheme,rel.terms):\n",
    "            raise ValueError(f\"Relation '{rel.name}' expected schema {pretty(engine.get_relation(rel.name))} but got called with {pretty(rel)}\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation 'Z' is not defined\n",
      "Relation 'R(hello,4,[4,5))' was called with 3 terms but it was defined with 2 terms\n",
      "Relation 'R' expected schema R(str,int) but got called with R(4,4)\n",
      "Relation 'R' expected schema R(str,int) but got called with R(hello,b)\n",
      "Relation 'R' expected schema R(str,int) but got called with R(4,Y)\n"
     ]
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    verify_referenced_relations\n",
    "    ])\n",
    "\n",
    "sess.engine.set_var('a',1)\n",
    "sess.engine.set_var('b','hello')\n",
    "sess.engine.set_relation(RelationDefinition(name='R',scheme=[str,int]))\n",
    "sess.engine.set_relation(RelationDefinition(name='S',scheme=[str,int,int]))\n",
    "sess.engine.set_ie_function(IEFunction(name='T',in_schema=[str,int],out_schema=[int,str],func=lambda x,y:(y,x)))\n",
    "\n",
    "asts = sess.run_query(\"\"\"\n",
    "R(\"hello\",6)\n",
    "R(\"hello\",a)\n",
    "?R(\"hello\",Y)\n",
    "NewRel(X,Y)<-S(X,Y,3),T(X,Y)->(Y,Z)\n",
    "\"\"\")\n",
    "\n",
    "# for ast in asts:\n",
    "#     draw(ast)\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                Z(\"hello\",4)\n",
    "                \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"Relation 'Z' is not defined\" in str(exc_info.value)\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(\"hello\",4,[4,5))\n",
    "                \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"Relation 'R(hello,4,[4,5))' was called with 3 terms but it was defined with 2 terms\" in str(exc_info.value)\n",
    "\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(4,4)\n",
    "                \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"Relation 'R' expected schema R(str,int) but got called with R(4,4)\" in str(exc_info.value)\n",
    "\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                R(\"hello\",b)\n",
    "                \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"Relation 'R' expected schema R(str,int) but got called with R(hello,b)\" in str(exc_info.value)\n",
    "\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(f\"\"\"\n",
    "                ?R(4,Y)\n",
    "                \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"Relation 'R' expected schema R(str,int) but got called with R(4,Y)\" in str(exc_info.value)\n",
    "\n",
    "# assert  [serialize_tree(ast) for ast in asts] \n",
    "# [serialize_tree(ast) for ast in asts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cast rules to data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rules_to_dataclasses(ast,engine):\n",
    "   for match in rewrite_iter(ast,\n",
    "      lhs='''\n",
    "         statement[type=\"rule\"]->head[type=\"rule_head\",val];\n",
    "         statement->body[type=\"rule_body_relation_list\"]\n",
    "      ''',p='statement[type]'):\n",
    "      body_nodes = list(ast.successors(match.mapping['body']))\n",
    "      head = match['head']['val']\n",
    "      match['statement']['val'] = Rule(head=match['head']['val'],body=[ast.nodes[body_node]['val'] for body_node in body_nodes])\n",
    "      ast.remove_nodes_from(body_nodes)\n",
    "   return ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OywgdmFsPVJ1bGUoaGVhZD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1ojcXVvdDspXSksIGJvZHk9W1JlbGF0aW9uKG5hbWU9I3F1b3Q7UyNxdW90OywgdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSksIFJlbGF0aW9uKG5hbWU9I3F1b3Q7VCNxdW90OywgdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cnVsZSNxdW90OywgdmFsPVJ1bGUoaGVhZD1SZWxhdGlvbihuYW1lPSNxdW90O1IjcXVvdDssIHRlcm1zPVtGcmVlVmFyKG5hbWU9I3F1b3Q7WCNxdW90OyksIEZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1ojcXVvdDspXSksIGJvZHk9W1JlbGF0aW9uKG5hbWU9I3F1b3Q7UyNxdW90OywgdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtYI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1kjcXVvdDspXSksIElFUmVsYXRpb24obmFtZT0jcXVvdDtUI3F1b3Q7LCBpbl90ZXJtcz1bRnJlZVZhcihuYW1lPSNxdW90O1gjcXVvdDspLCBGcmVlVmFyKG5hbWU9I3F1b3Q7WSNxdW90OyldLCBvdXRfdGVybXM9W0ZyZWVWYXIobmFtZT0jcXVvdDtZI3F1b3Q7KSwgRnJlZVZhcihuYW1lPSNxdW90O1ojcXVvdDspXSldKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    # verify_referenced_relations,\n",
    "    rules_to_dataclasses\n",
    "    ])\n",
    "\n",
    "asts = sess.run_query(\"\"\"\n",
    "R(X,Y,Z)<-S(X,Y),T(X,Y)\n",
    "R(X,Y,Z)<-S(X,Y),T(X,Y)->(Y,Z)\n",
    "\"\"\")\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "\n",
    "assert  [serialize_tree(ast) for ast in asts] == [{'type': 'rule',\n",
    "  'val': Rule(head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y'), FreeVar(name='Z')]),\n",
    "               body=[Relation(name='S', terms=[FreeVar(name='X'), FreeVar(name='Y')]), \n",
    "                     Relation(name='T', terms=[FreeVar(name='X'), FreeVar(name='Y')])]),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'rule',\n",
    "  'val': Rule(head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y'), FreeVar(name='Z')]), \n",
    "              body=[Relation(name='S', terms=[FreeVar(name='X'), FreeVar(name='Y')]), \n",
    "                    IERelation(name='T', in_terms=[FreeVar(name='X'), FreeVar(name='Y')], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')])]),\n",
    "  'id': 0,\n",
    "  'children': []}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistent Free Var types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _check_rule_consistency(rule,engine):\n",
    "    # for each free var we encounter, what is the type is is according to the relation schema\n",
    "    free_var_to_type = {}\n",
    "    # what is the first relation we found each var in, useful for error messages\n",
    "    first_rel_to_define_free_var = {}\n",
    "\n",
    "    # go over each body relation\n",
    "    for rel_idx,relation in enumerate(rule.body):\n",
    "\n",
    "        # if ie relation split into two relations\n",
    "        rel_type_terms_and_schema_list = []\n",
    "        if isinstance(relation,Relation):\n",
    "            rel_type_terms_and_schema_list.append(('relation',relation.terms,engine.get_relation(relation.name).scheme))\n",
    "        elif isinstance(relation,IERelation):\n",
    "            rel_type_terms_and_schema_list.append(('ie input relation',relation.in_terms,engine.get_ie_function(relation.name).in_schema))\n",
    "            rel_type_terms_and_schema_list.append(('ie output relation',relation.out_terms,engine.get_ie_function(relation.name).out_schema))\n",
    "\n",
    "        # for each relation type in the body relation\n",
    "        for rel_type_terms_and_schema in rel_type_terms_and_schema_list:\n",
    "            rel_type,terms,expected_schema = rel_type_terms_and_schema\n",
    "            # for each term in the relation that is a free var\n",
    "            for term_idx,(term,expected_type) in enumerate(zip(terms,expected_schema)):\n",
    "                if isinstance(term,FreeVar):\n",
    "                    # check if was defined before in other body relations\n",
    "                    # if so must have same type as before\n",
    "                    if term.name in free_var_to_type:\n",
    "                        if free_var_to_type[term.name] != expected_type:\n",
    "                            predefined_relation,predefined_term_idx = first_rel_to_define_free_var[term.name]\n",
    "                            raise ValueError(f\"In rule {pretty(rule)}, in body {rel_type} {pretty(relation)}, FreeVar {term.name} position {term_idx} expects type {pretty(expected_type)} \"\n",
    "                                            f\"but was previously defined in relation {pretty(predefined_relation)} position {predefined_term_idx} with type {pretty(free_var_to_type[term.name])}\")\n",
    "                    # if not register it to the mapping\n",
    "                    else:\n",
    "                        free_var_to_type[term.name] = expected_type\n",
    "                        first_rel_to_define_free_var[term.name] = (relation.name,term_idx)\n",
    "\n",
    "    # for rule head, make sure all free vars are defined in the body\n",
    "    # and if the rule head was used in another rule, make sure it has the same types\n",
    "    head_name, head_terms = rule.head.name, rule.head.terms\n",
    "\n",
    "    current_head_schema = []\n",
    "    for term in head_terms:\n",
    "        if not isinstance(term,FreeVar):\n",
    "            raise ValueError(f\"In rule {pretty(rule)}, in head clause {head_name}, only FreeVars are allowed\")\n",
    "        if not term.name in free_var_to_type:\n",
    "            raise ValueError(f\"In rule {pretty(rule)}, FreeVar {term.name} is used in the head but was not defined in the body\")\n",
    "\n",
    "    current_head_schema = RelationDefinition(name=head_name,scheme=[free_var_to_type[term.name] for term in head_terms])\n",
    "\n",
    "    if engine.get_relation(head_name):\n",
    "        expected_head_schema = engine.get_relation(head_name)\n",
    "        if expected_head_schema != current_head_schema:\n",
    "            raise ValueError(f\"In rule {pretty(rule)}, expected schema {pretty(expected_head_schema)} from a previously defined rule to {head_name} but got {pretty(current_head_schema)}\")\n",
    "    else:\n",
    "        engine.set_relation(current_head_schema)\n",
    "\n",
    "def consistent_free_var_types_in_rule(ast,engine):\n",
    "    for match in rewrite_iter(ast,lhs='X[type=\"rule\",val]'):\n",
    "        rule = match['X']['val']\n",
    "        _check_rule_consistency(rule,engine)\n",
    "    return ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In rule NewRel(X,Y) <- S(X,Y,3),T(X,Y) -> (Y,Z),R(Y,Z), in body relation R(Y,Z), FreeVar Y position 0 expects type str but was previously defined in relation S position 1 with type int\n",
      "In rule NewRel(X,Y) <- S(X,Y,3),T(X,Y) -> (Y,Y), in body ie output relation T(X,Y) -> (Y,Y), FreeVar Y position 1 expects type str but was previously defined in relation S position 1 with type int\n",
      "In rule NewRel(X,Y,W) <- S(X,Y,3),T(X,Y) -> (Y,Z),R(Z,Y), FreeVar W is used in the head but was not defined in the body\n",
      "In rule NewRel(Y,X) <- S(X,Y,3),T(X,Y) -> (Y,Z),R(Z,Y), expected schema NewRel(str,int) from a previously defined rule to NewRel but got NewRel(int,str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'rule',\n",
       " 'val': Rule(head=Relation(name='NewRel', terms=[FreeVar(name='X'), FreeVar(name='Y')]), body=[Relation(name='S', terms=[FreeVar(name='X'), FreeVar(name='Y'), 3]), IERelation(name='T', in_terms=[FreeVar(name='X'), FreeVar(name='Y')], out_terms=[FreeVar(name='Y'), FreeVar(name='Z')]), Relation(name='R', terms=[FreeVar(name='Z'), FreeVar(name='Y')])]),\n",
       " 'id': 0,\n",
       " 'children': []}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    verify_referenced_relations,\n",
    "    rules_to_dataclasses,\n",
    "    consistent_free_var_types_in_rule,\n",
    "    ])\n",
    "\n",
    "\n",
    "sess.engine.set_var('a',1)\n",
    "sess.engine.set_var('b','hello')\n",
    "sess.engine.set_relation(RelationDefinition(name='R',scheme=[str,int]))\n",
    "sess.engine.set_relation(RelationDefinition(name='S',scheme=[str,int,int]))\n",
    "sess.engine.set_relation(RelationDefinition(name='NewRel',scheme=[str,int]))\n",
    "sess.engine.set_ie_function(IEFunction(name='T',in_schema=[str,int],out_schema=[int,str],func=lambda x,y:(y,x)))\n",
    "\n",
    "# legal query\n",
    "asts = sess.run_query(\"\"\"\n",
    "NewRel(X,Y)<-S(X,Y,3),T(X,Y)->(Y,Z),R(Z,Y)\n",
    "\"\"\")\n",
    "t = serialize_tree(asts[0])\n",
    "\n",
    "# change types of R to make it illegal\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "    NewRel(X,Y)<-S(X,Y,3),T(X,Y)->(Y,Z),R(Y,Z)\n",
    "    \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"FreeVar Y position 0 expects type str but was previously defined in relation S position 1 with type int\" in str(exc_info.value)\n",
    "\n",
    "# change types of R to make it illegal\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "    NewRel(X,Y)<-S(X,Y,3),T(X,Y)->(Y,Y)\n",
    "    \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"FreeVar Y position 1 expects type str but was previously defined in relation S position 1 with type int\" in str(exc_info.value)\n",
    "\n",
    "# free var in head, bound by body\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "    NewRel(X,Y,W)<-S(X,Y,3),T(X,Y)->(Y,Z),R(Z,Y)\n",
    "    \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"FreeVar W is used in the head but was not defined in the body\" in str(exc_info.value)\n",
    "\n",
    "# head free var type mismatch\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "    NewRel(Y,X)<-S(X,Y,3),T(X,Y)->(Y,Z),R(Z,Y)\n",
    "    \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"expected schema NewRel(str,int) from a previously defined rule to NewRel but got NewRel(int,str)\" in str(exc_info.value)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_rule_safe(rule:Rule):\n",
    "    \"\"\"\n",
    "    Checks that the Spannerlog Rule is safe\n",
    "    ---\n",
    "    In spannerlog, rule safety is a semantic property that ensures that IE relation's inputs are limited \n",
    "    in the values they can be assigned to by other relations in the rule body.\n",
    "    This could include outputs of other IE relations.\n",
    "\n",
    "    We call a free variable in a rule body \"bound\" if it exists in the output of any safe relation in the rule body.\n",
    "    For normal relations, they only have output terms, so all their free variables are considered bound.\n",
    "\n",
    "    We call a relation in a rule's body safe if all its input free variables are bound.\n",
    "    For normal relations, they don't have input relations, so they are always considered safe.\n",
    "\n",
    "    We call a rule safe if all of its body relations are safe.\n",
    "\n",
    "    This basically means that we need to make sure there is at least one order of IE relation evaluation, in which\n",
    "    each IE relation input variables is bound by the normal relations and the output relation of the previous IE relations.\n",
    "\n",
    "    Examples:\n",
    "    * `rel2(X,Y) <- rel1(X,Z), ie1(X)->(Y)` is a safe rule as the only input free variable, `X`, exists in the output of the safe relation `rel1(X, Z)`.  \n",
    "    * `rel2(Y) <- ie1(Z)->(Y)` is not safe as the input free variable `Z` does not exist in the output of any safe relation.\n",
    "    * `rel2(Z,W) <- rel1(X,Y),ie1(Z,Y)->(W),ie2(W,Y)->Z` is not safe as both ie functions require each other's output as input, creating a circular dependency.\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    # get all free vars in regular relations\n",
    "    normal_relations_free_vars = set()\n",
    "    for body in rule.body:\n",
    "        if isinstance(body,Relation):\n",
    "            for term in body.terms:\n",
    "                if isinstance(term,FreeVar):\n",
    "                    normal_relations_free_vars.add(term.name)\n",
    "    \n",
    "    # get list of form [(ie_rel,{input_vars},{output_vars})]\n",
    "    free_vars_per_ie_relation = {}\n",
    "    for body in rule.body:\n",
    "        if isinstance(body,IERelation):\n",
    "            input_vars = set(term.name for term in body.in_terms if isinstance(term,FreeVar))\n",
    "            output_vars = set(term.name for term in body.out_terms if isinstance(term,FreeVar))\n",
    "            free_vars_per_ie_relation[body]=(input_vars,output_vars)\n",
    "        \n",
    "    # iteratively go over all previously unsafe ie relations and check if they are now safe\n",
    "\n",
    "    safe_vars = normal_relations_free_vars.copy()\n",
    "    safe_ie_relations = set()\n",
    "\n",
    "    while True:\n",
    "        if len(free_vars_per_ie_relation)==0:\n",
    "            break\n",
    "        \n",
    "        safe_ie_relations_in_this_iteration = set()\n",
    "        for ie_relation,(input_vars,output_vars) in free_vars_per_ie_relation.items():\n",
    "            if input_vars.issubset(safe_vars):\n",
    "                safe_ie_relations_in_this_iteration.add(ie_relation)\n",
    "        \n",
    "        if len(safe_ie_relations_in_this_iteration)== 0 :\n",
    "            raise ValueError(f\"Rule \\'{pretty(rule)}\\' is not safe:\\n\"\n",
    "                            f\"the following free vars where bound by normal relations: {normal_relations_free_vars}\\n\"\n",
    "                            f\"the following ie relations where safe: {safe_ie_relations}\\n\"\n",
    "                            f\"leading to the following free vars being bound: {safe_vars}\\n\"\n",
    "                            f\"However the following ie relations could not be bound: {[pretty(ie) for ie in free_vars_per_ie_relation.keys()]}\\n\"\n",
    "                             )\n",
    "    \n",
    "        for ie_relation in safe_ie_relations_in_this_iteration:\n",
    "            input_vars,output_vars = free_vars_per_ie_relation[ie_relation]\n",
    "            safe_vars.update(output_vars)\n",
    "            safe_ie_relations.add(ie_relation)\n",
    "            del free_vars_per_ie_relation[ie_relation]\n",
    "\n",
    "\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rule_safety(ast,engine):\n",
    "    for match in rewrite_iter(ast,lhs='X[type=\"rule\",val]'):\n",
    "        rule = match['X']['val']\n",
    "        is_rule_safe(rule)\n",
    "    return ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 'rel2(Y) <- ie1(Z) -> (Y)' is not safe:\n",
      "the following free vars where bound by normal relations: set()\n",
      "the following ie relations where safe: set()\n",
      "leading to the following free vars being bound: set()\n",
      "However the following ie relations could not be bound: ['ie1(Z) -> (Y)']\n",
      "\n",
      "Rule 'rel2(Z,W) <- rel1(X,Y),ie1(Z,Y) -> (W),ie2(W,Y) -> (Z)' is not safe:\n",
      "the following free vars where bound by normal relations: {'Y', 'X'}\n",
      "the following ie relations where safe: set()\n",
      "leading to the following free vars being bound: {'Y', 'X'}\n",
      "However the following ie relations could not be bound: ['ie1(Z,Y) -> (W)', 'ie2(W,Y) -> (Z)']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    relations_to_dataclasses,\n",
    "    rules_to_dataclasses,\n",
    "    check_rule_safety,\n",
    "    ])\n",
    "\n",
    "\n",
    "# safe rules\n",
    "asts = sess.run_query(\"\"\"\n",
    "S(X,Y)<-R(X,Y)    \n",
    "rel2(X,Y) <- rel1(X,Z), ie1(X)->(Y)\n",
    "rel2(X,Y) <- rel1(X,Z), ie1(X)->(Y), ie2(Y)->(Z)\n",
    "rel2(X,Y) <- rel1(X), ie1(X)->(Y), ie2(Y)->(Z)\n",
    "\"\"\")\n",
    "t = serialize_tree(asts[0])\n",
    "\n",
    "# change types of R to make it illegal\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "    rel2(Y) <- ie1(Z)->(Y)\n",
    "    \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"is not safe\" in str(exc_info.value)\n",
    "\n",
    "\n",
    "with pytest.raises(ValueError) as exc_info:\n",
    "    asts = sess.run_query(\"\"\"\n",
    "    rel2(Z,W) <- rel1(X,Y),ie1(Z,Y)->(W),ie2(W,Y)->(Z)    \n",
    "    \"\"\")\n",
    "print(exc_info.value)\n",
    "assert \"is not safe\" in str(exc_info.value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignemnts_to_name_val_tuple(ast,engine):\n",
    "    for match in rewrite_iter(ast,lhs='''\n",
    "                                statement[type]-[idx=0]->var_name_node[val];\n",
    "                                statement-[idx=1]->val_node[val]''',p='statement[type]',\n",
    "                                condition=lambda match: match['statement']['type'] in ['assignment','read_assignment'],\n",
    "                                # display_matches=True\n",
    "                                ):\n",
    "        match['statement']['val'] = (\n",
    "            match['var_name_node']['val'].name,\n",
    "            match['val_node']['val']\n",
    "        )\n",
    "    return ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OywgdmFsPSgjcXVvdDt4I3F1b3Q7LCAzKSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OywgdmFsPSgjcXVvdDt5I3F1b3Q7LCAjcXVvdDtoZWxsbyNxdW90OykiXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OywgdmFsPSgjcXVvdDt6I3F1b3Q7LCAjcXVvdDtoZWxsbyB3b3JsZCNxdW90OykiXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7YXNzaWdubWVudCNxdW90OywgdmFsPSgjcXVvdDt3I3F1b3Q7LCBbMyw0KSkiXQo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgowWyIwCnR5cGU9I3F1b3Q7cmVhZF9hc3NpZ25tZW50I3F1b3Q7LCB2YWw9KCNxdW90O2YjcXVvdDssICNxdW90O2ZpbGUudHh0I3F1b3Q7KSJdCg==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    # check_referenced_paths_exist,\n",
    "    # check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    # verify_referenced_relations,\n",
    "    rules_to_dataclasses,\n",
    "    # consistent_free_var_types_in_rule,\n",
    "    check_rule_safety,\n",
    "    assignemnts_to_name_val_tuple\n",
    "    ])\n",
    "\n",
    "\n",
    "file = Path(\"file.txt\")\n",
    "file.write_text(\"hello file\")\n",
    "\n",
    "# safe rules\n",
    "asts = sess.run_query(\"\"\"\n",
    "x=3\n",
    "y=\"hello\"\n",
    "z=\"hello \\\n",
    "world\"\n",
    "w=[3,4)\n",
    "f=read(\"file.txt\")\n",
    "\"\"\")\n",
    "\n",
    "for ast in asts:\n",
    "    draw(ast)\n",
    "assert [serialize_tree(ast) for ast in asts] == [{'type': 'assignment', 'val': ('x', 3), 'id': 0, 'children': []},\n",
    " {'type': 'assignment', 'val': ('y', 'hello'), 'id': 0, 'children': []},\n",
    " {'type': 'assignment', 'val': ('z', 'hello world'), 'id': 0, 'children': []},\n",
    " {'type': 'assignment',\n",
    "  'val': ('w', Span(start=3, end=4)),\n",
    "  'id': 0,\n",
    "  'children': []},\n",
    " {'type': 'read_assignment',\n",
    "  'val': ('f', 'file.txt'),\n",
    "  'id': 0,\n",
    "  'children': []}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def execute_statement(ast,engine):\n",
    "    statement_node = list(ast.nodes)[0]\n",
    "    node_data = ast.nodes[statement_node]\n",
    "    statement = node_data['type']\n",
    "    value = node_data['val']\n",
    "    match statement:\n",
    "        case 'assignment':\n",
    "            engine.set_var(*value)\n",
    "        case 'read_assignment':\n",
    "            engine.set_var(*value,read_from_file=True)\n",
    "        case 'add_fact':\n",
    "            engine.add_fact(value)\n",
    "        case 'remove_fact':\n",
    "            engine.del_fact(value)\n",
    "        case 'relation_declaration':\n",
    "            engine.set_relation(value)\n",
    "        case 'rule':\n",
    "            return engine.add_rule(value)\n",
    "        case 'query':\n",
    "            return engine.run_query(value)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown statement type {statement}\")\n",
    "    return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sess.engine.set_relation(RelationDefinition(name='R',scheme=[str,int]))\n",
    "sess.engine.Relation_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = DummySession(passes=[\n",
    "    convert_primitive_values_to_objects,\n",
    "    remove_new_lines_from_strings,\n",
    "    CheckReservedRelationNames('spanner_'),\n",
    "    check_referenced_paths_exist,\n",
    "    check_referenced_vars_exist,\n",
    "    relations_to_dataclasses,\n",
    "    verify_referenced_relations,\n",
    "    rules_to_dataclasses,\n",
    "    consistent_free_var_types_in_rule,\n",
    "    check_rule_safety,\n",
    "    assignemnts_to_name_val_tuple,\n",
    "    ],\n",
    "    execution_function=execute_statement\n",
    "    )\n",
    "\n",
    "sess.symbol_table ={}\n",
    "\n",
    "file = Path(\"file.txt\")\n",
    "file.write_text(\"hello file\")\n",
    "\n",
    "# safe rules\n",
    "results = sess.run_query(\"\"\"\n",
    "x=3\n",
    "y=read(\"file.txt\")\n",
    "new R(str,int)\n",
    "R(\"hello\",4)\n",
    "?R(\"hello\",x)\n",
    "S(X,Y)<-R(X,Y)    \n",
    "?R(X,Y)\n",
    "R(\"hello\",4)<-False\n",
    "?S(X,Y)\n",
    "\"\"\")\n",
    "file.unlink()\n",
    "\n",
    "assert serialize_df_values(results[-3])=={('hello',4)}\n",
    "assert serialize_df_values(results[-1])==set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
