{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine\n",
    "> Execution spannerlog commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from IPython.display import display, HTML\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "import pytest\n",
    "from collections import defaultdict\n",
    "from spannerflow.engine import Engine as SpannerflowEngine\n",
    "from spannerflow.span import Span\n",
    "from numbers import Real\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import no_type_check, Set, Sequence, Any,Optional,List,Callable,Dict,Union\n",
    "from pydantic import BaseModel\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from graph_rewrite import draw, draw_match, rewrite, rewrite_iter\n",
    "from spannerlib.utils import (\n",
    "    serialize_graph,\n",
    "    assert_df_equals,\n",
    "    checkLogs,\n",
    "    get_new_node_name\n",
    "    )\n",
    "\n",
    "\n",
    "from spannerlib.data_types import (\n",
    "    Var, \n",
    "    FreeVar, \n",
    "    RelationDefinition, \n",
    "    Relation, \n",
    "    IEFunction,\n",
    "    AGGFunction,\n",
    "    IERelation, \n",
    "    Rule, \n",
    "    pretty\n",
    ")\n",
    "from spannerlib.ra import (\n",
    "    _col_names,\n",
    "    get_const,\n",
    "    select,\n",
    "    project,\n",
    "    rename,\n",
    "    union,\n",
    "    intersection,\n",
    "    difference,\n",
    "    join,\n",
    "    product,\n",
    "    groupby,\n",
    "    ie_map,\n",
    "    merge_rows\n",
    ")\n",
    "\n",
    "from spannerlib.term_graph import graph_compose, merge_term_graphs_pair,rule_to_graph,add_relation,add_project_uniq_free_vars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _pd_drop_row(df,row_vals):\n",
    "    new_df = df[(df!=row_vals).all(axis=1)]\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    [1,'2fs'],[3,4]\n",
    "])\n",
    "assert list(_pd_drop_row(df,[3,4]).itertuples(index=False,name=None))==[(1,'2fs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DB(dict):\n",
    "    def __repr__(self):\n",
    "        key_str=', '.join(self.keys())\n",
    "        return f'DB({key_str})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from copy import deepcopy\n",
    "from time import sleep\n",
    "import atexit\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Engine():\n",
    "    def __init__(self, rewrites=None):\n",
    "        if rewrites is None:\n",
    "            self.rewrites = []\n",
    "        self.symbol_table={\n",
    "            # key : type,val\n",
    "        }\n",
    "        self.Relation_defs={\n",
    "            # key : RelationDefinition for both real and derived relations\n",
    "        }\n",
    "        self.ie_functions={\n",
    "            # name : IEFunction class\n",
    "        }\n",
    "\n",
    "        self.agg_functions={\n",
    "        }\n",
    "\n",
    "        self.term_graph = nx.DiGraph()\n",
    "        \n",
    "        self.node_counter = itertools.count()\n",
    "        self.rule_counter = itertools.count()\n",
    "\n",
    "        self.db = DB(\n",
    "            # relation_name: dataframe\n",
    "        )\n",
    "        self.collections = set()\n",
    "        self.rules = set()\n",
    "        # lets skip this for now and keep it a an attribute in the node graph\n",
    "        self.rules_to_ids = {\n",
    "            # rule pretty string: ( node id in term_graph, head_name)\n",
    "        }\n",
    "        self.head_to_rules = defaultdict(set)\n",
    "        # head relation name to rule pretty string\n",
    "\n",
    "        # self.rels_to_nodes() = {\n",
    "        #     # relation name to node that represents it\n",
    "        # }\n",
    "        self.spannerflow_engine = SpannerflowEngine()\n",
    "        atexit.register(self.spannerflow_engine.close)\n",
    "\n",
    "\n",
    "    def set_var(self,var_name,value,read_from_file=False):\n",
    "        symbol_table = self.symbol_table\n",
    "        if var_name in symbol_table:\n",
    "            existing_type,existing_value = symbol_table[var_name]\n",
    "            if type(value) != existing_type:\n",
    "                raise ValueError(f\"Variable {var_name} was previously defined with {existing_value}({pretty(existing_type)})\"\n",
    "                                f\" but is trying to be redefined to {value}({pretty(type(value))}) of a different type which might interfere with previous rule definitions\")    \n",
    "        symbol_table[var_name] = type(value),value\n",
    "        return\n",
    "    def get_var(self,var_name):\n",
    "        return self.symbol_table.get(var_name,None)\n",
    "    \n",
    "    def del_var(self,var_name):\n",
    "        del self.symbol_table[var_name]\n",
    "\n",
    "    def get_relation(self,rel_name:str)-> RelationDefinition:\n",
    "        return self.Relation_defs.get(rel_name,None)\n",
    "\n",
    "    def set_relation(self,rel_def:RelationDefinition, rule=False):\n",
    "        if rel_def.name in self.spannerflow_engine.get_collections():\n",
    "            existing_def = self.Relation_defs[rel_def.name]\n",
    "            if existing_def != rel_def:\n",
    "                raise ValueError(f\"Relation {rel_def.name} was previously defined with {existing_def}\"\n",
    "                                f\"but is trying to be redefined to {rel_def} which might interfere with previous rule definitions\")\n",
    "            elif not rule:\n",
    "                raise ValueError(f\"Relation {rel_def.name} was previously defined\")     \n",
    "        SPANNER_LIB_TO_SPANNER_FLOW_TYPES_DICT = {\n",
    "            str: \"DATA_TYPE_STRING\",\n",
    "            int: \"DATA_TYPE_INT\",\n",
    "            float: \"DATA_TYPE_FLOAT\",\n",
    "            bool: \"DATA_TYPE_BOOL\",\n",
    "            Span: \"DATA_TYPE_SPAN\",\n",
    "            Real: \"DATA_TYPE_FLOAT\",\n",
    "            np.int64: \"DATA_TYPE_INT64\",\n",
    "        }\n",
    "\n",
    "        spannerflow_schema = []\n",
    "        for col_type in rel_def.scheme:\n",
    "            if col_type not in SPANNER_LIB_TO_SPANNER_FLOW_TYPES_DICT:\n",
    "                raise ValueError(f\"Type {col_type} not supported by spannerflow\")\n",
    "            spannerflow_schema.append(SPANNER_LIB_TO_SPANNER_FLOW_TYPES_DICT[col_type])\n",
    "        \n",
    "        self.term_graph.add_node(rel_def.name, rel=rel_def.name, rule_id={'fact'})\n",
    "        self.Relation_defs[rel_def.name] = rel_def\n",
    "        if not rule:\n",
    "            self.collections.add(rel_def.name)\n",
    "            self.spannerflow_engine.add_collection(rel_def.name, spannerflow_schema)\n",
    "        else:\n",
    "            self.rules.add(rel_def.name)\n",
    "        \n",
    "    def del_relation(self,rel_name:str):\n",
    "        if rel_name not in self.spannerflow_engine.get_collections():\n",
    "            raise ValueError(f\"Relation {rel_name.name} is not defined\")\n",
    "        \n",
    "        if rel_name in self.Relation_defs:\n",
    "            self.Relation_defs.pop(rel_name)\n",
    "            if rel_name in self.rules:\n",
    "                self.rules.remove(rel_name)\n",
    "            elif rel_name in self.collections:\n",
    "                self.collections.remove(rel_name)\n",
    "\n",
    "        self.spannerflow_engine.delete_collection(rel_name)\n",
    "\n",
    "    def add_fact(self,fact:Relation):\n",
    "        self.spannerflow_engine.add_row(fact.name, fact.terms)\n",
    "        \n",
    "    def add_facts(self,rel_name,facts:pd.DataFrame):\n",
    "        self.spannerflow_engine.add_rows(rel_name, facts.values.tolist())\n",
    "        \n",
    "    def load_csv(self, rel_name:str , path: str|Path, delim: str = ',', has_header: bool = False):\n",
    "        if not os.path.exists(path):\n",
    "            raise ValueError(f\"Path {path} does not exist\")\n",
    "        self.spannerflow_engine.load_from_csv(rel_name, path, delim, has_header)\n",
    "        \n",
    "    def del_fact(self,fact:Relation):\n",
    "        self.spannerflow_engine.delete_row(fact.name, fact.terms)\n",
    "        # self.db[fact.name] = _pd_drop_row(df = self.db[fact.name],row_vals=fact.terms)\n",
    "\n",
    "    def get_ie_function(self,name:str):\n",
    "        return self.ie_functions.get(name,None)\n",
    "\n",
    "    def set_ie_function(self,ie_func:IEFunction):\n",
    "        self.ie_functions[ie_func.name]=ie_func\n",
    "        self.spannerflow_engine.set_ie_function(ie_func.name, ie_func.func, ie_func.in_schema, ie_func.out_schema)\n",
    "\n",
    "    def del_ie_function(self,name:str):\n",
    "        del self.ie_functions[name]\n",
    "\n",
    "    def get_agg_function(self,name:str):\n",
    "        return self.agg_functions.get(name,None)\n",
    "    \n",
    "    def set_agg_function(self,agg_func:AGGFunction):\n",
    "        self.agg_functions[agg_func.name]=agg_func\n",
    "        self.spannerflow_engine.set_agg_function(agg_func.name, agg_func.func, agg_func.in_schema, agg_func.out_schema)\n",
    "    \n",
    "    def del_agg_function(self,name:str):\n",
    "        del self.agg_functions[name]\n",
    "\n",
    "    def add_rule(self,rule:Rule,schema:RelationDefinition=None):\n",
    "        if not self.get_relation(rule.head.name) and schema is None:\n",
    "            raise ValueError(f\"Relation {rule.head.name} not defined before adding the rule with it's head\\n\"\n",
    "                             f\"And an relation schema was not supplied.\"\n",
    "                             f\"existing relations are {self.Relation_defs.keys()}\")\n",
    "        # if already defined, do nothing.\n",
    "        if pretty(rule) in self.rules_to_ids:\n",
    "            return\n",
    "\n",
    "        if not schema is None:\n",
    "            self.set_relation(schema, rule=True)\n",
    "\n",
    "        rule_id = next(self.rule_counter)\n",
    "\n",
    "        self.rules_to_ids[pretty(rule)] = rule_id,rule.head.name\n",
    "        self.head_to_rules[rule.head.name].add(pretty(rule))\n",
    "\n",
    "        g2 = rule_to_graph(rule,rule_id)\n",
    "\n",
    "        merge_term_graph = merge_term_graphs_pair(self.term_graph,g2)\n",
    "        self.term_graph = merge_term_graph\n",
    "        \n",
    "\n",
    "    def del_rule(self,rule_str:str):\n",
    "        #TODO here we need to save rules by their head and when removing the last rule of a head, remove its definition from db as well\n",
    "        if not rule_str in self.rules_to_ids:\n",
    "            raise ValueError(f\"Rule {rule_str} does not exist\\n\"\n",
    "                             f\"existing rules are {self.rules_to_ids.keys()}\")\n",
    "        rule_id,rule_head = self.rules_to_ids[rule_str]\n",
    "        self.rules_to_ids.pop(rule_str)\n",
    "        self.head_to_rules[rule_head].remove(rule_str)\n",
    "\n",
    "        g = self.term_graph\n",
    "\n",
    "        # if the head has no more rules, remove it from the relation defs and the term graph\n",
    "        if len(self.head_to_rules[rule_head])==0:\n",
    "            self.Relation_defs.pop(rule_head)\n",
    "            g.remove_node(rule_head)\n",
    "\n",
    "        nodes_to_delete=[]\n",
    "        for u in g.nodes:\n",
    "            node_rule_ids = g.nodes[u].get('rule_id',set())\n",
    "            if rule_id in node_rule_ids:\n",
    "                node_rule_ids.remove(rule_id)\n",
    "                if len(node_rule_ids) == 0:\n",
    "                    nodes_to_delete.append(u)\n",
    "        g.remove_nodes_from(nodes_to_delete)\n",
    "            \n",
    "        return\n",
    "\n",
    "    def del_head(self,head_name:str):\n",
    "        \"\"\"Deletes all rules whose head is head_name\n",
    "        \"\"\"\n",
    "        rules_to_delete = self.head_to_rules[head_name].copy()\n",
    "        for rule_str in rules_to_delete:\n",
    "            self.del_rule(rule_str)\n",
    "\n",
    "    def _inline_db_and_ies_in_graph(self,g:nx.DiGraph):\n",
    "        g=deepcopy(g)\n",
    "        for u in g.nodes:\n",
    "            if g.out_degree(u)==0 and 'rel' in g.nodes[u]:\n",
    "                g.nodes[u]['op'] = 'get_rel'\n",
    "                g.nodes[u]['db'] = self.db\n",
    "                g.nodes[u]['schema'] = _col_names(len(self.Relation_defs[g.nodes[u]['rel']].scheme))\n",
    "            elif g.nodes[u]['op'] == 'ie_map':\n",
    "                ie_func_name = g.nodes[u]['func']\n",
    "                ie_definition = self.ie_functions[ie_func_name]\n",
    "                g.nodes[u]['func'] = ie_definition.func\n",
    "                g.nodes[u]['name'] = ie_definition.name\n",
    "                g.nodes[u]['in_schema'] = ie_definition.in_schema\n",
    "                g.nodes[u]['out_schema'] = ie_definition.out_schema\n",
    "            elif g.nodes[u]['op'] == 'groupby':\n",
    "                aggregate_func_names = g.nodes[u]['agg']\n",
    "                aggregate_funcs = [self.agg_functions[name].func if name is not None else None for name in aggregate_func_names]\n",
    "                g.nodes[u]['agg'] = aggregate_funcs\n",
    "        return g\n",
    "\n",
    "\n",
    "    def plan_query(self,q_rel:Relation,rewrites=None):\n",
    "        if rewrites is None:\n",
    "            rewrites = self.rewrites\n",
    "        query_graph = self._inline_db_and_ies_in_graph(self.term_graph)\n",
    "\n",
    "        # get the sub term graph induced by the relation head\n",
    "        root_node = q_rel.name\n",
    "        connected_nodes = list(nx.shortest_path(query_graph,root_node).keys())\n",
    "        query_graph = nx.DiGraph(nx.subgraph(query_graph,connected_nodes))\n",
    "        \n",
    "        # add selects renames etc based on the query relation\n",
    "        root_node,_ = add_relation(query_graph,name='query',terms=q_rel.terms,source=root_node)\n",
    "\n",
    "        # TODO for all rewrites, run them\n",
    "        return query_graph,root_node\n",
    "\n",
    "    def execute_plan(self,query_graph,root_node,return_intermediate=False, output_csv_path: Path| str | None = None):\n",
    "        if isinstance(output_csv_path, Path):\n",
    "            output_csv_path = str(output_csv_path.resolve())\n",
    "        res =  self.spannerflow_engine.run_dataflow(nx.reverse(query_graph), output_csv_path=output_csv_path)\n",
    "        return pd.DataFrame(columns=query_graph.nodes[root_node]['schema'], data=res)\n",
    "\n",
    "    def run_query(self,q:Relation,rewrites=None,return_intermediate=False):\n",
    "        query_graph, root_node = self.plan_query(q,rewrites)\n",
    "        return self.execute_plan(query_graph,root_node,return_intermediate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame([\n",
    "    [1,1],\n",
    "    [2,2],\n",
    "    [3,3],\n",
    "    [4,5]\n",
    "])\n",
    "\n",
    "s2 = pd.DataFrame([\n",
    "    [1,2,3],\n",
    "    [2,3,4],\n",
    "    [3,4,5],\n",
    "    [4,5,6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = Rule(\n",
    "    head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='S', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "        Relation(name='S2', terms=[FreeVar(name='X'), FreeVar(name='A'),3]),\n",
    "    ])\n",
    "\n",
    "r2 = Rule(\n",
    "    head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='S', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "        IERelation(name='T', in_terms=[FreeVar(name='X'),FreeVar(name='Y')], out_terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "r3 = Rule(\n",
    "    head=Relation(name='R2', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='S3', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "        Relation(name='S2', terms=[FreeVar(name='X'), FreeVar(name='A'),1]),\n",
    "    ])\n",
    "\n",
    "\n",
    "rec_r1 = Rule(\n",
    "    head=Relation(name='A', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='B', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "rec_r2 = Rule(\n",
    "    head=Relation(name='A', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='C', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "rec_r3 = Rule(\n",
    "    head=Relation(name='B', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='D', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n",
    "\n",
    "rec_r4 = Rule(\n",
    "    head=Relation(name='B', terms=[FreeVar(name='X'), FreeVar(name='Y')]),\n",
    "    body=[\n",
    "        Relation(name='A', terms=[FreeVar(name='X'),FreeVar(name='Y')]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Engine()\n",
    "e.set_relation(RelationDefinition(name='S', scheme=[int,int]))\n",
    "e.set_relation(RelationDefinition(name='S2', scheme=[int,int,int]))\n",
    "e.set_relation(RelationDefinition(name='S3', scheme=[int,int]))\n",
    "\n",
    "e.add_rule(r1,RelationDefinition(name='R', scheme=[int,int]))\n",
    "e.add_rule(r2,RelationDefinition(name='R', scheme=[int,int]))\n",
    "e.add_rule(r3,RelationDefinition(name='R2', scheme=[int,int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.add_facts('S',s)\n",
    "e.add_facts('S2',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.db['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.db['S2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(e.term_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.rules_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.del_rule(pretty(r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(e.term_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert serialize_graph(e.term_graph) ==([('S', {'rel': 'S', 'rule_id': {0, 1}}),\n",
    "#   ('S2', {'rel': 'S2', 'rule_id': {0}}),\n",
    "#   ('R', {'rel': 'R', 'op': 'union', 'rule_id': {0, 1}}),\n",
    "#   (0, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')], 'rule_id': {0}}),\n",
    "#   (1, {'op': 'rename', 'names': [(0, 'X'), (1, 'A')], 'rule_id': {0}}),\n",
    "#   (2, {'op': 'select', 'theta': [(2, 3)], 'rule_id': {0}}),\n",
    "#   (3, {'op': 'join', 'rule_id': {0}}),\n",
    "#   (4, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R_0', 'rule_id': {0}}),\n",
    "#   (8, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')], 'rule_id': {1}}),\n",
    "#   (9, {'op': 'project', 'on': ['X', 'Y'], 'rule_id': {1}}),\n",
    "#   (10, {'op': 'calc', 'func': 'T', 'rule_id': {1}}),\n",
    "#   (11, {'op': 'rename', 'names': [(0, 'X'), (1, 'Y')], 'rule_id': {1}}),\n",
    "#   (6, {'op': 'join', 'rule_id': {1}}),\n",
    "#   (7, {'op': 'project', 'on': ['X', 'Y'], 'rel': '_R_1', 'rule_id': {1}})],\n",
    "#  [('R', 4, {}),\n",
    "#   ('R', 7, {}),\n",
    "#   (0, 'S', {}),\n",
    "#   (1, 'S2', {}),\n",
    "#   (2, 1, {}),\n",
    "#   (3, 0, {}),\n",
    "#   (3, 2, {}),\n",
    "#   (4, 3, {}),\n",
    "#   (8, 'S', {}),\n",
    "#   (9, 8, {}),\n",
    "#   (10, 9, {}),\n",
    "#   (11, 10, {}),\n",
    "#   (6, 8, {}),\n",
    "#   (6, 11, {}),\n",
    "#   (7, 6, {})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.add_rule(rec_r1,RelationDefinition(name='A', scheme=[int,int]))\n",
    "e.add_rule(rec_r2,RelationDefinition(name='A', scheme=[int,int]))\n",
    "e.add_rule(rec_r3,RelationDefinition(name='B', scheme=[int,int]))\n",
    "e.add_rule(rec_r4,RelationDefinition(name='B', scheme=[int,int]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(e.term_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.del_head('R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert e.rules_to_ids == {'A(X,Y) <- B(X,Y).': (3, 'A'),\n",
    " 'A(X,Y) <- C(X,Y).': (4, 'A'),\n",
    " 'B(X,Y) <- D(X,Y).': (5, 'B'),\n",
    " 'B(X,Y) <- A(X,Y).': (6, 'B')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(e.term_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recursive least fixed point logic algorithm mimicing the bottom up evalutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_rel(rel,db,**kwargs):\n",
    "    # helper function to get the relation from the db for external relations\n",
    "    return db[rel]\n",
    "\n",
    "op_to_func = {\n",
    "    'union':union,\n",
    "    'intersection':intersection,\n",
    "    'difference':difference,\n",
    "    'select':select,\n",
    "    'project':project,\n",
    "    'rename':rename,\n",
    "    'join':join,\n",
    "    'ie_map':ie_map,\n",
    "    'get_rel':get_rel,\n",
    "    'get_const':get_const,\n",
    "    'product':product,\n",
    "    'groupby':groupby\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _in_cycle(g):\n",
    "    return list(set(\n",
    "        itertools.chain.from_iterable(nx.cycles.simple_cycles(g))\n",
    "    ))\n",
    "\n",
    "def _depends_on_cycle(g):\n",
    "    in_cycle_nodes = _in_cycle(g)\n",
    "    depends_on_cycle = {\n",
    "        node for node in g.nodes if node in in_cycle_nodes or \n",
    "        len(set(nx.descendants(g,node)).intersection(in_cycle_nodes))>0\n",
    "    }\n",
    "    return depends_on_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _collect_children_and_run(G,u,results,stack,log=False):\n",
    "    children = list(G.successors(u))\n",
    "    u_data = G.nodes[u]\n",
    "\n",
    "    children_results = [results[v][-1] for v in children]\n",
    "    op_func = op_to_func[u_data['op']]\n",
    "\n",
    "    if log:\n",
    "        logger.debug(f\"computing node {u} with children {children} and data {u_data} , stack = {stack}\")\n",
    "        logger.debug(f\"children results are {children_results}\")\n",
    "        logger.debug(f\"children_data is {[G.nodes[v] for v in children]}\")\n",
    "    try:\n",
    "        res = op_func(*children_results,**u_data)\n",
    "    except Exception as e:\n",
    "        raise Exception(f'During excution of node {u} with args {children_results} and kwargs {u_data}'\n",
    "                        f' got error {e}'\n",
    "        )\n",
    "    if log:\n",
    "        logger.debug(f\"result of node {u} is {res}\")\n",
    "    results[u].append(res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_acyclic_node(G,u,results,stack=None):\n",
    "    res = _collect_children_and_run(G,u,results,[])\n",
    "    logger.debug(f\"setting {u} to final since it is acyclic\\n\")\n",
    "    G.nodes[u]['final'] = True\n",
    "    return res\n",
    "\n",
    "def compute_recursive_node(G,u,results,stack=None):\n",
    "\n",
    "    if stack is None:\n",
    "        stack = []\n",
    "\n",
    "    children = list(G.successors(u))\n",
    "    u_data = G.nodes[u]\n",
    "    op_func = op_to_func[u_data['op']]\n",
    "\n",
    "    if u_data.get('final',False):\n",
    "        return results[u][-1]    \n",
    "\n",
    "\n",
    "    logger.debug(f\"computing node {u} with stack {stack}\")\n",
    "\n",
    "\n",
    "    went_in_a_cycle = u in stack\n",
    "    if went_in_a_cycle:\n",
    "        logger.debug(f\"went in a cycle at {u}, computing op with empty children if necessary\\n\")\n",
    "        # for each child that doesnt have data, put an empty df instead of it\n",
    "        res = _collect_children_and_run(G,u,results,stack,log=True)\n",
    "        return res\n",
    "\n",
    "    # if we are here we are in a cycle but didnt return to an old position yet\n",
    "    # then we compute all our children first\n",
    "    for v in children:\n",
    "        stack.append(u)\n",
    "        compute_recursive_node(G,v,results,stack)\n",
    "        stack.pop()\n",
    "\n",
    "    # compute and mark as final if reached fixed point\n",
    "    res = _collect_children_and_run(G,u,results,stack,log=True)\n",
    "\n",
    "    all_children_final = all(G.nodes[v].get('final',False) for v in children)\n",
    "    fixed_point_reached = len(results[u])>1 and results[u][-1].equals(results[u][-2])\n",
    "\n",
    "    if all_children_final:\n",
    "        logger.debug(f\"setting {u} to final since all children are final\\n\")\n",
    "        G.nodes[u]['final'] = True\n",
    "    elif fixed_point_reached:\n",
    "        logger.debug(f\"setting {u} to final since fixed point has been achieved\\n\")\n",
    "        # if u==9:\n",
    "        #     logger.debug(f\"graph nodes are{g.nodes(data=True)}\")\n",
    "        G.nodes[u]['final'] = True\n",
    "    else:\n",
    "        logger.debug(f\"{u} not final yet so we will need to run another iteration\\n\")\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def compute_node(G,root,ret_inter=False):\n",
    "\n",
    "    # makes sure there is always a last value in the list for each key\n",
    "    # which is None\n",
    "    list_with_none_factory = lambda : [None]\n",
    "    results_dict = defaultdict(list_with_none_factory)\n",
    "\n",
    "    depends_on_cycle = _depends_on_cycle(G)\n",
    "    not_depends_on_cycle = [u for u in G.nodes if u not in depends_on_cycle]\n",
    "\n",
    "    # compute non cyclic nodes in postorder\n",
    "    non_cycle_topological_sort = list(nx.topological_sort(nx.DiGraph(nx.subgraph(G,not_depends_on_cycle))))\n",
    "    for u in non_cycle_topological_sort[::-1]:\n",
    "        compute_acyclic_node(G,u,results_dict)\n",
    "\n",
    "    logger.debug(f\"the following nodes were computed non cyclically {non_cycle_topological_sort}\")\n",
    "    # now that all initial conditions for recursions are set\n",
    "    # run the compute_recursive_node on u\n",
    "    logger.debug(f\"running compute_recursive_node on {root}\")\n",
    "\n",
    "    while True:\n",
    "        res = compute_recursive_node(G,root,results_dict)\n",
    "        if G.nodes[root].get('final',False):\n",
    "            break\n",
    "\n",
    "    if ret_inter:\n",
    "        return res,results_dict\n",
    "    else:\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test - path query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph  = nx.DiGraph()\n",
    "graph.add_nodes_from([\n",
    "    0,1,2,3,\n",
    "])\n",
    "graph.add_edges_from(\n",
    "    [(0,1),(0,2),(1,3),(2,3),(3,4)]\n",
    ")\n",
    "draw(graph)\n",
    "edges_df = pd.DataFrame(list(graph.edges),columns=['S','T'])\n",
    "edges_df\n",
    "db = DB({\n",
    "    'edges':edges_df\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_paths = pd.DataFrame(\n",
    "    [\n",
    "        [0,1],\n",
    "        [0,2],\n",
    "        [1,3],\n",
    "        [2,3],\n",
    "        [3,4],\n",
    "        [0,3],\n",
    "        [0,4],\n",
    "        [1,4],\n",
    "        [2,4]\n",
    "    ],\n",
    "    columns=['S','T']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "g.add_nodes_from([\n",
    "    ('edges',{'rel':'edges','op':'get_rel','db':db}),\n",
    "    (1,{'op':'rename','schema':['S','T']}),\n",
    "    (2,{'op':'rename','schema':['S','X']}),\n",
    "    (3,{'op':'rename','schema':['X','T']}),\n",
    "    (4,{'op':'join','schema':['S','X','T']}),\n",
    "    (5,{'op':'project','schema':['S','T']}),\n",
    "    ('reachable',{'op':'union','schema':[0,1]}),\n",
    "    (6,{'op':'rename','schema':['S','T']})]\n",
    ")\n",
    "g.add_edges_from([\n",
    "    (1,'edges'),\n",
    "    (2,'edges'),\n",
    "    (4,2),\n",
    "    (4,3),\n",
    "    (5,4),\n",
    "    ('reachable',5),\n",
    "    ('reachable',1),\n",
    "    (3,'reachable'),\n",
    "    (6,'reachable')\n",
    "])\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 6\n",
    "# with checkLogs():\n",
    "res,inter = compute_node(g,root,True)\n",
    "assert_df_equals(res,expected_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e2e tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 0 - path queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=Engine()\n",
    "e.set_relation(RelationDefinition(name='edges',scheme=[int,int]))\n",
    "e.add_facts('edges',edges_df)\n",
    "\n",
    "base_rule = Rule(\n",
    "    head=Relation(name='reachable',terms=[FreeVar(name='S'),FreeVar(name='T')]),\n",
    "    body=[\n",
    "        Relation(name='edges',terms=[FreeVar(name='S'),FreeVar(name='T')]),\n",
    "    ])\n",
    "\n",
    "rec_rule = Rule(\n",
    "    head=Relation(name='reachable',terms=[FreeVar(name='S'),FreeVar(name='T')]),\n",
    "    body=[\n",
    "        Relation(name='edges',terms=[FreeVar(name='S'),FreeVar(name='X')]),\n",
    "        Relation(name='reachable',terms=[FreeVar(name='X'),FreeVar(name='T')]),\n",
    "    ])\n",
    "\n",
    "e.add_rule(base_rule,RelationDefinition(name='reachable',scheme=[int,int]))\n",
    "e.add_rule(rec_rule,RelationDefinition(name='reachable',scheme=[int,int]))\n",
    "\n",
    "print(e.rules_to_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(e.run_query(Relation(name='reachable',terms=[FreeVar(name='S'),FreeVar(name='T')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,r = e.plan_query(Relation(name='reachable',terms=[FreeVar(name='S'),FreeVar(name='T')]))\n",
    "draw(q)\n",
    "# with checkLogs():\n",
    "res,inter = e.run_query(Relation(name='reachable',terms=[FreeVar(name='S'),FreeVar(name='T')]),return_intermediate=True)\n",
    "\n",
    "assert_df_equals(pd.Dataframe(columns=(\"S\", \"T\"), data=res),expected_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we actually got the intermediate results\n",
    "assert len(inter)!=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Engine()\n",
    "e.set_relation(RelationDefinition(name='S', scheme=[int,int]))\n",
    "e.set_relation(RelationDefinition(name='S2', scheme=[int,int,int]))\n",
    "\n",
    "e.add_rule(r1,RelationDefinition(name='R', scheme=[int,int]))\n",
    "e.add_rule(r2,RelationDefinition(name='R', scheme=[int,int]))\n",
    "\n",
    "e.add_facts('S',s)\n",
    "e.add_facts('S2',s2)\n",
    "\n",
    "def func(x,y):\n",
    "    return [(y,x)]\n",
    "\n",
    "ie_def = IEFunction(name='T',func=func,in_schema=[int,int],out_schema=[int,int])\n",
    "\n",
    "e.set_ie_function(ie_def)\n",
    "g = e._inline_db_and_ies_in_graph(e.term_graph)\n",
    "print(e.rules_to_ids)\n",
    "display(s)\n",
    "display(s2)\n",
    "# draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=(\"X\", \"Y\"), data=e.run_query(Relation(name='R',terms=[FreeVar(name='X'),FreeVar(name='Y')])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_df_equals(res,pd.DataFrame([\n",
    "    [1,1],\n",
    "    [2,2],\n",
    "    [3,3]\n",
    "],columns=['X','Y']))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=(\"S\",), data=e.run_query(Relation(name='R',terms=[FreeVar(name='S'),3])))\n",
    "assert_df_equals(res,pd.DataFrame([\n",
    "    [3]\n",
    "],columns=['S']))\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = Engine()\n",
    "e2.set_relation(RelationDefinition(name='C', scheme=[int,int]))\n",
    "e2.set_relation(RelationDefinition(name='D', scheme=[int,int]))\n",
    "\n",
    "for rule in [rec_r1,rec_r2,rec_r3,rec_r4]:\n",
    "    e2.add_rule(rule,RelationDefinition(name=rule.head.name, scheme=[int,int]))\n",
    "\n",
    "e2.add_fact(Relation(name='C',terms=[1,2]))\n",
    "e2.add_fact(Relation(name='D',terms=[3,4]))\n",
    "\n",
    "g2 = e2._inline_db_and_ies_in_graph(e2.term_graph)\n",
    "e2.rules_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with checkLogs():\n",
    "res = pd.DataFrame(columns=(\"X\", \"Y\"), data=e2.run_query(Relation(name='A',terms=[FreeVar(name='X'),FreeVar(name='Y')])))\n",
    "assert_df_equals(res,pd.DataFrame([\n",
    "    [3,4],\n",
    "    [1,2]\n",
    "],columns=['X','Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=(\"X\", \"Y\"), data=e2.run_query(Relation(name='B',terms=[FreeVar(name='X'),FreeVar(name='Y')])))\n",
    "assert_df_equals(res,pd.DataFrame([\n",
    "    [3,4],\n",
    "    [1,2]\n",
    "],columns=['X','Y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Engine()\n",
    "e.set_relation(RelationDefinition(name='string', scheme=[str]))\n",
    "e.add_fact(Relation(name='string',terms=['a']))\n",
    "e.add_fact(Relation(name='string',terms=['aa']))\n",
    "def func(str):\n",
    "    yield (len(str),)\n",
    "\n",
    "e.set_ie_function(IEFunction(name='Length',func=func,in_schema=[str],out_schema=[int]))\n",
    "\n",
    "r = Rule(\n",
    "    head=Relation(name='string_length', terms=[FreeVar(name='Str'), FreeVar(name='Len')]),\n",
    "    body=[\n",
    "        Relation(name='string', terms=[FreeVar(name='Str')]),\n",
    "        IERelation(name='Length', in_terms=[FreeVar(name='Str')], out_terms=[FreeVar(name='Len')]),\n",
    "    ])\n",
    "\n",
    "e.add_rule(r,RelationDefinition(name='string_length', scheme=[str,int]))\n",
    "# check that adding the same rule twice does nothing.\n",
    "e.add_rule(r,RelationDefinition(name='string_length', scheme=[str,int]))\n",
    "\n",
    "\n",
    "\n",
    "g = e._inline_db_and_ies_in_graph(e.term_graph)\n",
    "print(e.rules_to_ids)\n",
    "draw(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with checkLogs():\n",
    "res = pd.DataFrame(columns=(\"Str\", \"Len\"), data=e.run_query(Relation(name='string_length', terms=[FreeVar(name='Str'), FreeVar(name='Len')])))\n",
    "assert_df_equals(res,pd.DataFrame([\n",
    "    ['a',1],\n",
    "    ['aa',2]\n",
    "],columns=['Str','Len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = pd.DataFrame([\n",
    "    [1,2,\"str\"],\n",
    "    [1,3,\"str\"],\n",
    "    [3,4,\"str\"],\n",
    "    [3,5,\"str\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Engine()\n",
    "e.set_relation(RelationDefinition(name='S3', scheme=[int,int,str]))\n",
    "e.add_facts('S3',s3)\n",
    "\n",
    "e.set_agg_function(AGGFunction(name='max',func='max',in_schema=[int],out_schema=[float]))\n",
    "e.set_agg_function(AGGFunction(name='count',func='count',in_schema=[str],out_schema=[int]))\n",
    "\n",
    "agg_rule = Rule(\n",
    "    head=Relation(name='R', terms=[FreeVar(name='X'), FreeVar(name='Y'), FreeVar(name='Z')],\n",
    "    agg=[None,'max','count']\n",
    "    ),\n",
    "    body=[\n",
    "        Relation(name='S3', terms=[FreeVar(name='X'),FreeVar(name='Y'),FreeVar(name='Z')]),\n",
    "    ])\n",
    "\n",
    "e.add_rule(agg_rule,RelationDefinition(name='R', scheme=[int,int,int]))\n",
    "\n",
    "g = e._inline_db_and_ies_in_graph(e.term_graph)\n",
    "print(e.rules_to_ids)\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=(\"X\", \"Y\", \"Z\"), data=e.run_query(Relation(name='R',terms=[FreeVar(name='X'),FreeVar(name='Y'),FreeVar(name='Z')])))\n",
    "assert_df_equals(res,pd.DataFrame([\n",
    "    [1,3.0,2],\n",
    "    [3,5.0,2]\n",
    "],columns=['X','Y','Z']))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
