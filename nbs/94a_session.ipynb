{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Union, Optional, Callable, Type, Iterable, no_type_check, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from lark.lark import Lark\n",
    "import networkx as nx\n",
    "from pandas import DataFrame\n",
    "from tabulate import tabulate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| output: false\n",
    "from spannerlib.utils import get_base_file_path,checkLogs\n",
    "from spannerlib.primitive_types import Span\n",
    "from spannerlib.engine import SqliteEngine\n",
    "from spannerlib.ast_node_types import AddFact, RelationDeclaration\n",
    "from spannerlib.primitive_types import Span, DataTypes, DataTypeMapping\n",
    "from spannerlib.engine import FALSE_VALUE, TRUE_VALUE\n",
    "from spannerlib.execution import (Query, FREE_VAR_PREFIX, naive_execution)\n",
    "from spannerlib.adding_inference_rules_to_term_graph import AddRulesToTermGraph\n",
    "from spannerlib.optimizations_passes import RemoveUselessRelationsFromRule\n",
    "from spannerlib.lark_passes import (RemoveTokens, FixStrings, CheckReservedRelationNames,\n",
    "                                              ConvertSpanNodesToSpanInstances, ConvertStatementsToStructuredNodes,\n",
    "                                              CheckDefinedReferencedVariables,\n",
    "                                              CheckReferencedRelationsExistenceAndArity,\n",
    "                                              CheckReferencedIERelationsExistenceAndArity, CheckRuleSafety,\n",
    "                                              TypeCheckAssignments, TypeCheckRelations,\n",
    "                                              SaveDeclaredRelationsSchemas, ResolveVariablesReferences,\n",
    "                                              ExecuteAssignments, AddStatementsToNetxParseGraph, GenericPass)\n",
    "#from spannerlib.graphs import TermGraph, NetxStateGraph, GraphBase, TermGraphBase\n",
    "from spannerlib.symbol_table import SymbolTable, SymbolTableBase\n",
    "from spannerlib.general_utils import rule_to_relation_name, string_to_span, SPAN_PATTERN, QUERY_RESULT_PREFIX\n",
    "from spannerlib.passes_utils import LarkNode\n",
    "from spannerlib.ie_func.json_path import JsonPath, JsonPathFull\n",
    "from spannerlib.ie_func.nlp import (Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment, TrueCase)\n",
    "from spannerlib.ie_func.python_regex import PYRGX, PYRGX_STRING\n",
    "from spannerlib.ie_func.rust_spanner_regex import RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE\n",
    "from spannerlib.utils import patch_method, get_base_file_path, get_lib_name\n",
    "from spannerlib.grammar import parse_spannerlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "CSV_DELIMITER = \";\"\n",
    "\n",
    "# ordered by rgx, json, nlp, etc.\n",
    "PREDEFINED_IE_FUNCS = [PYRGX, PYRGX_STRING, RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE,\n",
    "                       JsonPath, JsonPathFull,\n",
    "                       Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment,\n",
    "                       TrueCase]\n",
    "\n",
    "STRING_PATTERN = re.compile(r\"^[^\\r\\n]+$\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _infer_relation_type(row: Iterable # an iterable of values, extracted from a csv file or a dataframe\n",
    "                        ) -> Sequence[DataTypes]: # Inferred tpye list of the given relation\n",
    "    \"\"\"\n",
    "    Guess the relation type based on the data.\n",
    "    We support both the actual types (e.g. 'Span'), and their string representation ( e.g. `\"[0,8)\"`).\n",
    "\n",
    "    **@raise** ValueError: if there is a cell inside `row` of an illegal type.\n",
    "    \"\"\"\n",
    "    relation_types = []\n",
    "    for cell in row:\n",
    "        try:\n",
    "            int(cell)  # check if the cell can be converted to integer\n",
    "            relation_types.append(DataTypes.integer)\n",
    "        except (ValueError, TypeError):\n",
    "            if isinstance(cell, Span) or re.match(SPAN_PATTERN, cell):\n",
    "                relation_types.append(DataTypes.span)\n",
    "            elif re.match(STRING_PATTERN, cell):\n",
    "                relation_types.append(DataTypes.string)\n",
    "            else:\n",
    "                raise ValueError(f\"value doesn't match any datatype: {cell}\")\n",
    "\n",
    "    return relation_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _infer_relation_type([1, 2, 3]) == [ DataTypes.integer,DataTypes.integer,DataTypes.integer]\n",
    "assert _infer_relation_type([1, 'a']) == [ DataTypes.integer,DataTypes.string]\n",
    "assert _infer_relation_type(['[0,1)','[0, 1)',Span(1,3)]) == [DataTypes.span,DataTypes.span,DataTypes.span]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _verify_relation_types(row: Iterable, expected_types: Iterable[DataTypes]) -> None:\n",
    "    if _infer_relation_type(row) != expected_types:\n",
    "        raise Exception(f\"row:\\n{str(row)}\\ndoes not match the relation's types:\\n{str(expected_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _text_to_typed_data(term_list: Sequence[DataTypeMapping.term], relation_types: Sequence[DataTypes]) -> List[DataTypeMapping.term]:\n",
    "    transformed_term_list: List[DataTypeMapping.term] = []\n",
    "    for str_or_object, rel_type in zip(term_list, relation_types):\n",
    "        if rel_type == DataTypes.span:\n",
    "            if isinstance(str_or_object, Span):\n",
    "                transformed_term_list.append(str_or_object)\n",
    "            else:\n",
    "                assert isinstance(str_or_object, str), \"a span can only be a Span object or a string\"\n",
    "                transformed_span = string_to_span(str_or_object)\n",
    "                if transformed_span is None:\n",
    "                    raise TypeError(f\"expected a Span, found this instead: {str_or_object}\")\n",
    "                transformed_term_list.append(transformed_span)\n",
    "\n",
    "        elif rel_type == DataTypes.integer:\n",
    "            if isinstance(str_or_object, Span):\n",
    "                raise TypeError(f\"expected an int, found Span instead: {str_or_object}\")\n",
    "            transformed_term_list.append(int(str_or_object))\n",
    "        else:\n",
    "            assert rel_type == DataTypes.string, f\"illegal type given: {rel_type}\"\n",
    "            transformed_term_list.append(str_or_object)\n",
    "\n",
    "    return transformed_term_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def format_query_results(query: Query, # the query that was executed, and outputted `query_results`\n",
    "                         query_results: List # the results after executing the aforementioned query\n",
    "                         ) -> Union[DataFrame, List]: # a false value, a true value, or a dataframe representing the query + its results\n",
    "    \"\"\"\n",
    "    Formats a single result from the engine into a usable format.\n",
    "    \"\"\"\n",
    "    assert isinstance(query_results, list), \"illegal results format\"\n",
    "\n",
    "    # check for the special conditions for which we can't print a table: no results were returned or a single\n",
    "    # empty tuple was returned\n",
    "\n",
    "    if query_results == FALSE_VALUE:  # empty list := false\n",
    "        return FALSE_VALUE\n",
    "    elif query_results == TRUE_VALUE:  # single tuple := true\n",
    "        return TRUE_VALUE\n",
    "    else:\n",
    "        # convert the resulting tuples to a more organized format\n",
    "        results_matrix = []\n",
    "        for result in query_results:\n",
    "            # span tuples are converted to Span objects\n",
    "            converted_span_result = [Span(term[0], term[1]) if (isinstance(term, tuple) and len(term) == 2)\n",
    "                                     else term\n",
    "                                     for term in result]\n",
    "\n",
    "            results_matrix.append(converted_span_result)\n",
    "\n",
    "        # get the free variables of the query, they will be used as headers\n",
    "        query_free_vars = [term for term, term_type in zip(query.term_list, query.type_list)\n",
    "                           if term_type is DataTypes.free_var_name]\n",
    "\n",
    "        return DataFrame(data=results_matrix, columns=query_free_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tabulate_result(result: Union[DataFrame, List] # the query result (free variable names are the dataframe's column names)\n",
    "                    ) -> str: # a tabulated string\n",
    "    \"\"\"\n",
    "    Organizes a query result in a table <br>\n",
    "    for example: <br>\n",
    "    ```prolog\n",
    "    {QUERY_RESULT_PREFIX}'lecturer_of(X, \"abigail\")':\n",
    "       X\n",
    "    -------\n",
    "     linus\n",
    "     walter\n",
    "    ```\n",
    "    There are two cases in which a table won't be printed:\n",
    "\n",
    "    1. **Query returned no results**: This will result in an output of `[]`.\n",
    "\n",
    "    2. **Query returned a single empty tuple**: The output will be `[()]`.\n",
    "    \"\"\"\n",
    "    if isinstance(result, DataFrame):\n",
    "        # query results can be printed as a table\n",
    "        result_string = tabulate(result, headers=\"keys\", tablefmt=\"presto\", stralign=\"center\", showindex=False)\n",
    "    else:\n",
    "        assert isinstance(result, list), \"illegal result format\"\n",
    "        if len(result) == 0:\n",
    "            result_string = \"[]\"\n",
    "        else:\n",
    "            assert len(result) == 1, \"illegal result format\"\n",
    "            result_string = \"[()]\"\n",
    "\n",
    "    return result_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def queries_to_string(query_results: List[Tuple[Query, List]] # List[the Query object used in execution, the execution's results (from engine)]\n",
    "                      ) -> str: # a tabulated string\n",
    "    \"\"\"\n",
    "    Takes in a list of results from the engine and converts them into a single string, which contains\n",
    "    either a table, a false value (=`[]`), or a true value (=`[tuple()]`), for each result.\n",
    "\n",
    "    for example:\n",
    "\n",
    "    ```prolog\n",
    "    {QUERY_RESULT_PREFIX}'lecturer_of(X, \"abigail\")':\n",
    "       X\n",
    "    -------\n",
    "     linus\n",
    "     walter\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    all_result_strings = []\n",
    "    query_results = list(filter(None, query_results))  # remove Nones\n",
    "    for query, results in query_results:\n",
    "        query_result_string = tabulate_result(format_query_results(query, results))\n",
    "        query_title = f\"{QUERY_RESULT_PREFIX}'{query}':\"\n",
    "\n",
    "        # combine the title and table to a single string and save it to the prints buffer\n",
    "        titled_result_string = f'{query_title}\\n{query_result_string}\\n'\n",
    "        all_result_strings.append(titled_result_string)\n",
    "    return \"\\n\".join(all_result_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Session:\n",
    "    def __init__(self, \n",
    "                 symbol_table: Optional[SymbolTableBase] = None, # symbol table to help with all semantic checks\n",
    "                 parse_graph: Optional[nx.Digraph] = None, # an AST that contains nodes which represent commands\n",
    "                 term_graph: Optional[nx.DiGraph] = None): # a graph that holds all the connection between the relations\n",
    "        \"\"\"\n",
    "        A class that serves as the central connection point between various modules in the system.\n",
    "\n",
    "        This class takes input data and coordinates communication between different modules by sending the relevant parts\n",
    "        of the input to each module. It also orchestrates the execution of micro passes and handles engine-related tasks. <br>\n",
    "        Finally, it formats the results before presenting them to the user.\n",
    "\n",
    "        \"\"\"\n",
    "        if symbol_table is None:\n",
    "            self._symbol_table: SymbolTableBase = SymbolTable()\n",
    "            self._symbol_table.register_predefined_ie_functions(PREDEFINED_IE_FUNCS)\n",
    "\n",
    "        else:\n",
    "            self._symbol_table = symbol_table\n",
    "\n",
    "        self._parse_graph = nx.DiGraph() if parse_graph is None else parse_graph\n",
    "        self._term_graph = nx.DiGraph() if term_graph is None else term_graph\n",
    "        self._engine = SqliteEngine()\n",
    "\n",
    "        self._pass_stack: List[Type[GenericPass]] = [\n",
    "            RemoveTokens,\n",
    "            FixStrings,\n",
    "            CheckReservedRelationNames,\n",
    "            ConvertSpanNodesToSpanInstances,\n",
    "            ConvertStatementsToStructuredNodes,\n",
    "            CheckDefinedReferencedVariables,\n",
    "            CheckReferencedRelationsExistenceAndArity,\n",
    "            CheckReferencedIERelationsExistenceAndArity,\n",
    "            #TODO agg - add here checkAggFunctionsExistanceAndArity\n",
    "            CheckRuleSafety,\n",
    "            TypeCheckAssignments,\n",
    "            TypeCheckRelations, # TODO agg - add here type check for agg function\n",
    "            SaveDeclaredRelationsSchemas,\n",
    "            ResolveVariablesReferences,\n",
    "            ExecuteAssignments,\n",
    "             # note that AddStatementsToNetxParseGraph and AddRulesToTermGraph are mutually exclusive, only one will actually run per statement\n",
    "            # TODO agg remove AddStatementsToNetxParseGraph just use the parsetree directly\n",
    "            # TODO remove AddRulesToTermGraph, make it a side effect of the executionÂ§\n",
    "            # AddStatementsToNetxParseGraph,\n",
    "            # AddRulesToTermGraph # TODO agg - change this pass to also add the group by and aggregation operations\n",
    "        ]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"\\n\".join([repr(self._symbol_table), repr(self._parse_graph)])\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f'Symbol Table:\\n{str(self._symbol_table)}\\n\\nTerm Graph:\\n{str(self._parse_graph)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _run_passes(self: Session, lark_tree: LarkNode, pass_list: list=None) -> None:\n",
    "    \"\"\"\n",
    "    Runs the passes in pass_list on tree, one after another.\n",
    "    \"\"\"\n",
    "    #logger.debug(f\"initial lark tree:\\n{lark_tree.pretty()}\")\n",
    "    #logger.debug(f\"initial term graph:\\n{self._term_graph}\")\n",
    "\n",
    "    if pass_list is None:\n",
    "        pass_list = self._pass_stack\n",
    "\n",
    "    for curr_pass in pass_list:\n",
    "        curr_pass_object = curr_pass(parse_graph=self._parse_graph,\n",
    "                                        symbol_table=self._symbol_table,\n",
    "                                        term_graph=self._term_graph)\n",
    "        new_tree = curr_pass_object.run_pass(tree=lark_tree)\n",
    "        if new_tree is not None:\n",
    "            lark_tree = new_tree\n",
    "            #logger.debug(f\"lark tree after {curr_pass.__name__}:\\n{lark_tree.pretty()}\")\n",
    "    return lark_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def get_pass_stack(self: Session) -> List[Type[GenericPass]]:\n",
    "    \"\"\"\n",
    "    @return: the current pass stack.\n",
    "    \"\"\"\n",
    "\n",
    "    return self._pass_stack.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.get_pass_stack\n",
       "\n",
       ">      Session.get_pass_stack ()\n",
       "\n",
       "@return: the current pass stack."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.get_pass_stack\n",
       "\n",
       ">      Session.get_pass_stack ()\n",
       "\n",
       "@return: the current pass stack."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.get_pass_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def set_pass_stack(self: Session, user_stack: List[Type[GenericPass]] #  a user supplied pass stack\n",
    "                    ) -> List[Type[GenericPass]]: # success message with the new pass stack\n",
    "    \"\"\"\n",
    "    Sets a new pass stack instead of the current one.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(user_stack) is not list:\n",
    "        raise TypeError('user stack should be a list of passes')\n",
    "    for pass_ in user_stack:\n",
    "        if not issubclass(pass_, GenericPass):\n",
    "            raise TypeError('user stack should be a subclass of `GenericPass`')\n",
    "\n",
    "    self._pass_stack = user_stack.copy()\n",
    "    return self.get_pass_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.set_pass_stack\n",
       "\n",
       ">      Session.set_pass_stack\n",
       ">                              (user_stack:List[Type[spannerlib.lark_passes.Gene\n",
       ">                              ricPass]])\n",
       "\n",
       "Sets a new pass stack instead of the current one.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| user_stack | List[Type[GenericPass]] | a user supplied pass stack |\n",
       "| **Returns** | **List[Type[GenericPass]]** | **success message with the new pass stack** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.set_pass_stack\n",
       "\n",
       ">      Session.set_pass_stack\n",
       ">                              (user_stack:List[Type[spannerlib.lark_passes.Gene\n",
       ">                              ricPass]])\n",
       "\n",
       "Sets a new pass stack instead of the current one.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| user_stack | List[Type[GenericPass]] | a user supplied pass stack |\n",
       "| **Returns** | **List[Type[GenericPass]]** | **success message with the new pass stack** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.set_pass_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def print_all_rules(self: Session, head: Optional[str] = None # if specified it will print only rules with the given head relation name\n",
    "                    ) -> None:\n",
    "    \"\"\"\n",
    "    Prints all the rules that are registered.\n",
    "    \"\"\"\n",
    "\n",
    "    self._term_graph.print_all_rules(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _remove_rule_relation_from_symbols_and_engine(self: Session, relation_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Removes the relation from the symbol table and the execution tables.\n",
    "\n",
    "    @param relation_name: the name of the relation ot remove.\n",
    "    \"\"\"\n",
    "    self._symbol_table.remove_rule_relation(relation_name)\n",
    "    self._engine.remove_table(relation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _add_imported_relation_to_engine(self: Session, relation_table: Iterable, relation_name: str, relation_types: Sequence[DataTypes]) -> None:\n",
    "    symbol_table = self._symbol_table\n",
    "    engine = self._engine\n",
    "    # first make sure the types are legal, then we add them to the engine (to make sure\n",
    "    #  we don't add them in case of an error)\n",
    "    facts = []\n",
    "\n",
    "    for row in relation_table:\n",
    "        _verify_relation_types(row, relation_types)\n",
    "        typed_line = _text_to_typed_data(row, relation_types)\n",
    "        facts.append(AddFact(relation_name, typed_line, relation_types))\n",
    "\n",
    "    # declare relation if it does not exist\n",
    "    if not symbol_table.contains_relation(relation_name):\n",
    "        engine.declare_relation_table(RelationDeclaration(relation_name, relation_types))\n",
    "        symbol_table.add_relation_schema(relation_name, relation_types, False)\n",
    "\n",
    "    for fact in facts:\n",
    "        engine.add_fact(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def send_commands_result_into_df(self: Session, commands: str # the commands to run\n",
    "                                    ) -> Union[DataFrame, List]: # formatted results (possibly a dataframe)\n",
    "    \"\"\"\n",
    "    run commands as usual and output their formatted results into a dataframe (the commands should contain a query)\n",
    "    \"\"\"\n",
    "    commands_results = self.run_commands(commands, print_results=False)\n",
    "    if len(commands_results) != 1:\n",
    "        raise Exception(\"the commands must have exactly one output\")\n",
    "\n",
    "    return format_query_results(*commands_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def _relation_name_to_query(self: Session, relation_name: str) -> str:\n",
    "    symbol_table = self._symbol_table\n",
    "    relation_schema = symbol_table.get_relation_schema(relation_name)\n",
    "    relation_arity = len(relation_schema)\n",
    "    query = (f\"?{relation_name}(\" + \", \".join(f\"{FREE_VAR_PREFIX}{i}\" for i in range(relation_arity)) + \")\")\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def export(self: Session, query=None, # query string to export\n",
    "            relation_name: str =None, # whether to export an entire relation (either extrinsic or intrinsic), cant be used together with query parameter\n",
    "            csv_path=None, # whether to export to csv, by default returns as a dataframe\n",
    "            delimiter: str = CSV_DELIMITER, # the delimeter to use in the csv file\n",
    "        ) -> Union[DataFrame, List]:\n",
    "    \"\"\"Exports the given query or relation to a csv file or a dataframe.\n",
    "    \"\"\"\n",
    "    if query is None and relation_name is None:\n",
    "        raise Exception(\"either a query or a relation name must be specified\")\n",
    "    elif query is not None and relation_name is not None:\n",
    "        raise Exception(\"either a query or a relation name must be specified, not both\")\n",
    "    \n",
    "    if relation_name is not None:\n",
    "        query = self._relation_name_to_query(relation_name)\n",
    "    \n",
    "    if csv_path is not None:\n",
    "        self.send_commands_result_into_csv(query,csv_path,delimiter)\n",
    "    else:\n",
    "        return self.send_commands_result_into_df(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.export\n",
       "\n",
       ">      Session.export (query=None, relation_name:str=None, csv_path=None,\n",
       ">                      delimiter:str=';')\n",
       "\n",
       "Exports the given query or relation to a csv file or a dataframe.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | NoneType | None | query string to export |\n",
       "| relation_name | str | None | whether to export an entire relation (either extrinsic or intrinsic), cant be used together with query parameter |\n",
       "| csv_path | NoneType | None | whether to export to csv, by default returns as a dataframe |\n",
       "| delimiter | str | ; | the delimeter to use in the csv file |\n",
       "| **Returns** | **Union[DataFrame, List]** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.export\n",
       "\n",
       ">      Session.export (query=None, relation_name:str=None, csv_path=None,\n",
       ">                      delimiter:str=';')\n",
       "\n",
       "Exports the given query or relation to a csv file or a dataframe.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | NoneType | None | query string to export |\n",
       "| relation_name | str | None | whether to export an entire relation (either extrinsic or intrinsic), cant be used together with query parameter |\n",
       "| csv_path | NoneType | None | whether to export to csv, by default returns as a dataframe |\n",
       "| delimiter | str | ; | the delimeter to use in the csv file |\n",
       "| **Returns** | **Union[DataFrame, List]** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "from spannerlib.passes_utils import ParseNodeType\n",
    "\n",
    "@patch_method\n",
    "def run_commands(self: Session, query: str, # The user's input\n",
    "                    print_results: bool = True, # whether to print the results to stdout or not\n",
    "                    format_results: bool = False, # if this is true, return the formatted result instead of the `[Query, List]` pair\n",
    "                    ) -> (Union[List[Union[List, List[Tuple], DataFrame]], List[Tuple[Query, List]]]): # the results of every query, in a list\n",
    "    \"\"\"\n",
    "    Generates an AST and passes it through the pass stack.\n",
    "    \"\"\"\n",
    "    query_results = []\n",
    "    parse_tree = parse_spannerlog(query,start='start')\n",
    "    engine = self._engine\n",
    "    term_graph = self._term_graph\n",
    "    for statement in parse_tree.children:\n",
    "        clean_statement = self._run_passes(statement, self._pass_stack)\n",
    "\n",
    "        action_type=clean_statement.data.value\n",
    "        action_input_value = clean_statement.children[0]\n",
    "        \n",
    "\n",
    "        def run_query(q):\n",
    "            query_plan = plan_query(q,term_graph,engine)\n",
    "            result = partial_fixed_point_execution(query_plan,engine)\n",
    "\n",
    "        node_type_to_action = {\n",
    "            'rule': lambda rule: engine.declare_relation_table(rule.head_relation.as_relation_declaration()),\n",
    "            'relation_declaration': engine.declare_relation_table,\n",
    "            'add_fact': engine.add_fact,\n",
    "            'remove_fact': engine.remove_fact,\n",
    "            'query': run_query\n",
    "        }\n",
    "\n",
    "        if action_type in node_type_to_action:\n",
    "            action_result = node_type_to_action[action_type](action_input_value)\n",
    "        \n",
    "        if action_type == ParseNodeType.QUERY:\n",
    "            query_result = action_result\n",
    "            if query_result is not None:\n",
    "                query_results.append(query_result)\n",
    "            if print_results:\n",
    "                print(queries_to_string([query_result]))\n",
    "\n",
    "        #TODO implement plan_query and partial_fixed_point_execution before testing this\n",
    "        # query_result = self._execution(parse_graph=self._parse_graph,\n",
    "        #                                 symbol_table=self._symbol_table,\n",
    "        #                                 spannerlog_engine=self._engine,\n",
    "        #                                 term_graph=self._term_graph)\n",
    "\n",
    "    if format_results:\n",
    "        return [format_query_results(*query_result) for query_result in query_results]\n",
    "    else:\n",
    "        return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.run_commands\n",
       "\n",
       ">      Session.run_commands (query:str, print_results:bool=True,\n",
       ">                            format_results:bool=False)\n",
       "\n",
       "Generates an AST and passes it through the pass stack.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | str |  | The user's input |\n",
       "| print_results | bool | True | whether to print the results to stdout or not |\n",
       "| format_results | bool | False | if this is true, return the formatted result instead of the `[Query, List]` pair |\n",
       "| **Returns** | **Union[List[Union[List, List[Tuple], DataFrame]], List[Tuple[Query, List]]]** |  | **the results of every query, in a list** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.run_commands\n",
       "\n",
       ">      Session.run_commands (query:str, print_results:bool=True,\n",
       ">                            format_results:bool=False)\n",
       "\n",
       "Generates an AST and passes it through the pass stack.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| query | str |  | The user's input |\n",
       "| print_results | bool | True | whether to print the results to stdout or not |\n",
       "| format_results | bool | False | if this is true, return the formatted result instead of the `[Query, List]` pair |\n",
       "| **Returns** | **Union[List[Union[List, List[Tuple], DataFrame]], List[Tuple[Query, List]]]** |  | **the results of every query, in a list** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.run_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def register(self: Session, ie_function: Callable, ie_function_name: str, in_rel: List[DataTypes],\n",
    "            out_rel: Union[List[DataTypes], Callable[[int], Sequence[DataTypes]]]) -> None:\n",
    "    \"\"\"\n",
    "    Registers an ie function.\n",
    "\n",
    "    @see params in `IEFunction`'s __init__.\n",
    "    \"\"\"\n",
    "    self._symbol_table.register_ie_function(ie_function, ie_function_name, in_rel, out_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.register\n",
       "\n",
       ">      Session.register (ie_function:Callable, ie_function_name:str,\n",
       ">                        in_rel:List[spannerlib.primitive_types.DataTypes], out_\n",
       ">                        rel:Union[List[spannerlib.primitive_types.DataTypes],Ca\n",
       ">                        llable[[int],Sequence[spannerlib.primitive_types.DataTy\n",
       ">                        pes]]])\n",
       "\n",
       "Registers an ie function.\n",
       "\n",
       "@see params in `IEFunction`'s __init__."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.register\n",
       "\n",
       ">      Session.register (ie_function:Callable, ie_function_name:str,\n",
       ">                        in_rel:List[spannerlib.primitive_types.DataTypes], out_\n",
       ">                        rel:Union[List[spannerlib.primitive_types.DataTypes],Ca\n",
       ">                        llable[[int],Sequence[spannerlib.primitive_types.DataTy\n",
       ">                        pes]]])\n",
       "\n",
       "Registers an ie function.\n",
       "\n",
       "@see params in `IEFunction`'s __init__."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.register)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree(Token('RULE', 'relation_declaration'), [RelationDeclaration(A, [<DataTypes.string: 0>, <DataTypes.string: 0>])]),\n",
       " Tree(Token('RULE', 'relation_declaration'), [RelationDeclaration(B, [<DataTypes.string: 0>, <DataTypes.string: 0>])]),\n",
       " Tree(Token('RULE', 'rule'), [Rule(C(X, Y) <- A(X, Y))]),\n",
       " Tree(Token('RULE', 'rule'), [Rule(D(X, Y, X) <- C(X, Y))]),\n",
       " Tree(Token('RULE', 'rule'), [Rule(D(X, Y, Z) <- A(X, \"1\"), B(X, Y), ID(X) -> (Y), ID2(Y) -> (Z, W))])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "        new A(str, str)\n",
    "        new B(str, str)\n",
    "        C(X, Y) <- A(X, Y)\n",
    "        D(X, Y, X) <- C(X, Y)\n",
    "        D(X, Y, Z) <- A(X, \"1\"), B(X, Y), ID(X) -> (Y), ID2(Y)->(Z,W)  \n",
    "    \"\"\"\n",
    "\n",
    "def ID(string: str):\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield f'{string}_id'\n",
    "\n",
    "def ID2(string: str):\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield f'{string}_id2_z',f'{string}_id2_w'\n",
    "\n",
    "session = Session()\n",
    "session.register(ID,'ID', [DataTypes.string], [DataTypes.string])\n",
    "session.register(ID2,'ID2', [DataTypes.string], [DataTypes.string,DataTypes.string])\n",
    "\n",
    "parsed_commands = parse_spannerlog(commands)\n",
    "clean_statements=[]\n",
    "for statement in parsed_commands.children[:]:\n",
    "    clean_statements.append( session._run_passes(statement))\n",
    "clean_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rule(D(X, Y, Z) <- A(X, \"1\"), B(X, Y), ID(X) -> (Y), ID2(Y) -> (Z, W))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = clean_statements[-1].children[0]\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DataTypes.free_var_name: 3>,\n",
       " <DataTypes.free_var_name: 3>,\n",
       " <DataTypes.free_var_name: 3>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.head_relation.get_type_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spannerlib.ast_node_types.Relation"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r.body_relation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token('RULE', 'relation'),\n",
       " Token('RULE', 'relation'),\n",
       " Token('RULE', 'ie_relation'),\n",
       " Token('RULE', 'ie_relation')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.body_relation_type_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree(Token('RULE', 'relation_declaration'), [RelationDeclaration(Parent, [<DataTypes.string: 0>, <DataTypes.string: 0>])]),\n",
       " Tree(Token('RULE', 'add_fact'), [AddFact(Parent(\"Sam\", \"Noah\"))]),\n",
       " Tree(Token('RULE', 'add_fact'), [AddFact(Parent(\"Noah\", \"Austin\"))]),\n",
       " Tree(Token('RULE', 'add_fact'), [AddFact(Parent(\"Austin\", \"Stephen\"))]),\n",
       " Tree(Token('RULE', 'rule'), [Rule(GrandParent(G, C) <- Parent(G, M), Parent(M, C))])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new Parent(str, str)\n",
    "    Parent(\"Sam\", \"Noah\")\n",
    "    Parent(\"Noah\", \"Austin\")\n",
    "    Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "    GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
    "    #?GrandParent(X, \"Austin\")\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "parsed_commands = parse_spannerlog(commands)\n",
    "clean_statements=[]\n",
    "for statement in parsed_commands.children[:]:\n",
    "    clean_statements.append( session._run_passes(statement))\n",
    "clean_statements\n",
    "# _ = session.run_commands(commands)\n",
    "# p_graph,t_graph = session.run_commands('?GrandParent(X, \"Austin\")',ret_graphs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree(Token('RULE', 'relation_declaration'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'decl_term_list'), [Tree('decl_string', []), Tree('decl_string', [])])]),\n",
       " Tree(Token('RULE', 'add_fact'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'const_term_list'), [Tree(Token('RULE', 'string'), [Token('STRING', '\"Sam\"')]), Tree(Token('RULE', 'string'), [Token('STRING', '\"Noah\"')])])]),\n",
       " Tree(Token('RULE', 'add_fact'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'const_term_list'), [Tree(Token('RULE', 'string'), [Token('STRING', '\"Noah\"')]), Tree(Token('RULE', 'string'), [Token('STRING', '\"Austin\"')])])]),\n",
       " Tree(Token('RULE', 'add_fact'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'const_term_list'), [Tree(Token('RULE', 'string'), [Token('STRING', '\"Austin\"')]), Tree(Token('RULE', 'string'), [Token('STRING', '\"Stephen\"')])])]),\n",
       " Tree(Token('RULE', 'rule'), [Tree(Token('RULE', 'rule_head'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'GrandParent')]), Tree(Token('RULE', 'free_var_name_list'), [Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'G')]), Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'C')])])]), Tree(Token('RULE', 'rule_body_relation_list'), [Tree(Token('RULE', 'relation'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'term_list'), [Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'G')]), Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'M')])])]), Tree(Token('RULE', 'relation'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'term_list'), [Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'M')]), Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'C')])])])])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_commands.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_statement' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m action_type\u001b[38;5;241m=\u001b[39m\u001b[43mclean_statement\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m      2\u001b[0m action_input_value \u001b[38;5;241m=\u001b[39m clean_statement\u001b[38;5;241m.\u001b[39mchildren[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m action_type,action_input_value\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_statement' is not defined"
     ]
    }
   ],
   "source": [
    "action_type=clean_statement.data.type\n",
    "action_input_value = clean_statement.children[0]\n",
    "action_type,action_input_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relation_declaration'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_commands.children[0].data.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree(Token('RULE', 'relation_declaration'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'decl_term_list'), [Tree('decl_string', []), Tree('decl_string', [])])]),\n",
       " Tree(Token('RULE', 'add_fact'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'const_term_list'), [Tree(Token('RULE', 'string'), [Token('STRING', '\"Sam\"')]), Tree(Token('RULE', 'string'), [Token('STRING', '\"Noah\"')])])]),\n",
       " Tree(Token('RULE', 'add_fact'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'const_term_list'), [Tree(Token('RULE', 'string'), [Token('STRING', '\"Noah\"')]), Tree(Token('RULE', 'string'), [Token('STRING', '\"Austin\"')])])]),\n",
       " Tree(Token('RULE', 'add_fact'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'const_term_list'), [Tree(Token('RULE', 'string'), [Token('STRING', '\"Austin\"')]), Tree(Token('RULE', 'string'), [Token('STRING', '\"Stephen\"')])])]),\n",
       " Tree(Token('RULE', 'rule'), [Tree(Token('RULE', 'rule_head'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'GrandParent')]), Tree(Token('RULE', 'free_var_name_list'), [Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'G')]), Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'C')])])]), Tree(Token('RULE', 'rule_body_relation_list'), [Tree(Token('RULE', 'relation'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'term_list'), [Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'G')]), Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'M')])])]), Tree(Token('RULE', 'relation'), [Tree(Token('RULE', 'relation_name'), [Token('UPPER_CASE_NAME', 'Parent')]), Tree(Token('RULE', 'term_list'), [Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'M')]), Tree(Token('RULE', 'free_var_name'), [Token('UPPER_CASE_NAME', 'C')])])])])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_commands.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RULE'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_statement.data.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spannerlib.graphs import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmZsb3djaGFydCBUQgo=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(session._term_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def plan_query(query,term_graph,optimization_passes=None):\n",
    "    if optimization_passes is None:\n",
    "        optimization_passes = []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_fixed_point_execution(g):\n",
    "    pass\n",
    "#compute_node\n",
    "\n",
    "# if node is not part of circle,\n",
    "# compute it by computing all of its children and performing the nodes operation on them.\n",
    "\n",
    "# if its a part of a cycle, \n",
    "    #compute current iterations\n",
    "\n",
    "\n",
    "# compute_current_iteration (i)\n",
    "    # take the (i-1) value of children that are in the cycle\n",
    "    # take the final value of children that are not in the cycle\n",
    "\n",
    "    # compute the node based on the children values, assign it to the values of the ith iteration of the node\n",
    "    # if the value of the node didnt change from last time, mark the node as finished and return\n",
    "\n",
    "\n",
    "# TODO from here, add good drawing to the graph, seperate query execution from side effect execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plan_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m session \u001b[38;5;241m=\u001b[39m Session()\n\u001b[1;32m     11\u001b[0m _ \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrun_commands(commands)\n\u001b[0;32m---> 12\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_commands\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m?GrandParent(X, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAustin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 38\u001b[0m, in \u001b[0;36mrun_commands\u001b[0;34m(self, query, print_results, format_results)\u001b[0m\n\u001b[1;32m     29\u001b[0m node_type_to_action \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrule\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m rule: engine\u001b[38;5;241m.\u001b[39mdeclare_relation_table(rule\u001b[38;5;241m.\u001b[39mhead_relation\u001b[38;5;241m.\u001b[39mas_relation_declaration()),\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelation_declaration\u001b[39m\u001b[38;5;124m'\u001b[39m: engine\u001b[38;5;241m.\u001b[39mdeclare_relation_table,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m: run_query\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_type \u001b[38;5;129;01min\u001b[39;00m node_type_to_action:\n\u001b[0;32m---> 38\u001b[0m     action_result \u001b[38;5;241m=\u001b[39m \u001b[43mnode_type_to_action\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_input_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_type \u001b[38;5;241m==\u001b[39m ParseNodeType\u001b[38;5;241m.\u001b[39mQUERY:\n\u001b[1;32m     41\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m action_result\n",
      "Cell \u001b[0;32mIn[61], line 26\u001b[0m, in \u001b[0;36mrun_commands.<locals>.run_query\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_query\u001b[39m(q):\n\u001b[0;32m---> 26\u001b[0m     query_plan \u001b[38;5;241m=\u001b[39m \u001b[43mplan_query\u001b[49m(q,term_graph,engine)\n\u001b[1;32m     27\u001b[0m     result \u001b[38;5;241m=\u001b[39m partial_fixed_point_execution(query_plan,engine)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plan_query' is not defined"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new Parent(str, str)\n",
    "    Parent(\"Sam\", \"Noah\")\n",
    "    Parent(\"Noah\", \"Austin\")\n",
    "    Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "    GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
    "    #?GrandParent(X, \"Austin\")\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "_ = session.run_commands(commands)\n",
    "session.run_commands('?GrandParent(X, \"Austin\")')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'query'), [GrandParent(X, \"Austin\")])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X\n",
       "0  Sam"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = session.export(query='?GrandParent(X, \"Austin\")')\n",
    "assert output.to_dict(orient='records') == [{'X': 'Sam'}]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'query'), [GrandParent(COL0, COL1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COL0</th>\n",
       "      <th>COL1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noah</td>\n",
       "      <td>Stephen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COL0     COL1\n",
       "0   Sam   Austin\n",
       "1  Noah  Stephen"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = session.export(relation_name='GrandParent')\n",
    "assert output.to_dict(orient='records') == [{'COL0': 'Sam', 'COL1': 'Austin'}, {'COL0': 'Noah', 'COL1': 'Stephen'}]\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'relation_declaration'), [string(str)])\n",
      "Tree(Token('RULE', 'add_fact'), [string(\"a\")])\n",
      "Tree(Token('RULE', 'add_fact'), [string(\"d\")])\n",
      "Tree(Token('RULE', 'add_fact'), [string(\"a\")])\n",
      "Tree(Token('RULE', 'add_fact'), [string(\"ab\")])\n",
      "Tree(Token('RULE', 'add_fact'), [string(\"abc\")])\n",
      "Tree(Token('RULE', 'add_fact'), [string(\"abcd\")])\n",
      "Tree(Token('RULE', 'rule'), [string_length(Str, Len) <- string(Str), Length(Str) -> (Len)])\n",
      "Tree(Token('RULE', 'query'), [string_length(Str, Len)])\n",
      "printing results for query 'string_length(Str, Len)':\n",
      "  Str  |   Len\n",
      "-------+-------\n",
      "   a   |     1\n",
      "   d   |     1\n",
      "  ab   |     2\n",
      "  abc  |     3\n",
      " abcd  |     4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def length(string: str) -> Iterable[int]:\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield len(string)\n",
    "\n",
    "length_dict = dict(ie_function=length,\n",
    "                ie_function_name='Length',\n",
    "                in_rel=[DataTypes.string],\n",
    "                out_rel=[DataTypes.integer])\n",
    "\n",
    "session = Session()\n",
    "session.register(**length_dict)\n",
    "commands = \"\"\"new string(str)\n",
    "            string(\"a\")\n",
    "            string(\"d\")\n",
    "            string(\"a\")\n",
    "            string(\"ab\")\n",
    "            string(\"abc\")\n",
    "            string(\"abcd\")\n",
    "\n",
    "            string_length(Str, Len) <- string(Str), Length(Str) -> (Len)\n",
    "            ?string_length(Str, Len)\n",
    "            \"\"\"\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_rule(self: Session, rule: str # The rule to be removed\n",
    "                ) -> None:\n",
    "    \"\"\"\n",
    "    Remove a rule from the spannerlog's engine.\n",
    "    \"\"\"\n",
    "    is_last = self._term_graph.remove_rule(rule)\n",
    "    if is_last:\n",
    "        relation_name = rule_to_relation_name(rule)\n",
    "        self._remove_rule_relation_from_symbols_and_engine(relation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_rule\n",
       "\n",
       ">      Session.remove_rule (rule:str)\n",
       "\n",
       "Remove a rule from the spannerlog's engine.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| rule | str | The rule to be removed |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_rule\n",
       "\n",
       ">      Session.remove_rule (rule:str)\n",
       "\n",
       "Remove a rule from the spannerlog's engine.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| rule | str | The rule to be removed |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'relation_declaration'), [parent(str, str)])\n",
      "Tree(Token('RULE', 'relation_declaration'), [grandparent(str, str)])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"Liam\", \"Noah\")])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"Noah\", \"Oliver\")])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"James\", \"Lucas\")])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"Noah\", \"Benjamin\")])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"Benjamin\", \"Mason\")])\n",
      "Tree(Token('RULE', 'add_fact'), [grandparent(\"Tom\", \"Avi\")])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- parent(X, Y)])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- grandparent(X, Y)])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)])\n",
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- parent(X, Y)\n",
      "\t2. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t3. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    parent(\"Noah\", \"Oliver\")\n",
    "    parent(\"James\", \"Lucas\")\n",
    "    parent(\"Noah\", \"Benjamin\")\n",
    "    parent(\"Benjamin\", \"Mason\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing first rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t2. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "session.remove_rule(\"ancestor(X, Y) <- parent(X, Y)\")\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_all_rules(self: Session, rule_head: Optional[str] = None # if rule head is not none we remove all rules with rule_head\n",
    "                        ) -> None:\n",
    "    \"\"\"\n",
    "    Removes all rules from the engine.\n",
    "    \"\"\"\n",
    "\n",
    "    if rule_head is None:\n",
    "        self._term_graph = TermGraph()\n",
    "        relations_names = self._symbol_table.remove_all_rule_relations()\n",
    "        self._engine.remove_tables(relations_names)\n",
    "    else:\n",
    "        self._term_graph.remove_rules_with_head(rule_head)\n",
    "        self._remove_rule_relation_from_symbols_and_engine(rule_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_all_rules\n",
       "\n",
       ">      Session.remove_all_rules (rule_head:Union[str,NoneType]=None)\n",
       "\n",
       "Removes all rules from the engine.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| rule_head | Optional[str] | None | if rule head is not none we remove all rules with rule_head |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_all_rules\n",
       "\n",
       ">      Session.remove_all_rules (rule_head:Union[str,NoneType]=None)\n",
       "\n",
       "Removes all rules from the engine.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| rule_head | Optional[str] | None | if rule head is not none we remove all rules with rule_head |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_all_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'relation_declaration'), [parent(str, str)])\n",
      "Tree(Token('RULE', 'relation_declaration'), [grandparent(str, str)])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"Liam\", \"Noah\")])\n",
      "Tree(Token('RULE', 'add_fact'), [grandparent(\"Tom\", \"Avi\")])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- parent(X, Y)])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- grandparent(X, Y)])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)])\n",
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- parent(X, Y)\n",
      "\t2. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t3. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    grandparent(\"Tom\", \"Avi\")\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after removing all rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the rules:\n"
     ]
    }
   ],
   "source": [
    "session.remove_all_rules()\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def clear_relation(self: Session, relation_name: str # The name of the relation to clear\n",
    "                    ) -> None:\n",
    "    # @raises: Exception if relation does not exist\n",
    "    if not self._engine.is_table_exists(relation_name):\n",
    "        raise Exception(f\"Relation {relation_name} does not exist\")\n",
    "\n",
    "    self._engine.clear_relation(relation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.clear_relation\n",
       "\n",
       ">      Session.clear_relation (relation_name:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| relation_name | str | The name of the relation to clear |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.clear_relation\n",
       "\n",
       ">      Session.clear_relation (relation_name:str)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| relation_name | str | The name of the relation to clear |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.clear_relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'relation_declaration'), [parent(str, str)])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"Liam\", \"Noah\")])\n",
      "Tree(Token('RULE', 'add_fact'), [parent(\"Noah\", \"Oliver\")])\n",
      "Tree(Token('RULE', 'query'), [parent(X, Y)])\n",
      "printing results for query 'parent(X, Y)':\n",
      "  X   |   Y\n",
      "------+--------\n",
      " Liam |  Noah\n",
      " Noah | Oliver\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    parent(\"Liam\", \"Noah\")\n",
    "    parent(\"Noah\", \"Oliver\")\n",
    "    ?parent(X,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after clearing parent relation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'query'), [parent(X, Y)])\n",
      "printing results for query 'parent(X, Y)':\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session.clear_relation(\"parent\")\n",
    "commands = \"\"\"\n",
    "    ?parent(X,Y)\n",
    "    \"\"\"\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def send_commands_result_into_csv(self: Session, commands: str, # the commands to run\n",
    "                                    csv_file_name: Path, # the file into which the output will be written\n",
    "                                    delimiter: str = CSV_DELIMITER # a csv separator between values\n",
    "                                    ) -> None:\n",
    "    \"\"\"\n",
    "    run commands as usual and output their formatted results into a csv file (the commands should contain a query)\n",
    "    \"\"\"\n",
    "    commands_results = self.run_commands(commands, print_results=False)\n",
    "    if len(commands_results) != 1:\n",
    "        raise Exception(\"the commands must have exactly one output\")\n",
    "\n",
    "    formatted_result = format_query_results(*commands_results[0])\n",
    "\n",
    "    if isinstance(formatted_result, DataFrame):\n",
    "        formatted_result.to_csv(csv_file_name, index=False, sep=delimiter)\n",
    "    else:\n",
    "        # true or false\n",
    "        with open(csv_file_name, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f, delimiter=delimiter)\n",
    "            writer.writerows(formatted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.send_commands_result_into_csv\n",
       "\n",
       ">      Session.send_commands_result_into_csv (commands:str,\n",
       ">                                             csv_file_name:pathlib.Path,\n",
       ">                                             delimiter:str=';')\n",
       "\n",
       "run commands as usual and output their formatted results into a csv file (the commands should contain a query)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| commands | str |  | the commands to run |\n",
       "| csv_file_name | Path |  | the file into which the output will be written |\n",
       "| delimiter | str | ; | a csv separator between values |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.send_commands_result_into_csv\n",
       "\n",
       ">      Session.send_commands_result_into_csv (commands:str,\n",
       ">                                             csv_file_name:pathlib.Path,\n",
       ">                                             delimiter:str=';')\n",
       "\n",
       "run commands as usual and output their formatted results into a csv file (the commands should contain a query)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| commands | str |  | the commands to run |\n",
       "| csv_file_name | Path |  | the file into which the output will be written |\n",
       "| delimiter | str | ; | a csv separator between values |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.send_commands_result_into_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def print_registered_ie_functions(self: Session) -> None:\n",
    "    \"\"\"\n",
    "    Prints information about the registered ie functions.\n",
    "    \"\"\"\n",
    "    self._symbol_table.print_registered_ie_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.print_registered_ie_functions\n",
       "\n",
       ">      Session.print_registered_ie_functions ()\n",
       "\n",
       "Prints information about the registered ie functions."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.print_registered_ie_functions\n",
       "\n",
       ">      Session.print_registered_ie_functions ()\n",
       "\n",
       "Prints information about the registered ie functions."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.print_registered_ie_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_ie_function(self: Session, name: str # the name of the ie function to remove\n",
    "                        ) -> None:\n",
    "    \"\"\"\n",
    "    Removes a function from the symbol table.\n",
    "    \"\"\"\n",
    "    self._symbol_table.remove_ie_function(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_ie_function\n",
       "\n",
       ">      Session.remove_ie_function (name:str)\n",
       "\n",
       "Removes a function from the symbol table.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| name | str | the name of the ie function to remove |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_ie_function\n",
       "\n",
       ">      Session.remove_ie_function (name:str)\n",
       "\n",
       "Removes a function from the symbol table.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| name | str | the name of the ie function to remove |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_ie_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def remove_all_ie_functions(self: Session) -> None:\n",
    "    \"\"\"\n",
    "    Removes all the ie functions from the symbol table.\n",
    "    \"\"\"\n",
    "    self._symbol_table.remove_all_ie_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.remove_all_ie_functions\n",
       "\n",
       ">      Session.remove_all_ie_functions ()\n",
       "\n",
       "Removes all the ie functions from the symbol table."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.remove_all_ie_functions\n",
       "\n",
       ">      Session.remove_all_ie_functions ()\n",
       "\n",
       "Removes all the ie functions from the symbol table."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.remove_all_ie_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def print_all_rules(self: Session, head: Optional[str] = None # if specified it will print only rules with the given head relation name\n",
    "                    ) -> None:\n",
    "    \"\"\"\n",
    "    Prints all the rules that are registered.\n",
    "    \"\"\"\n",
    "\n",
    "    self._term_graph.print_all_rules(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.print_all_rules\n",
       "\n",
       ">      Session.print_all_rules (head:Union[str,NoneType]=None)\n",
       "\n",
       "Prints all the rules that are registered.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| head | Optional[str] | None | if specified it will print only rules with the given head relation name |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.print_all_rules\n",
       "\n",
       ">      Session.print_all_rules (head:Union[str,NoneType]=None)\n",
       "\n",
       "Prints all the rules that are registered.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| head | Optional[str] | None | if specified it will print only rules with the given head relation name |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.print_all_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'relation_declaration'), [parent(str, str)])\n",
      "Tree(Token('RULE', 'relation_declaration'), [grandparent(str, str)])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- parent(X, Y)])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- grandparent(X, Y)])\n",
      "Tree(Token('RULE', 'rule'), [ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)])\n",
      "Printing all the rules:\n",
      "\t1. ancestor(X, Y) <- parent(X, Y)\n",
      "\t2. ancestor(X, Y) <- grandparent(X, Y)\n",
      "\t3. ancestor(X, Y) <- parent(X, Z), ancestor(Z, Y)\n"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new parent(str, str)\n",
    "    new grandparent(str, str)\n",
    "    ancestor(X,Y) <- parent(X,Y)\n",
    "    ancestor(X,Y) <- grandparent(X,Y)\n",
    "    ancestor(X,Y) <- parent(X,Z), ancestor(Z,Y)\n",
    "    \"\"\"\n",
    "session = Session()\n",
    "output = session.run_commands(commands)\n",
    "session.print_all_rules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@patch_method\n",
    "def import_rel(self: Session, data: Union[DataFrame,Path], #Either a dataframe or a path to a csv file to import.\n",
    "                             relation_name: str = None, #The name of the relation. If not provided when importing a csv, it will be derived from the file name.\n",
    "                             delimiter: str = None #The delimiter used when parsing a csv file, defaults to ';'\n",
    "                             )-> None:\n",
    "    \"\"\"Imports a relation into the current session, either from a dataframe or from a csv file.\n",
    "    \"\"\"\n",
    "    global CSV_DELIMITER\n",
    "\n",
    "    if isinstance(data, DataFrame):\n",
    "        data_list = data.values.tolist()\n",
    "\n",
    "        if not isinstance(data_list, list):\n",
    "            raise Exception(\"dataframe could not be converted to list\")\n",
    "        if len(data_list) < 1:\n",
    "            raise Exception(\"dataframe is empty\")\n",
    "        if relation_name is None:\n",
    "            raise Exception(\"relation_name must be provided when importing a dataframe\")\n",
    "        relation_types = _infer_relation_type(data_list[0])\n",
    "        self._add_imported_relation_to_engine(data_list, relation_name, relation_types)\n",
    "\n",
    "\n",
    "    elif isinstance(data, (Path,str)):\n",
    "        csv_file_name = Path(data)\n",
    "        if not csv_file_name.is_file():\n",
    "            raise IOError(\"csv file does not exist\")\n",
    "        if os.stat(csv_file_name).st_size == 0:\n",
    "            raise IOError(\"csv file is empty\")\n",
    "        if relation_name is None:\n",
    "            relation_name = Path(csv_file_name).stem\n",
    "\n",
    "        if delimiter is None:\n",
    "            delimiter = CSV_DELIMITER\n",
    "\n",
    "        with open(csv_file_name) as fh:\n",
    "            reader = csv.reader(fh, delimiter=delimiter)\n",
    "\n",
    "            # read first line and go back to start of file - make sure there is no empty line!\n",
    "            relation_types = _infer_relation_type(next(reader))\n",
    "            fh.seek(0)\n",
    "\n",
    "            data_list = reader\n",
    "            self._add_imported_relation_to_engine(data_list, relation_name, relation_types)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Session.import_rel\n",
       "\n",
       ">      Session.import_rel (data:Union[pandas.core.frame.DataFrame,pathlib.Path],\n",
       ">                          relation_name:str=None, delimiter:str=None)\n",
       "\n",
       "Imports a relation into the current session, either from a dataframe or from a csv file.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | Union[DataFrame, Path] |  | Either a dataframe or a path to a csv file to import. |\n",
       "| relation_name | str | None | The name of the relation. If not provided when importing a csv, it will be derived from the file name. |\n",
       "| delimiter | str | None | The delimiter used when parsing a csv file, defaults to ';' |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Session.import_rel\n",
       "\n",
       ">      Session.import_rel (data:Union[pandas.core.frame.DataFrame,pathlib.Path],\n",
       ">                          relation_name:str=None, delimiter:str=None)\n",
       "\n",
       "Imports a relation into the current session, either from a dataframe or from a csv file.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | Union[DataFrame, Path] |  | Either a dataframe or a path to a csv file to import. |\n",
       "| relation_name | str | None | The name of the relation. If not provided when importing a csv, it will be derived from the file name. |\n",
       "| delimiter | str | None | The delimiter used when parsing a csv file, defaults to ';' |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Session.import_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'add_fact'), [enrolled(\"abigail\", \"chemistry\")])\n",
      "Tree(Token('RULE', 'assignment'), [gpa_str = \"abigail 100 jordan 80 gale 79 howard 60\"])\n",
      "Tree(Token('RULE', 'rule'), [gpa(Student, Grade) <- py_rgx_string(\"abigail 100 jordan 80 gale 79 howard 60\", \"(\\w+).*?(\\d+)\") -> (Student, Grade), enrolled(Student, X)])\n",
      "Tree(Token('RULE', 'query'), [gpa(X, Y)])\n",
      "printing results for query 'gpa(X, Y)':\n",
      "    X    |   Y\n",
      "---------+-----\n",
      " abigail | 100\n",
      " jordan  |  80\n",
      "  gale   |  79\n",
      " howard  |  60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "session.import_rel(\"./sample_data/enrolled.csv\", relation_name=\"enrolled\", delimiter=\",\")\n",
    "commands = \"\"\"\n",
    "    enrolled(\"abigail\", \"chemistry\")\n",
    "gpa_str = \"abigail 100 jordan 80 gale 79 howard 60\"\n",
    "\n",
    "gpa(Student,Grade) <- py_rgx_string(gpa_str, \"(\\w+).*?(\\d+)\")->(Student, Grade),enrolled(Student,X)\n",
    "\n",
    "?gpa(X,Y)\n",
    "\"\"\"\n",
    "x = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'query'), [lecturer(X, Y)])\n",
      "printing results for query 'lecturer(X, Y)':\n",
      "   X    |         Y\n",
      "--------+-------------------\n",
      " walter |     chemistry\n",
      " linus  | operating_systems\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "lecturer_df = DataFrame(([[\"walter\",\"chemistry\"], [\"linus\", \"operating_systems\"]]))\n",
    "session.import_rel(lecturer_df, relation_name=\"lecturer\")\n",
    "commands = \"\"\" \n",
    "?lecturer(X,Y)\n",
    "\"\"\"\n",
    "output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(lecturer(X, Y), [('walter', 'chemistry'), ('linus', 'operating_systems')])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with checkLogs():\n",
    "#TODO from here make logging work with dict logging like in llmcourse,\n",
    "# then make an example with an ie function so we see how the engines execute it\n",
    "\n",
    "# Then make a tests example with aggregation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'register'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_id2_z\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstring\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_id2_w\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m session \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m---> 18\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m(ID,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, [DataTypes\u001b[38;5;241m.\u001b[39mstring], [DataTypes\u001b[38;5;241m.\u001b[39mstring])\n\u001b[1;32m     19\u001b[0m session\u001b[38;5;241m.\u001b[39mregister(ID2,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID2\u001b[39m\u001b[38;5;124m'\u001b[39m, [DataTypes\u001b[38;5;241m.\u001b[39mstring], [DataTypes\u001b[38;5;241m.\u001b[39mstring,DataTypes\u001b[38;5;241m.\u001b[39mstring])\n\u001b[1;32m     21\u001b[0m _ \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrun_commands(commands)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'register'"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "        new A(str, str)\n",
    "        new B(str, str)\n",
    "        C(X, Y) <- A(X, Y)\n",
    "        D(X, Y, X) <- C(X, Y)\n",
    "        D(X, Y, Z) <- A(X, 1), B(X, Y), ID(X) -> (Y), ID2(Y)->(Z,W)  \n",
    "    \"\"\"\n",
    "\n",
    "def ID(string: str):\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield f'{string}_id'\n",
    "\n",
    "def ID2(string: str):\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield f'{string}_id2_z',f'{string}_id2_w'\n",
    "\n",
    "session = Session()\n",
    "session.register(ID,'ID', [DataTypes.string], [DataTypes.string])\n",
    "session.register(ID2,'ID2', [DataTypes.string], [DataTypes.string,DataTypes.string])\n",
    "\n",
    "_ = session.run_commands(commands)\n",
    "# p_graph,t_graph = session.run_commands('?GP(G, \"Austin\" , L)',ret_graphs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Session' object has no attribute 'register'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n\u001b[1;32m     17\u001b[0m session \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m---> 18\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m(length,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLen\u001b[39m\u001b[38;5;124m'\u001b[39m, [DataTypes\u001b[38;5;241m.\u001b[39mstring], [DataTypes\u001b[38;5;241m.\u001b[39minteger])\n\u001b[1;32m     20\u001b[0m _ \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrun_commands(commands)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# p_graph,t_graph = session.run_commands('?GP(G, \"Austin\" , L)',ret_graphs=True)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Session' object has no attribute 'register'"
     ]
    }
   ],
   "source": [
    "commands = \"\"\"\n",
    "    new Parent(str, str)\n",
    "    Parent(\"Sam\", \"Noah\")\n",
    "    Parent(\"Noah\", \"Austin\")\n",
    "    Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "    GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
    "\n",
    "    GP(G,C,L)<- GrandParent(G,C),Len(G)->(L)\n",
    "    GP(G,C,L)<- Parent(G,C),Len(G)->(L)\n",
    "    \"\"\"\n",
    "\n",
    "def length(string: str) -> Iterable[int]:\n",
    "        # here we append the input to the output inside the ie function!\n",
    "        yield len(string)\n",
    "\n",
    "session = Session()\n",
    "session.register(length,'Len', [DataTypes.string], [DataTypes.integer])\n",
    "\n",
    "_ = session.run_commands(commands)\n",
    "# p_graph,t_graph = session.run_commands('?GP(G, \"Austin\" , L)',ret_graphs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "  relation_declaration\n",
      "    relation_name\tParent\n",
      "    decl_term_list\n",
      "      decl_string\n",
      "      decl_string\n",
      "  add_fact\n",
      "    relation_name\tParent\n",
      "    const_term_list\n",
      "      string\t\"Sam\"\n",
      "      string\t\"Noah\"\n",
      "  add_fact\n",
      "    relation_name\tParent\n",
      "    const_term_list\n",
      "      string\t\"Noah\"\n",
      "      string\t\"Austin\"\n",
      "  add_fact\n",
      "    relation_name\tParent\n",
      "    const_term_list\n",
      "      string\t\"Austin\"\n",
      "      string\t\"Stephen\"\n",
      "  rule\n",
      "    rule_head\n",
      "      relation_name\tGrandParent\n",
      "      free_var_name_list\n",
      "        free_var_name\tG\n",
      "        free_var_name\tC\n",
      "    rule_body_relation_list\n",
      "      relation\n",
      "        relation_name\tParent\n",
      "        term_list\n",
      "          free_var_name\tG\n",
      "          free_var_name\tM\n",
      "      relation\n",
      "        relation_name\tParent\n",
      "        term_list\n",
      "          free_var_name\tM\n",
      "          free_var_name\tC\n",
      "  rule\n",
      "    rule_head\n",
      "      relation_name\tGP\n",
      "      free_var_name_list\n",
      "        free_var_name\tG\n",
      "        free_var_name\tC\n",
      "        free_var_name\tL\n",
      "    rule_body_relation_list\n",
      "      relation\n",
      "        relation_name\tGrandParent\n",
      "        term_list\n",
      "          free_var_name\tG\n",
      "          free_var_name\tC\n",
      "      ie_relation\n",
      "        relation_name\tLen\n",
      "        term_list\n",
      "          free_var_name\tG\n",
      "        term_list\n",
      "          free_var_name\tL\n",
      "  rule\n",
      "    rule_head\n",
      "      relation_name\tGP\n",
      "      free_var_name_list\n",
      "        free_var_name\tG\n",
      "        free_var_name\tC\n",
      "        free_var_name\tL\n",
      "    rule_body_relation_list\n",
      "      relation\n",
      "        relation_name\tParent\n",
      "        term_list\n",
      "          free_var_name\tG\n",
      "          free_var_name\tC\n",
      "      ie_relation\n",
      "        relation_name\tLen\n",
      "        term_list\n",
      "          free_var_name\tG\n",
      "        term_list\n",
      "          free_var_name\tL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = Session()\n",
    "session.register(length,'Len', [DataTypes.string], [DataTypes.integer])\n",
    "\n",
    "parse_tree = parse_spannerlog(\"\"\"\n",
    "    new Parent(str, str)\n",
    "    Parent(\"Sam\", \"Noah\")\n",
    "    Parent(\"Noah\", \"Austin\")\n",
    "    Parent(\"Austin\", \"Stephen\")\n",
    "\n",
    "    GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
    "\n",
    "    GP(G,C,L)<- GrandParent(G,C),Len(G)->(L)\n",
    "    GP(G,C,L)<- Parent(G,C),Len(G)->(L)\n",
    "    \"\"\")\n",
    "print(parse_tree.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree(Token('RULE', 'relation_declaration'), [Parent(str, str)]),\n",
       " Tree(Token('RULE', 'add_fact'), [Parent(\"Sam\", \"Noah\")]),\n",
       " Tree(Token('RULE', 'add_fact'), [Parent(\"Noah\", \"Austin\")]),\n",
       " Tree(Token('RULE', 'add_fact'), [Parent(\"Austin\", \"Stephen\")]),\n",
       " Tree(Token('RULE', 'rule'), [GrandParent(G, C) <- Parent(G, M), Parent(M, C)]),\n",
       " Tree(Token('RULE', 'rule'), [GP(G, C, L) <- GrandParent(G, C), Len(G) -> (L)]),\n",
       " Tree(Token('RULE', 'rule'), [GP(G, C, L) <- Parent(G, C), Len(G) -> (L)])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_statements = [\n",
    "    session._run_passes(s, session.get_pass_stack()) for s in parse_tree.children\n",
    "]\n",
    "new_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RULE'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_statements[0].data.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parent(str, str)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_statements[0].children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO from here take out the type of action and the type itself and put it in the execution loop in run commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(__spannerlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Parent(str, str)\n",
      "    (1) (computed) add_fact: Parent(\"Sam\", \"Noah\")\n",
      "    (2) (computed) add_fact: Parent(\"Noah\", \"Austin\")\n",
      "    (3) (computed) add_fact: Parent(\"Austin\", \"Stephen\")\n",
      "    (4) (computed) rule: GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
      "    (5) (computed) rule: GP(G, C, L) <- GrandParent(G, C), Len(G) -> (L)\n",
      "    (6) (computed) rule: GP(G, C, L) <- Parent(G, C), Len(G) -> (L)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(session._parse_graph.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session._engine.declare_relation_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spannerlog_engine.declare_relation_table(rule.head_relation.as_relation_declaration())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.export('?GP(G, C , L)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(__spannerlog_root) (computed) root\n",
      "    (0) (computed) relation_declaration: Parent(str, str)\n",
      "    (1) (computed) add_fact: Parent(\"Sam\", \"Noah\")\n",
      "    (2) (computed) add_fact: Parent(\"Noah\", \"Austin\")\n",
      "    (3) (computed) add_fact: Parent(\"Austin\", \"Stephen\")\n",
      "    (4) (computed) rule: GrandParent(G, C) <- Parent(G, M), Parent(M, C)\n",
      "    (5) (computed) rule: GP(G, C, L) <- GrandParent(G, C), Len(G) -> (L)\n",
      "    (6) (computed) rule: GP(G, C, L) <- Parent(G, C), Len(G) -> (L)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(session._parse_graph.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__spannerlog_root',\n",
       "  {'type': 'root', 'state': <EvalState.COMPUTED: 'computed'>}),\n",
       " (0,\n",
       "  {'type': <ParseNodeType.RELATION_DECLARATION: 'relation_declaration'>,\n",
       "   'value': Parent(str, str),\n",
       "   'state': <EvalState.COMPUTED: 'computed'>}),\n",
       " (1,\n",
       "  {'type': <ParseNodeType.ADD_FACT: 'add_fact'>,\n",
       "   'value': Parent(\"Sam\", \"Noah\"),\n",
       "   'state': <EvalState.COMPUTED: 'computed'>}),\n",
       " (2,\n",
       "  {'type': <ParseNodeType.ADD_FACT: 'add_fact'>,\n",
       "   'value': Parent(\"Noah\", \"Austin\"),\n",
       "   'state': <EvalState.COMPUTED: 'computed'>}),\n",
       " (3,\n",
       "  {'type': <ParseNodeType.ADD_FACT: 'add_fact'>,\n",
       "   'value': Parent(\"Austin\", \"Stephen\"),\n",
       "   'state': <EvalState.COMPUTED: 'computed'>}),\n",
       " (4,\n",
       "  {'type': <ParseNodeType.RULE: 'rule'>,\n",
       "   'value': GrandParent(G, C) <- Parent(G, M), Parent(M, C),\n",
       "   'state': <EvalState.COMPUTED: 'computed'>}),\n",
       " (5,\n",
       "  {'type': <ParseNodeType.RULE: 'rule'>,\n",
       "   'value': GP(G, C, L) <- GrandParent(G, C), Len(G) -> (L),\n",
       "   'state': <EvalState.COMPUTED: 'computed'>}),\n",
       " (6,\n",
       "  {'type': <ParseNodeType.RULE: 'rule'>,\n",
       "   'value': GP(G, C, L) <- Parent(G, C), Len(G) -> (L),\n",
       "   'state': <EvalState.COMPUTED: 'computed'>})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(session._parse_graph._graph.nodes(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__spannerlog_root', 0, {}),\n",
       " ('__spannerlog_root', 1, {}),\n",
       " ('__spannerlog_root', 2, {}),\n",
       " ('__spannerlog_root', 3, {}),\n",
       " ('__spannerlog_root', 4, {}),\n",
       " ('__spannerlog_root', 5, {}),\n",
       " ('__spannerlog_root', 6, {})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(session._parse_graph._graph.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(__spannerlog_root) (not_computed) root\n",
      "    (GrandParent) (not_computed) rule_rel: GrandParent(G, C)\n",
      "        (0) (not_computed) union\n",
      "            (1) (not_computed) project: ['G', 'C']\n",
      "                (2) (not_computed) join: {'C': [(Parent(M, C), 1)], 'M': [(Parent(M, C), 0), (Parent(G, M), 1)], 'G': [(Parent(G, M), 0)]}\n",
      "                    (3) (not_computed) get_rel: Parent(M, C)\n",
      "                    (4) (not_computed) get_rel: Parent(G, M)\n",
      "    (GP) (not_computed) rule_rel: GP(G, C, L)\n",
      "        (5) (not_computed) union\n",
      "            (6) (not_computed) project: ['G', 'C', 'L']\n",
      "                (7) (not_computed) join: {'C': [(GrandParent(G, C), 1)], 'L': [(Len(G) -> (L), 1)], 'G': [(Len(G) -> (L), 0), (GrandParent(G, C), 0)]}\n",
      "                    (8) (not_computed) get_rel: GrandParent(G, C)\n",
      "                        (GrandParent) (not_computed) rule_rel: GrandParent(G, C)\n",
      "                    (9) (not_computed) calc: Len(G) -> (L)\n",
      "                        (8) (not_computed) get_rel: GrandParent(G, C)\n",
      "            (10) (not_computed) project: ['G', 'C', 'L']\n",
      "                (11) (not_computed) join: {'C': [(Parent(G, C), 1)], 'L': [(Len(G) -> (L), 1)], 'G': [(Len(G) -> (L), 0), (Parent(G, C), 0)]}\n",
      "                    (12) (not_computed) get_rel: Parent(G, C)\n",
      "                    (13) (not_computed) calc: Len(G) -> (L)\n",
      "                        (12) (not_computed) get_rel: Parent(G, C)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(t_graph.pretty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spannerlib.adding_inference_rules_to_term_graph - DEBUG - term graph after AddRulesToTermGraph:\n",
      "(__spannerlog_root) (not_computed) root\n",
      "    (GrandParent) (not_computed) rule_rel: GrandParent(G, C)\n",
      "        (0) (not_computed) union\n",
      "            (1) (not_computed) project: ['G', 'C']\n",
      "                (2) (not_computed) join: {'C': [(Parent(M, C), 1)], 'M': [(Parent(M, C), 0), (Parent(G, M), 1)], 'G': [(Parent(G, M), 0)]}\n",
      "                    (3) (not_computed) get_rel: Parent(M, C)\n",
      "                    (4) (not_computed) get_rel: Parent(G, M)\n",
      "    (GP) (not_computed) rule_rel: GP(G, C, L)\n",
      "        (5) (not_computed) union\n",
      "            (6) (not_computed) project: ['G', 'C', 'L']\n",
      "                (7) (not_computed) join: {'C': [(GrandParent(G, C), 1)], 'L': [(Len(G) -> (L), 1)], 'G': [(Len(G) -> (L), 0), (GrandParent(G, C), 0)]}\n",
      "                    (8) (not_computed) get_rel: GrandParent(G, C)\n",
      "                        (GrandParent) (not_computed) rule_rel: GrandParent(G, C)\n",
      "                    (9) (not_computed) calc: Len(G) -> (L)\n",
      "                        (8) (not_computed) get_rel: GrandParent(G, C)\n",
      "            (10) (not_computed) project: ['G', 'C', 'L']\n",
      "                (11) (not_computed) join: {'C': [(Parent(G, C), 1)], 'L': [(Len(G) -> (L), 1)], 'G': [(Len(G) -> (L), 0), (Parent(G, C), 0)]}\n",
      "                    (12) (not_computed) get_rel: Parent(G, C)\n",
      "                    (13) (not_computed) calc: Len(G) -> (L)\n",
      "                        (12) (not_computed) get_rel: Parent(G, C)\n",
      "\n",
      "DependencyGraph is:\n",
      "__spannerlog_root\n",
      "    GrandParent\n",
      "    GP\n",
      "        GrandParent\n",
      "\n",
      "spannerlib.engine - DEBUG - sql DELETE FROM GP\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GP\n",
      "spannerlib.engine - DEBUG - sql DELETE FROM GrandParent\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GrandParent\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__join30'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__join30 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__join30 SELECT DISTINCT\n",
      "\n",
      "table0.col1 AS col0\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "table0.col0 AS col1\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "table1.col0 AS col2\n",
      "\n",
      "\n",
      "FROM Parent AS table0\n",
      "\n",
      "INNER JOIN Parent AS table1\n",
      "\n",
      "ON\n",
      "\n",
      "table0.col0=table1.col1\n",
      "\n",
      "\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__join30_project31'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__join30_project31 (col0, col1)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__join30_project31 SELECT DISTINCT col2 AS col0, col0 AS col1 FROM __spannerlog__join30\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='GrandParent'\n",
      "spannerlib.engine - DEBUG - sql DELETE FROM GrandParent\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO GrandParent SELECT DISTINCT * FROM __spannerlog__join30_project31\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GrandParent\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GrandParent\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GrandParent\n",
      "spannerlib.engine - DEBUG - Computing IE relation Len based on bounding relation GrandParent(G, C)\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__Len_output32'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__Len_output32 (col0, col1)\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GrandParent_select33'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__GrandParent_select33 (col0, col1)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__GrandParent_select33 SELECT DISTINCT * FROM GrandParent\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GrandParent_select33_project34'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__GrandParent_select33_project34 (col0, col1)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__GrandParent_select33_project34 SELECT DISTINCT col0, col1 FROM __spannerlog__GrandParent_select33\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT * FROM __spannerlog__GrandParent_select33_project34\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GrandParent_select33'\n",
      "spannerlib.engine - DEBUG - sql DROP TABLE __spannerlog__GrandParent_select33\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GrandParent_select33_project34'\n",
      "spannerlib.engine - DEBUG - sql DROP TABLE __spannerlog__GrandParent_select33_project34\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__Len_output32 (col0, col1)\n",
      "VALUES (\"Sam\", 3)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__Len_output32 (col0, col1)\n",
      "VALUES (\"Noah\", 4)\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__join35'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__join35 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__join35 SELECT DISTINCT\n",
      "\n",
      "table0.col1 AS col0\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "table1.col1 AS col1\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "table0.col0 AS col2\n",
      "\n",
      "\n",
      "FROM GrandParent AS table0\n",
      "\n",
      "INNER JOIN __spannerlog__Len_output32 AS table1\n",
      "\n",
      "ON\n",
      "\n",
      "table0.col0=table1.col0\n",
      "\n",
      "\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__join35_project36'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__join35_project36 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__join35_project36 SELECT DISTINCT col2 AS col0, col0 AS col1, col1 AS col2 FROM __spannerlog__join35\n",
      "spannerlib.engine - DEBUG - Computing IE relation Len based on bounding relation Parent(G, C)\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__Len_output37'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__Len_output37 (col0, col1)\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__Parent_select38'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__Parent_select38 (col0, col1)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__Parent_select38 SELECT DISTINCT * FROM Parent\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__Parent_select38_project39'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__Parent_select38_project39 (col0, col1)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__Parent_select38_project39 SELECT DISTINCT col0, col1 FROM __spannerlog__Parent_select38\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT * FROM __spannerlog__Parent_select38_project39\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__Parent_select38'\n",
      "spannerlib.engine - DEBUG - sql DROP TABLE __spannerlog__Parent_select38\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__Parent_select38_project39'\n",
      "spannerlib.engine - DEBUG - sql DROP TABLE __spannerlog__Parent_select38_project39\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__Len_output37 (col0, col1)\n",
      "VALUES (\"Sam\", 3)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__Len_output37 (col0, col1)\n",
      "VALUES (\"Noah\", 4)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__Len_output37 (col0, col1)\n",
      "VALUES (\"Austin\", 6)\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__join40'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__join40 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__join40 SELECT DISTINCT\n",
      "\n",
      "table0.col1 AS col0\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "table1.col1 AS col1\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "table1.col0 AS col2\n",
      "\n",
      "\n",
      "FROM Parent AS table0\n",
      "\n",
      "INNER JOIN __spannerlog__Len_output37 AS table1\n",
      "\n",
      "ON\n",
      "\n",
      "table1.col0=table0.col0\n",
      "\n",
      "\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__join40_project41'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__join40_project41 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__join40_project41 SELECT DISTINCT col2 AS col0, col0 AS col1, col1 AS col2 FROM __spannerlog__join40\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__union42'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__union42 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__union42 SELECT DISTINCT col0, col1, col2 FROM __spannerlog__join35_project36 UNION SELECT DISTINCT col0, col1, col2 FROM __spannerlog__join40_project41\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='GP'\n",
      "spannerlib.engine - DEBUG - sql DELETE FROM GP\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO GP SELECT DISTINCT * FROM __spannerlog__union42\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GP\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GP\n",
      "spannerlib.engine - DEBUG - sql SELECT COUNT(*) FROM GP\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GP_select43'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__GP_select43 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__GP_select43 SELECT DISTINCT * FROM GP\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GP_select43_project44'\n",
      "spannerlib.engine - DEBUG - sql CREATE TABLE __spannerlog__GP_select43_project44 (col0, col1, col2)\n",
      "spannerlib.engine - DEBUG - sql INSERT INTO __spannerlog__GP_select43_project44 SELECT DISTINCT col0, col1, col2 FROM __spannerlog__GP_select43\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT * FROM __spannerlog__GP_select43_project44\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GP_select43'\n",
      "spannerlib.engine - DEBUG - sql DROP TABLE __spannerlog__GP_select43\n",
      "spannerlib.engine - DEBUG - sql SELECT DISTINCT name FROM sqlite_master WHERE type='table' AND name='__spannerlog__GP_select43_project44'\n",
      "spannerlib.engine - DEBUG - sql DROP TABLE __spannerlog__GP_select43_project44\n"
     ]
    }
   ],
   "source": [
    "with checkLogs():\n",
    "    session.export('?GP(G, C , L)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# #| hide\n",
    "# @patch_method\n",
    "# def import_relation_from_csv(self: Session, csv_file_name: Path, #The path to the CSV file that is being imported\n",
    "#                              relation_name: str = None, #The name of the relation. If not provided, it will be derived from the CSV file name\n",
    "#                              delimiter: str = CSV_DELIMITER #The delimiter used in the CSV file\n",
    "#                              )-> None: \n",
    "#     if not Path(csv_file_name).is_file():\n",
    "#         raise IOError(\"csv file does not exist\")\n",
    "\n",
    "#     if os.stat(csv_file_name).st_size == 0:\n",
    "#         raise IOError(\"csv file is empty\")\n",
    "\n",
    "#     # the relation_name is either an argument or the file's name\n",
    "#     if relation_name is None:\n",
    "#         relation_name = Path(csv_file_name).stem\n",
    "\n",
    "#     with open(csv_file_name) as fh:\n",
    "#         reader = csv.reader(fh, delimiter=delimiter)\n",
    "\n",
    "#         # read first line and go back to start of file - make sure there is no empty line!\n",
    "#         relation_types = _infer_relation_type(next(reader))\n",
    "#         fh.seek(0)\n",
    "\n",
    "#         self._add_imported_relation_to_engine(reader, relation_name, relation_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(Session.import_relation_from_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = Session()\n",
    "# session.import_relation_from_csv(\"./sample_data/enrolled.csv\", relation_name=\"enrolled\", delimiter=\",\")\n",
    "# commands = \"\"\"\n",
    "#     enrolled(\"abigail\", \"chemistry\")\n",
    "# gpa_str = \"abigail 100 jordan 80 gale 79 howard 60\"\n",
    "\n",
    "# gpa(Student,Grade) <- py_rgx_string(gpa_str, \"(\\w+).*?(\\d+)\")->(Student, Grade),enrolled(Student,X)\n",
    "\n",
    "# ?gpa(X,Y)\n",
    "# \"\"\"\n",
    "# x = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# #| hide\n",
    "# @patch_method\n",
    "# def import_relation_from_df(self: Session, relation_df: DataFrame, #The DataFrame containing the data to be imported\n",
    "#                             relation_name: str #The name to be assigned to the relation. It can be an existing relation or a new one\n",
    "#                             ) -> None:\n",
    "#     data = relation_df.values.tolist()\n",
    "\n",
    "#     if not isinstance(data, list):\n",
    "#         raise Exception(\"dataframe could not be converted to list\")\n",
    "\n",
    "#     if len(data) < 1:\n",
    "#         raise Exception(\"dataframe is empty\")\n",
    "\n",
    "#     relation_types = _infer_relation_type(data[0])\n",
    "\n",
    "#     self._add_imported_relation_to_engine(data, relation_name, relation_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(Session.import_relation_from_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.callout-note collapse=\"true\"}\n",
    "\n",
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = Session()\n",
    "# lecturer_df = DataFrame(([[\"walter\",\"chemistry\"], [\"linus\", \"operating_systems\"]]))\n",
    "# session.import_relation_from_df(lecturer_df, relation_name=\"lecturer\")\n",
    "# commands = \"\"\" \n",
    "# ?lecturer(X,Y)\n",
    "# \"\"\"\n",
    "# output = session.run_commands(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing results for query 'parent(X, Y)':\n",
      "    X    |    Y\n",
      "---------+---------\n",
      "  Jack   |  Alex\n",
      " Michael | Jackson\n",
      "   Van   | Diesel\n",
      "\n",
      "printing results for query 'parent(X, Y)':\n",
      "[]\n",
      "\n",
      "printing results for query 'parent(X, Y)':\n",
      "  X   |  Y\n",
      "------+------\n",
      " John | Cena\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "if __name__ == \"__main__\":\n",
    "    my_session = Session()\n",
    "    my_session.run_commands(\"\"\"\n",
    "                        new parent(str,str)\n",
    "                        parent(\"Jack\", \"Alex\")\n",
    "                        parent(\"Michael\", \"Jackson\")\n",
    "                        parent(\"Van\", \"Diesel\")\n",
    "                        ?parent(X,Y)\n",
    "            \"\"\")\n",
    "    my_session.clear_relation(\"parent\")\n",
    "    output = my_session.run_commands(\"\"\"\n",
    "                # Expect to see empty relation\n",
    "                ?parent(X,Y)\n",
    "            \"\"\")\n",
    "    assert str(output) == \"[(parent(X, Y), [])]\"\n",
    "    output = my_session.run_commands(\"\"\"\n",
    "                        # Check smooth refilling\n",
    "                        parent(\"John\", \"Cena\")\n",
    "                        ?parent(X,Y)\n",
    "                    \"\"\")\n",
    "    assert str(output) == \"[(parent(X, Y), [('John', 'Cena')])]\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
