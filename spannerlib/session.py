# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/030_session.ipynb.

# %% auto 0
__all__ = ['logger', 'load_stdlib', 'Session', 'test_session']

# %% ../nbs/030_session.ipynb 3
import csv

import os
import re
from pathlib import Path
from typing import Tuple, List, Union, Optional, Callable, Type, Iterable, no_type_check, Sequence
from IPython import display

import pandas as pd
import os

import logging
logger = logging.getLogger(__name__)

from graph_rewrite import draw

from .utils import checkLogs,get_base_file_path,assert_df_equals
from .grammar import parse_spannerlog,reconstruct
from .span import Span
from spannerlib.data_types import (
    _infer_relation_schema,
     Var,
    FreeVar,
    RelationDefinition,
    Relation,
    IEFunction,
    AGGFunction,
    IERelation,
    Rule,
    pretty,
)
from .engine import Engine

from spannerlib.micro_passes import (
    convert_primitive_values_to_objects,
    CheckReservedRelationNames,
    dereference_vars,
    check_referenced_paths_exist,
    inline_aggregation,
    relations_to_dataclasses,
    verify_referenced_relations_and_functions,
    rules_to_dataclasses,
    check_rule_safety,
    consistent_free_var_types_in_rule,
    assignments_to_name_val_tuple,
    execute_statement,
)


# %% ../nbs/030_session.ipynb 4
def load_stdlib():
    from spannerlib.ie_func.json_path import JsonPath, JsonPathFull
    from spannerlib.ie_func.nlp import (Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment, TrueCase)
    from spannerlib.ie_func.python_regex import PYRGX,AS_STRING
    from spannerlib.ie_func.rust_spanner_regex import RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE


    # # ordered by rgx, json, nlp, etc.
    ies = [AS_STRING,PYRGX, RGX, RGX_STRING, RGX_FROM_FILE, RGX_STRING_FROM_FILE,
                            JsonPath, JsonPathFull,
                            Tokenize, SSplit, POS, Lemma, NER, EntityMentions, CleanXML, Parse, DepParse, Coref, OpenIE, KBP, Quote, Sentiment,
                            TrueCase]

    aggs = [
        ['count','count',[str],[int]],
        ['sum','sum',[int],[int]],
        ['avg','avg',[int],[int]],
        ['max','max',[int],[int]],
        ['min','min',[int],[int]],
    ]

    return ies, aggs

# %% ../nbs/030_session.ipynb 6
class Session():
    def __init__(self,register_stdlib=True):
        
        self.pass_stack = [
            convert_primitive_values_to_objects,
            CheckReservedRelationNames('spanner_'),
            check_referenced_paths_exist,
            dereference_vars,
            inline_aggregation,
            relations_to_dataclasses,
            verify_referenced_relations_and_functions,
            rules_to_dataclasses,
            check_rule_safety,
            consistent_free_var_types_in_rule,
            assignments_to_name_val_tuple,
        ]

        self.clear(register_stdlib=register_stdlib)

    def clear(self,register_stdlib=True):
        self.engine = Engine()
        if not register_stdlib:
            return
        ies, aggs = load_stdlib()
        for ie_def in ies:
            self.register(*ie_def)
        for agg_def in aggs:
            self.register_agg(*agg_def)
    
    def register(self,name,func,in_schema,out_schema):
        ie_func_obj = IEFunction(name=name,func=func,in_schema=in_schema,out_schema=out_schema)
        self.engine.set_ie_function(ie_func_obj)

    def register_agg(self,name,func,in_schema,out_schema):
        agg_func_obj = AGGFunction(name=name,func=func,in_schema=in_schema,out_schema=out_schema)
        self.engine.set_agg_function(agg_func_obj)


    def _display_result(self,result,statement_lark):
        if result is None:
            pass
        elif isinstance(result,pd.DataFrame):
            display.display(reconstruct(statement_lark))
            display.display(result.map(repr))
        elif isinstance(result,bool):
            display.display(reconstruct(statement_lark))
            display.display(result)
        else:
            pass
    


    def parse_and_check_semantics(self,code):
        statements = parse_spannerlog(code,split_statements=True)
        asts = []
        for statement_nx,statement_lark in statements:
            ast = statement_nx
            for pass_ in self.pass_stack:
                try:
                    pass_(ast,self.engine)
                except Exception as e:
                    raise Exception(
                        f"During semantic checks for statement \n\"{reconstruct(statement_lark)}\"\n"
                        f"in pass {pass_} the following exception was raised:\n{e}\n"
                        ).with_traceback(e.__traceback__)
            yield ast,statement_lark

    def handle_boolean_results(self,res):
        if not isinstance(res,pd.DataFrame):
            return res
        if res.shape == (1,0):
            return True
        elif res.shape == (0,0):
            return False
        else:
            return res

    def plan_query(self,code):
        statements = list(self.parse_and_check_semantics(code))
        if len(statements) > 1:
            raise ValueError(f"Only one statement is allowed in plan_query, got {len(statements)}")
        ast,_ = statements[0]
        statement_node = list(ast.nodes)[0]
        node_data = ast.nodes[statement_node]
        statement = node_data['type']
        value = node_data['val']
        if statement != 'query':
            raise ValueError(f"Expected a query statement, got {statement}")

        query_graph,root =  self.engine.plan_query(value)
        return query_graph,root

    def draw_query(self,code):
        query_graph,root = self.plan_query(code)
        draw(query_graph)

    def execute_plan(self,query_graph,root,return_intermediate=False):
        res,inter = self.engine.execute_plan(query_graph,root,return_intermediate=True)
        res = self.handle_boolean_results(res)
        if return_intermediate:
            return res,inter
        return res
        

    def export(self,code,display_results=False):
        results = []
        for clean_ast,statement_lark in self.parse_and_check_semantics(code):
            try:
                result = execute_statement(clean_ast,self.engine)
                result = self.handle_boolean_results(result)
            except Exception as e:
                raise Exception(
                    f"During execution of statement \n\"{reconstruct(statement_lark)}\n\""
                    f"the following exception was raised:\n{e}\n"
                    ).with_traceback(e.__traceback__)
            results.append(result)
            if display_results:
                self._display_result(result,statement_lark)
        
        if len(results) == 0:
            return None
        else:
            return results[-1]

    def import_rel(self,name:str,data:Union[str,Path,pd.DataFrame],delim:str = None):
        """Imports a relation into the current session, either from a dataframe or from a csv file."""
        if isinstance(data, (Path,str)):
            csv_file_name = Path(data)
            if not csv_file_name.is_file():
                raise IOError("csv file does not exist")
            if os.stat(csv_file_name).st_size == 0:
                raise IOError("csv file is empty")
            data = pd.read_csv(csv_file_name, delimiter=delim)

        first_row = list(data.iloc[0,:])
        scheme = _infer_relation_schema(first_row)
        rel_def = RelationDefinition(name=name,scheme=scheme)
        self.engine.set_relation(rel_def)
        self.engine.add_facts(name,data)
        
    def print_rules(self):
        rules = list(self.engine.rules_to_ids.keys())
        for rule in rules:
            print(rule)
        return rules
    def remove_rule(self,rule:str):
        self.engine.del_rule(rule)

    def remove_all_rules(self):
        rules = list(self.engine.rules_to_ids.keys())
        for rule in rules:
            self.remove_rule(rule)

    def remove_relation(self,relation:str):
        self.engine.del_relation(relation)

    def get_all_functions(self):
        return {
            'ie':self.engine.ie_functions.copy(),
            'agg':self.engine.agg_functions.copy()
        }

# %% ../nbs/030_session.ipynb 8
def test_session(
    queries,
    expected_outputs=None,# list of expected dfs
    ie_funcs=None,# List of [name,func,in_scheme,out_scheme]
    agg_funcs=None,
    csvs=None,# List of [name,df]
    debug=False,
    display_results=True,
    ):

    sess=Session()

    # add data
    if csvs:
        for name,df in csvs:
            sess.import_rel(name,df)
    # add ies
    if ie_funcs:
        for name,func,in_scheme,out_scheme in ie_funcs:
            sess.register(name,func,in_scheme,out_scheme)
    
    if agg_funcs:
        for name,func,in_scheme,out_scheme in agg_funcs:
            sess.register_agg(name,func,in_scheme,out_scheme)

    if not isinstance(queries,list):
        queries = [queries]
    if expected_outputs is None:
        expected_outputs = [None]*len(queries)
        dont_assert = True
    else:
        dont_assert = False
    if not isinstance(expected_outputs,list):
        expected_outputs = [expected_outputs]
    for query,expected in zip(queries,expected_outputs):
        if debug and query == queries[-1]:
            print(query)
            q,root = sess.plan_query(query)
            draw(q)
            res,inter = sess.execute_plan(q,root,return_intermediate=True)
            return res,inter,sess
        else:
            res = sess.export(query,display_results=display_results)
        # used for debugging, we return the results of the first query without expected
        # if expected is None:
        #     return query
        if dont_assert:
            continue
        if isinstance(expected,pd.DataFrame):
            assert_df_equals(res,expected)
        else:
            assert res == expected, f"expected {expected}, got {res}"
    return sess
        
